{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import scipy.io\n",
    "from utils import log_gaussian_loss, gaussian, get_kl_Gaussian_divergence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BayesLinear_Normalq(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, prior):\n",
    "        super(BayesLinear_Normalq, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.prior = prior\n",
    "\n",
    "        scale = (2 / self.input_dim) ** 0.5\n",
    "        rho_init = np.log(np.exp((2 / self.input_dim) ** 0.5) - 1)\n",
    "\n",
    "        self.weight_mus = nn.Parameter(torch.Tensor(self.input_dim, self.output_dim).uniform_(-0.05, 0.05))\n",
    "        self.weight_rhos = nn.Parameter(torch.Tensor(self.input_dim, self.output_dim).uniform_(-3, -2))\n",
    "\n",
    "        self.bias_mus = nn.Parameter(torch.Tensor(self.output_dim).uniform_(-0.05, 0.05))\n",
    "        self.bias_rhos = nn.Parameter(torch.Tensor(self.output_dim).uniform_(-3, -2))\n",
    "\n",
    "        # nn.init.xavier_normal_(self.weight_mus.data, gain=1.0)\n",
    "        # nn.init.zeros_(self.bias_mus.data)\n",
    "\n",
    "    def forward(self, x, sample=True):\n",
    "\n",
    "        if sample:\n",
    "            # sample gaussian noise for each weight and each bias\n",
    "            weight_epsilons = self.weight_mus.data.new(self.weight_mus.size()).normal_()\n",
    "            bias_epsilons = self.bias_mus.data.new(self.bias_mus.size()).normal_()\n",
    "\n",
    "            # calculate the weight and bias stds from the rho parameters\n",
    "            weight_stds = torch.log(1 + torch.exp(self.weight_rhos))\n",
    "            bias_stds = torch.log(1 + torch.exp(self.bias_rhos))\n",
    "\n",
    "            # calculate samples from the posterior from the sampled noise and mus/stds\n",
    "            weight_sample = self.weight_mus + weight_epsilons * weight_stds\n",
    "            bias_sample = self.bias_mus + bias_epsilons * bias_stds\n",
    "            output = torch.mm(x, weight_sample) + bias_sample\n",
    "\n",
    "            # computing the KL loss term\n",
    "            KL_loss_weight = get_kl_Gaussian_divergence(self.prior.mu, self.prior.sigma**2, self.weight_mus, weight_stds**2)\n",
    "            KL_loss_bias = get_kl_Gaussian_divergence(self.prior.mu, self.prior.sigma**2, self.bias_mus, bias_stds**2)\n",
    "            KL_loss = KL_loss_weight + KL_loss_bias\n",
    "\n",
    "            return output, KL_loss\n",
    "        else:\n",
    "            output = torch.mm(x, self.weight_mus) + self.bias_mus\n",
    "            return output, KL_loss\n",
    "\n",
    "    def sample_layer(self, no_samples):\n",
    "        all_samples = []\n",
    "        for i in range(no_samples):\n",
    "            # sample gaussian noise for each weight and each bias\n",
    "            weight_epsilons = Variable(self.weight_mus.data.new(self.weight_mus.size()).normal_())\n",
    "\n",
    "            # calculate the weight and bias stds from the rho parameters\n",
    "            weight_stds = torch.log(1 + torch.exp(self.weight_rhos))\n",
    "\n",
    "            # calculate samples from the posterior from the sampled noise and mus/stds\n",
    "            weight_sample = self.weight_mus + weight_epsilons * weight_stds\n",
    "\n",
    "            all_samples += weight_sample.view(-1).cpu().data.numpy().tolist()\n",
    "\n",
    "        return all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "layer1 = BayesLinear_Normalq(2, 10, gaussian(0, 1))\n",
    "X = torch.tensor(X_u_train, requires_grad=True).float().to(device)\n",
    "a, b = layer1(X)\n",
    "\n",
    "activation = nn.Tanh()\n",
    "\n",
    "activation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BBP_Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, no_units):\n",
    "        super(BBP_Model, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # network with two hidden and one output layer\n",
    "        self.layer1 = BayesLinear_Normalq(input_dim, no_units, gaussian(0, 1))\n",
    "        self.layer2 = BayesLinear_Normalq(no_units, no_units, gaussian(0, 1))\n",
    "        self.layer3 = BayesLinear_Normalq(no_units, no_units, gaussian(0, 1))\n",
    "        self.layer4 = BayesLinear_Normalq(no_units, no_units, gaussian(0, 1))\n",
    "        self.layer5 = BayesLinear_Normalq(no_units, no_units, gaussian(0, 1))\n",
    "        self.layer6 = BayesLinear_Normalq(no_units, no_units, gaussian(0, 1))\n",
    "        self.layer7 = BayesLinear_Normalq(no_units, output_dim, gaussian(0, 1))\n",
    "\n",
    "        # activation to be used between hidden layers\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        KL_loss_total = 0\n",
    "        x = x.view(-1, self.input_dim)\n",
    "\n",
    "        x, KL_loss = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer3(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer4(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer5(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer6(x)\n",
    "        x = self.activation(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        x, KL_loss = self.layer7(x)\n",
    "        KL_loss_total += KL_loss\n",
    "\n",
    "        return x, KL_loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BBP_Model_PINN:\n",
    "    def __init__(self, xt_lb, xt_ub, u_lb, u_ub,\n",
    "                 input_dim, output_dim, no_units,\n",
    "                 learn_rate, batch_size, no_batches,\n",
    "                 prior_lambda1, prior_lambda2, num_epochs):\n",
    "\n",
    "        \n",
    "        self.xt_lb = torch.from_numpy(xt_lb).float().to(device)\n",
    "        self.xt_ub = torch.from_numpy(xt_ub).float().to(device)\n",
    "        self.u_lb = torch.from_numpy(u_lb).float().to(device)\n",
    "        self.u_ub = torch.from_numpy(u_ub).float().to(device)\n",
    "\n",
    "\n",
    "        self.learn_rate = learn_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.no_batches = no_batches\n",
    "\n",
    "        self.network = BBP_Model(input_dim = input_dim, output_dim = output_dim,\n",
    "                                    no_units = no_units)\n",
    "\n",
    "        # two PDE parameters\n",
    "        # self.log_noise_u = nn.Parameter(torch.log(torch.tensor([0.1], device = device)))\n",
    "        # self.log_noise_f = nn.Parameter(torch.log(torch.tensor([0.1], device = device)))\n",
    "        # self.log_noise_u = nn.Parameter(torch.FloatTensor([0]))\n",
    "        # self.log_noise_f = nn.Parameter(torch.FloatTensor([0]))\n",
    "        self.log_noise_u = nn.Parameter(torch.zeros(4000, 1))\n",
    "        self.log_noise_f = nn.Parameter(torch.zeros(4000, 1))\n",
    "        self.network.register_parameter('log_noise_u', self.log_noise_u)\n",
    "        self.network.register_parameter('log_noise_f', self.log_noise_f)\n",
    "\n",
    "        self.prior_lambda1 = prior_lambda1\n",
    "        self.prior_lambda2 = prior_lambda2\n",
    "\n",
    "        self.lambda1_mus = nn.Parameter(torch.Tensor(1).uniform_(0, 2))\n",
    "        self.lambda1_rhos = nn.Parameter(torch.Tensor(1).uniform_(-3, 2))\n",
    "        self.lambda2_mus = nn.Parameter(torch.Tensor(1).uniform_(0, 0.05))\n",
    "        self.lambda2_rhos = nn.Parameter(torch.Tensor(1).uniform_(-3, -2))\n",
    "\n",
    "        self.network.register_parameter('lambda1_mu', self.lambda1_mus)\n",
    "        self.network.register_parameter('lambda2_mu', self.lambda2_mus)\n",
    "        self.network.register_parameter('lambda1_rho', self.lambda1_rhos)\n",
    "        self.network.register_parameter('lambda2_rho', self.lambda2_rhos)\n",
    "\n",
    "        self.network = self.network.to(device)\n",
    "\n",
    "        # self.optimizer = torch.optim.SGD(self.network.parameters(), lr = self.learn_rate)\n",
    "        self.optimizer = torch.optim.AdamW(self.network.parameters(), lr = self.learn_rate)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr = 1e-3, \n",
    "        #                                     steps_per_epoch = no_batches, epochs = num_epochs)\n",
    "        self.loss_func = log_gaussian_loss\n",
    "\n",
    "    def net_U(self, x, t):\n",
    "        xt = torch.cat((x,t), dim=1)\n",
    "        xt = 2*(xt-self.xt_lb)/(self.xt_ub-self.xt_lb) - 1\n",
    "        u, KL_loss = self.network(xt)\n",
    "\n",
    "        # u = out[:,0:1]\n",
    "        # log_noise_u = out[:,1:2]\n",
    "        # log_noise_f = out[:,2:3]\n",
    "        return u, KL_loss\n",
    "\n",
    "    def net_F(self, x, t, lambda1_sample, lambda2_sample):\n",
    "        lambda_1 = lambda1_sample        \n",
    "        lambda_2 = torch.exp(lambda2_sample)\n",
    "\n",
    "        u, _ = self.net_U(x, t)\n",
    "        u = u*(self.u_ub-self.u_lb) + self.u_lb # reverse scaling\n",
    "\n",
    "        u_t = torch.autograd.grad(u, t, torch.ones_like(u),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x, torch.ones_like(u),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "\n",
    "        # F = u_t + 1*u*u_x - (0.01/np.pi)*u_xx\n",
    "        F = u_t + lambda_1*u*u_x - lambda_2*u_xx\n",
    "        return F\n",
    "\n",
    "    def fit(self, X, t, U, no_samples):\n",
    "        self.network.train()\n",
    "\n",
    "        # X = torch.tensor(self.X, requires_grad=True).float().to(device)\n",
    "        # t = torch.tensor(self.t, requires_grad=True).float().to(device)\n",
    "        U = (U-self.u_lb)/(self.u_ub-self.u_lb) # scaling\n",
    "\n",
    "        # reset gradient and total loss\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        fit_loss_total = 0\n",
    "        fit_loss_F_total = 0\n",
    "        fit_loss_U_total = 0\n",
    "\n",
    "        for i in range(no_samples):\n",
    "            lambda1_epsilons = self.lambda1_mus.data.new(self.lambda1_mus.size()).normal_()\n",
    "            lambda1_stds = torch.log(1 + torch.exp(self.lambda1_rhos))\n",
    "            lambda2_epsilons = self.lambda2_mus.data.new(self.lambda2_mus.size()).normal_()\n",
    "            lambda2_stds = torch.log(1 + torch.exp(self.lambda2_rhos))\n",
    "\n",
    "            lambda1_sample = self.lambda1_mus + lambda1_epsilons * lambda1_stds\n",
    "            lambda2_sample = self.lambda2_mus + lambda2_epsilons * lambda2_stds\n",
    "\n",
    "            u_pred, KL_loss_para = self.net_U(X, t)\n",
    "            f_pred = self.net_F(X, t, lambda1_sample, lambda2_sample)\n",
    "\n",
    "            # calculate fit loss based on mean and standard deviation of output\n",
    "            fit_loss_U_total += self.loss_func(u_pred, U, self.network.log_noise_u.exp(), self.network.output_dim)\n",
    "            fit_loss_F_total += torch.sum(f_pred**2)\n",
    "            # fit_loss_F_total += self.loss_func(f_pred, torch.zeros_like(f_pred), self.network.log_noise_f.exp(), self.network.output_dim)\n",
    "\n",
    "        KL_loss_lambda1 = get_kl_Gaussian_divergence(self.prior_lambda1.mu, self.prior_lambda1.sigma**2, self.lambda1_mus, lambda1_stds**2)\n",
    "        KL_loss_lambda2 = get_kl_Gaussian_divergence(self.prior_lambda2.mu, self.prior_lambda2.sigma**2, self.lambda2_mus, lambda2_stds**2)\n",
    "        KL_loss_total = KL_loss_para + KL_loss_lambda1 + KL_loss_lambda2\n",
    "\n",
    "        # KL_loss_total = KL_loss_para \n",
    "        # minibatches and KL reweighting\n",
    "        KL_loss_total = KL_loss_total/self.no_batches\n",
    "        total_loss = (KL_loss_total + fit_loss_U_total + fit_loss_F_total) / (no_samples*X.shape[0])\n",
    "        \n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        # self.scheduler.step()\n",
    "\n",
    "        return fit_loss_U_total/no_samples, fit_loss_F_total/no_samples, KL_loss_total, total_loss\n",
    "\n",
    "    def predict(self, xt, no_sample, best_net):\n",
    "        xt = torch.tensor(xt, requires_grad=True).float().to(device)\n",
    "        xt = 2*(xt-self.xt_lb)/(self.xt_ub-self.xt_lb) - 1\n",
    "\n",
    "        self.network.eval()\n",
    "        sample = []\n",
    "      \n",
    "        for i in range(no_sample):\n",
    "            u_pred, _, = best_net(xt)\n",
    "            u_pred = u_pred*(self.u_ub-self.u_lb) + self.u_lb # reverse scaling\n",
    "            sample.append(u_pred.detach().cpu().numpy())\n",
    "        return np.array(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('./Data/burgers_shock.mat')\n",
    "\n",
    "t = data['t'].flatten()[:,None] # 100 x 1\n",
    "x = data['x'].flatten()[:,None] # 256 x 1\n",
    "Exact = np.real(data['usol']).T # 100 x 256\n",
    "\n",
    "Exact += np.random.normal(0, 0.03, (100, 256))\n",
    "\n",
    "X, T = np.meshgrid(x,t) # 100 x 256\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None])) # 25600 x 2\n",
    "u_star = Exact.flatten()[:,None]  # 25600 x 1\n",
    "\n",
    "# Domain bounds of x, t\n",
    "xt_lb = X_star.min(0)\n",
    "xt_ub = X_star.max(0)\n",
    "\n",
    "# training data\n",
    "N_u = 4000\n",
    "idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "X_u_train = X_star[idx,:]\n",
    "\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "u_lb = u_train.min(0)\n",
    "u_ub = u_train.max(0)\n",
    "\n",
    "num_epochs, batch_size = 25000, len(X_u_train),\n",
    "\n",
    "net = BBP_Model_PINN(xt_lb, xt_ub, u_lb, u_ub,\n",
    "                     input_dim = 2, output_dim = 1, no_units = 50, learn_rate = 1e-3,\n",
    "                        batch_size = batch_size, no_batches = 1,\n",
    "                        prior_lambda1 = gaussian(0, 1), prior_lambda2 = gaussian(0, 1), num_epochs = num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_loss_U_train = np.zeros(num_epochs)\n",
    "fit_loss_F_train = np.zeros(num_epochs)\n",
    "KL_loss_train = np.zeros(num_epochs)\n",
    "loss = np.zeros(num_epochs)\n",
    "noise = []\n",
    "\n",
    "best_net, best_loss = None, float('inf')\n",
    "\n",
    "X = torch.tensor(X_u_train[:,0:1], requires_grad = True, device = device).float()\n",
    "t = torch.tensor(X_u_train[:,1:2], requires_grad = True, device = device).float()\n",
    "U = torch.tensor(u_train, requires_grad = True, device = device).float()\n",
    "\n",
    "X_u_test_25 = np.hstack([x, 0.25*np.ones_like((x))])\n",
    "target_25 = Exact[25].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1/25000, total loss = 1.424, Fit loss U = 4369.445, Fit loss F = 1.484, KL loss = 26493.150\n",
      "Epoch:     1/25000, lambda1_mu = 0.819, lambda2_mu = 1.031, lambda1_std = 0.087, lambda2_std = 0.086\n",
      "Epoch:     1/25000, error_25 = 1.73618, error_train = 1.94788\n",
      "\n",
      "Epoch:   101/25000, total loss = 1.211, Fit loss U = 3535.167, Fit loss F = 8.982, KL loss = 26012.709\n",
      "Epoch:   101/25000, lambda1_mu = 0.744, lambda2_mu = 1.007, lambda1_std = 0.089, lambda2_std = 0.094\n",
      "Epoch:   101/25000, error_25 = 0.99881, error_train = 1.00401\n",
      "\n",
      "Epoch:   201/25000, total loss = 1.102, Fit loss U = 3124.728, Fit loss F = 4.185, KL loss = 25563.213\n",
      "Epoch:   201/25000, lambda1_mu = 0.704, lambda2_mu = 0.985, lambda1_std = 0.093, lambda2_std = 0.104\n",
      "Epoch:   201/25000, error_25 = 0.99979, error_train = 0.99902\n",
      "\n",
      "Epoch:   301/25000, total loss = 1.012, Fit loss U = 2780.077, Fit loss F = 11.059, KL loss = 25138.154\n",
      "Epoch:   301/25000, lambda1_mu = 0.605, lambda2_mu = 0.890, lambda1_std = 0.096, lambda2_std = 0.112\n",
      "Epoch:   301/25000, error_25 = 0.92679, error_train = 0.91356\n",
      "\n",
      "Epoch:   401/25000, total loss = 0.916, Fit loss U = 2397.377, Fit loss F = 26.825, KL loss = 24818.611\n",
      "Epoch:   401/25000, lambda1_mu = 0.496, lambda2_mu = 0.697, lambda1_std = 0.091, lambda2_std = 0.102\n",
      "Epoch:   401/25000, error_25 = 0.86414, error_train = 0.87646\n",
      "\n",
      "Epoch:   501/25000, total loss = 0.849, Fit loss U = 2120.757, Fit loss F = 46.172, KL loss = 24568.404\n",
      "Epoch:   501/25000, lambda1_mu = 0.465, lambda2_mu = 0.581, lambda1_std = 0.086, lambda2_std = 0.092\n",
      "Epoch:   501/25000, error_25 = 0.85372, error_train = 0.86262\n",
      "\n",
      "Epoch:   601/25000, total loss = 0.761, Fit loss U = 1796.756, Fit loss F = 29.479, KL loss = 24355.668\n",
      "Epoch:   601/25000, lambda1_mu = 0.478, lambda2_mu = 0.493, lambda1_std = 0.082, lambda2_std = 0.086\n",
      "Epoch:   601/25000, error_25 = 0.84599, error_train = 0.83189\n",
      "\n",
      "Epoch:   701/25000, total loss = 0.673, Fit loss U = 1411.714, Fit loss F = 69.872, KL loss = 24171.225\n",
      "Epoch:   701/25000, lambda1_mu = 0.495, lambda2_mu = 0.427, lambda1_std = 0.076, lambda2_std = 0.080\n",
      "Epoch:   701/25000, error_25 = 0.80295, error_train = 0.81697\n",
      "\n",
      "Epoch:   801/25000, total loss = 0.611, Fit loss U = 1229.668, Fit loss F = 16.144, KL loss = 24003.695\n",
      "Epoch:   801/25000, lambda1_mu = 0.508, lambda2_mu = 0.373, lambda1_std = 0.071, lambda2_std = 0.074\n",
      "Epoch:   801/25000, error_25 = 0.82238, error_train = 0.83135\n",
      "\n",
      "Epoch:   901/25000, total loss = 0.530, Fit loss U = 885.092, Fit loss F = 44.311, KL loss = 23849.824\n",
      "Epoch:   901/25000, lambda1_mu = 0.542, lambda2_mu = 0.327, lambda1_std = 0.067, lambda2_std = 0.070\n",
      "Epoch:   901/25000, error_25 = 0.78523, error_train = 0.79199\n",
      "\n",
      "Epoch:  1001/25000, total loss = 0.497, Fit loss U = 771.024, Fit loss F = 31.375, KL loss = 23704.084\n",
      "Epoch:  1001/25000, lambda1_mu = 0.582, lambda2_mu = 0.285, lambda1_std = 0.063, lambda2_std = 0.066\n",
      "Epoch:  1001/25000, error_25 = 0.78135, error_train = 0.80255\n",
      "\n",
      "Epoch:  1101/25000, total loss = 0.399, Fit loss U = 362.873, Fit loss F = 53.110, KL loss = 23570.895\n",
      "Epoch:  1101/25000, lambda1_mu = 0.651, lambda2_mu = 0.245, lambda1_std = 0.060, lambda2_std = 0.062\n",
      "Epoch:  1101/25000, error_25 = 0.74895, error_train = 0.76471\n",
      "\n",
      "Epoch:  1201/25000, total loss = 0.347, Fit loss U = 182.143, Fit loss F = 33.325, KL loss = 23445.402\n",
      "Epoch:  1201/25000, lambda1_mu = 0.734, lambda2_mu = 0.208, lambda1_std = 0.058, lambda2_std = 0.059\n",
      "Epoch:  1201/25000, error_25 = 0.75165, error_train = 0.76889\n",
      "\n",
      "Epoch:  1301/25000, total loss = 0.288, Fit loss U = -88.149, Fit loss F = 74.211, KL loss = 23331.570\n",
      "Epoch:  1301/25000, lambda1_mu = 0.827, lambda2_mu = 0.173, lambda1_std = 0.055, lambda2_std = 0.055\n",
      "Epoch:  1301/25000, error_25 = 0.71538, error_train = 0.72803\n",
      "\n",
      "Epoch:  1401/25000, total loss = 0.203, Fit loss U = -406.117, Fit loss F = 54.903, KL loss = 23230.568\n",
      "Epoch:  1401/25000, lambda1_mu = 0.937, lambda2_mu = 0.143, lambda1_std = 0.054, lambda2_std = 0.052\n",
      "Epoch:  1401/25000, error_25 = 0.66800, error_train = 0.71479\n",
      "\n",
      "Epoch:  1501/25000, total loss = 0.158, Fit loss U = -618.666, Fit loss F = 94.572, KL loss = 23140.260\n",
      "Epoch:  1501/25000, lambda1_mu = 1.027, lambda2_mu = 0.120, lambda1_std = 0.052, lambda2_std = 0.048\n",
      "Epoch:  1501/25000, error_25 = 0.64447, error_train = 0.68400\n",
      "\n",
      "Epoch:  1601/25000, total loss = 0.095, Fit loss U = -852.019, Fit loss F = 77.901, KL loss = 23051.111\n",
      "Epoch:  1601/25000, lambda1_mu = 1.131, lambda2_mu = 0.101, lambda1_std = 0.050, lambda2_std = 0.046\n",
      "Epoch:  1601/25000, error_25 = 0.61146, error_train = 0.65126\n",
      "\n",
      "Epoch:  1701/25000, total loss = 0.047, Fit loss U = -1085.586, Fit loss F = 123.157, KL loss = 22975.078\n",
      "Epoch:  1701/25000, lambda1_mu = 1.234, lambda2_mu = 0.085, lambda1_std = 0.048, lambda2_std = 0.043\n",
      "Epoch:  1701/25000, error_25 = 0.58455, error_train = 0.62203\n",
      "\n",
      "Epoch:  1801/25000, total loss = -0.056, Fit loss U = -1431.973, Fit loss F = 63.171, KL loss = 22920.814\n",
      "Epoch:  1801/25000, lambda1_mu = 1.322, lambda2_mu = 0.072, lambda1_std = 0.046, lambda2_std = 0.041\n",
      "Epoch:  1801/25000, error_25 = 0.55385, error_train = 0.58247\n",
      "\n",
      "Epoch:  1901/25000, total loss = -0.110, Fit loss U = -1701.754, Fit loss F = 119.781, KL loss = 22879.301\n",
      "Epoch:  1901/25000, lambda1_mu = 1.367, lambda2_mu = 0.062, lambda1_std = 0.044, lambda2_std = 0.038\n",
      "Epoch:  1901/25000, error_25 = 0.53572, error_train = 0.56861\n",
      "\n",
      "Epoch:  2001/25000, total loss = -0.138, Fit loss U = -1837.101, Fit loss F = 141.932, KL loss = 22849.543\n",
      "Epoch:  2001/25000, lambda1_mu = 1.366, lambda2_mu = 0.054, lambda1_std = 0.042, lambda2_std = 0.035\n",
      "Epoch:  2001/25000, error_25 = 0.50234, error_train = 0.54796\n",
      "\n",
      "Epoch:  2101/25000, total loss = -0.218, Fit loss U = -2180.012, Fit loss F = 164.786, KL loss = 22829.580\n",
      "Epoch:  2101/25000, lambda1_mu = 1.340, lambda2_mu = 0.047, lambda1_std = 0.040, lambda2_std = 0.033\n",
      "Epoch:  2101/25000, error_25 = 0.50421, error_train = 0.51846\n",
      "\n",
      "Epoch:  2201/25000, total loss = -0.257, Fit loss U = -2299.991, Fit loss F = 129.899, KL loss = 22812.621\n",
      "Epoch:  2201/25000, lambda1_mu = 1.270, lambda2_mu = 0.041, lambda1_std = 0.039, lambda2_std = 0.031\n",
      "Epoch:  2201/25000, error_25 = 0.46522, error_train = 0.50488\n",
      "\n",
      "Epoch:  2301/25000, total loss = -0.311, Fit loss U = -2538.044, Fit loss F = 154.045, KL loss = 22805.225\n",
      "Epoch:  2301/25000, lambda1_mu = 1.189, lambda2_mu = 0.037, lambda1_std = 0.037, lambda2_std = 0.029\n",
      "Epoch:  2301/25000, error_25 = 0.44226, error_train = 0.48111\n",
      "\n",
      "Epoch:  2401/25000, total loss = -0.363, Fit loss U = -2708.767, Fit loss F = 115.308, KL loss = 22806.031\n",
      "Epoch:  2401/25000, lambda1_mu = 1.073, lambda2_mu = 0.033, lambda1_std = 0.034, lambda2_std = 0.028\n",
      "Epoch:  2401/25000, error_25 = 0.46658, error_train = 0.48803\n",
      "\n",
      "Epoch:  2501/25000, total loss = -0.423, Fit loss U = -2966.035, Fit loss F = 132.343, KL loss = 22811.701\n",
      "Epoch:  2501/25000, lambda1_mu = 0.941, lambda2_mu = 0.029, lambda1_std = 0.032, lambda2_std = 0.027\n",
      "Epoch:  2501/25000, error_25 = 0.42606, error_train = 0.47104\n",
      "\n",
      "Epoch:  2601/25000, total loss = -0.465, Fit loss U = -3182.717, Fit loss F = 180.430, KL loss = 22825.617\n",
      "Epoch:  2601/25000, lambda1_mu = 0.815, lambda2_mu = 0.026, lambda1_std = 0.031, lambda2_std = 0.026\n",
      "Epoch:  2601/25000, error_25 = 0.35461, error_train = 0.42268\n",
      "\n",
      "Epoch:  2701/25000, total loss = -0.509, Fit loss U = -3380.118, Fit loss F = 201.743, KL loss = 22843.252\n",
      "Epoch:  2701/25000, lambda1_mu = 0.693, lambda2_mu = 0.023, lambda1_std = 0.029, lambda2_std = 0.025\n",
      "Epoch:  2701/25000, error_25 = 0.36667, error_train = 0.40210\n",
      "\n",
      "Epoch:  2801/25000, total loss = -0.564, Fit loss U = -3544.314, Fit loss F = 144.845, KL loss = 22864.533\n",
      "Epoch:  2801/25000, lambda1_mu = 0.614, lambda2_mu = 0.021, lambda1_std = 0.027, lambda2_std = 0.024\n",
      "Epoch:  2801/25000, error_25 = 0.38193, error_train = 0.40867\n",
      "\n",
      "Epoch:  2901/25000, total loss = -0.532, Fit loss U = -3470.288, Fit loss F = 196.787, KL loss = 22881.389\n",
      "Epoch:  2901/25000, lambda1_mu = 0.544, lambda2_mu = 0.019, lambda1_std = 0.025, lambda2_std = 0.024\n",
      "Epoch:  2901/25000, error_25 = 0.37104, error_train = 0.39035\n",
      "\n",
      "Epoch:  3001/25000, total loss = -0.635, Fit loss U = -3825.033, Fit loss F = 138.163, KL loss = 22903.463\n",
      "Epoch:  3001/25000, lambda1_mu = 0.508, lambda2_mu = 0.017, lambda1_std = 0.024, lambda2_std = 0.023\n",
      "Epoch:  3001/25000, error_25 = 0.34580, error_train = 0.38118\n",
      "\n",
      "Epoch:  3101/25000, total loss = -0.657, Fit loss U = -3901.167, Fit loss F = 125.996, KL loss = 22924.176\n",
      "Epoch:  3101/25000, lambda1_mu = 0.458, lambda2_mu = 0.015, lambda1_std = 0.022, lambda2_std = 0.023\n",
      "Epoch:  3101/25000, error_25 = 0.34886, error_train = 0.37822\n",
      "\n",
      "Epoch:  3201/25000, total loss = -0.693, Fit loss U = -4053.245, Fit loss F = 134.163, KL loss = 22942.730\n",
      "Epoch:  3201/25000, lambda1_mu = 0.429, lambda2_mu = 0.014, lambda1_std = 0.021, lambda2_std = 0.023\n",
      "Epoch:  3201/25000, error_25 = 0.32560, error_train = 0.36624\n",
      "\n",
      "Epoch:  3301/25000, total loss = -0.752, Fit loss U = -4266.692, Fit loss F = 112.320, KL loss = 22960.994\n",
      "Epoch:  3301/25000, lambda1_mu = 0.410, lambda2_mu = 0.013, lambda1_std = 0.020, lambda2_std = 0.022\n",
      "Epoch:  3301/25000, error_25 = 0.29319, error_train = 0.35550\n",
      "\n",
      "Epoch:  3401/25000, total loss = -0.808, Fit loss U = -4480.166, Fit loss F = 97.945, KL loss = 22977.592\n",
      "Epoch:  3401/25000, lambda1_mu = 0.391, lambda2_mu = 0.011, lambda1_std = 0.019, lambda2_std = 0.022\n",
      "Epoch:  3401/25000, error_25 = 0.32361, error_train = 0.36328\n",
      "\n",
      "Epoch:  3501/25000, total loss = -0.805, Fit loss U = -4494.822, Fit loss F = 124.170, KL loss = 22995.166\n",
      "Epoch:  3501/25000, lambda1_mu = 0.375, lambda2_mu = 0.011, lambda1_std = 0.018, lambda2_std = 0.022\n",
      "Epoch:  3501/25000, error_25 = 0.29462, error_train = 0.33908\n",
      "\n",
      "Epoch:  3601/25000, total loss = -0.745, Fit loss U = -4265.891, Fit loss F = 135.424, KL loss = 23014.000\n",
      "Epoch:  3601/25000, lambda1_mu = 0.364, lambda2_mu = 0.010, lambda1_std = 0.017, lambda2_std = 0.022\n",
      "Epoch:  3601/25000, error_25 = 0.32974, error_train = 0.35033\n",
      "\n",
      "Epoch:  3701/25000, total loss = -0.842, Fit loss U = -4613.722, Fit loss F = 93.716, KL loss = 23030.490\n",
      "Epoch:  3701/25000, lambda1_mu = 0.355, lambda2_mu = 0.009, lambda1_std = 0.016, lambda2_std = 0.022\n",
      "Epoch:  3701/25000, error_25 = 0.31897, error_train = 0.35038\n",
      "\n",
      "Epoch:  3801/25000, total loss = -0.835, Fit loss U = -4584.683, Fit loss F = 94.313, KL loss = 23046.145\n",
      "Epoch:  3801/25000, lambda1_mu = 0.348, lambda2_mu = 0.008, lambda1_std = 0.016, lambda2_std = 0.021\n",
      "Epoch:  3801/25000, error_25 = 0.31335, error_train = 0.33729\n",
      "\n",
      "Epoch:  3901/25000, total loss = -0.862, Fit loss U = -4705.092, Fit loss F = 103.580, KL loss = 23066.939\n",
      "Epoch:  3901/25000, lambda1_mu = 0.351, lambda2_mu = 0.008, lambda1_std = 0.015, lambda2_std = 0.021\n",
      "Epoch:  3901/25000, error_25 = 0.31941, error_train = 0.34813\n",
      "\n",
      "Epoch:  4001/25000, total loss = -0.930, Fit loss U = -4987.636, Fit loss F = 113.183, KL loss = 23089.680\n",
      "Epoch:  4001/25000, lambda1_mu = 0.364, lambda2_mu = 0.007, lambda1_std = 0.014, lambda2_std = 0.021\n",
      "Epoch:  4001/25000, error_25 = 0.28604, error_train = 0.31550\n",
      "\n",
      "Epoch:  4101/25000, total loss = -0.989, Fit loss U = -5203.332, Fit loss F = 89.784, KL loss = 23116.480\n",
      "Epoch:  4101/25000, lambda1_mu = 0.392, lambda2_mu = 0.007, lambda1_std = 0.014, lambda2_std = 0.020\n",
      "Epoch:  4101/25000, error_25 = 0.27231, error_train = 0.30309\n",
      "\n",
      "Epoch:  4201/25000, total loss = -0.995, Fit loss U = -5247.332, Fit loss F = 110.720, KL loss = 23146.131\n",
      "Epoch:  4201/25000, lambda1_mu = 0.419, lambda2_mu = 0.006, lambda1_std = 0.013, lambda2_std = 0.020\n",
      "Epoch:  4201/25000, error_25 = 0.25328, error_train = 0.28365\n",
      "\n",
      "Epoch:  4301/25000, total loss = -1.053, Fit loss U = -5468.048, Fit loss F = 99.276, KL loss = 23173.902\n",
      "Epoch:  4301/25000, lambda1_mu = 0.432, lambda2_mu = 0.006, lambda1_std = 0.012, lambda2_std = 0.020\n",
      "Epoch:  4301/25000, error_25 = 0.23434, error_train = 0.27130\n",
      "\n",
      "Epoch:  4401/25000, total loss = -1.062, Fit loss U = -5536.990, Fit loss F = 130.542, KL loss = 23204.951\n",
      "Epoch:  4401/25000, lambda1_mu = 0.442, lambda2_mu = 0.006, lambda1_std = 0.012, lambda2_std = 0.019\n",
      "Epoch:  4401/25000, error_25 = 0.23193, error_train = 0.26134\n",
      "\n",
      "Epoch:  4501/25000, total loss = -1.045, Fit loss U = -5469.560, Fit loss F = 127.661, KL loss = 23233.502\n",
      "Epoch:  4501/25000, lambda1_mu = 0.456, lambda2_mu = 0.006, lambda1_std = 0.011, lambda2_std = 0.019\n",
      "Epoch:  4501/25000, error_25 = 0.22478, error_train = 0.25954\n",
      "\n",
      "Epoch:  4601/25000, total loss = -1.088, Fit loss U = -5661.672, Fit loss F = 147.452, KL loss = 23259.330\n",
      "Epoch:  4601/25000, lambda1_mu = 0.456, lambda2_mu = 0.005, lambda1_std = 0.011, lambda2_std = 0.018\n",
      "Epoch:  4601/25000, error_25 = 0.22340, error_train = 0.25303\n",
      "\n",
      "Epoch:  4701/25000, total loss = -1.139, Fit loss U = -5858.019, Fit loss F = 139.358, KL loss = 23282.738\n",
      "Epoch:  4701/25000, lambda1_mu = 0.468, lambda2_mu = 0.005, lambda1_std = 0.010, lambda2_std = 0.018\n",
      "Epoch:  4701/25000, error_25 = 0.20799, error_train = 0.24758\n",
      "\n",
      "Epoch:  4801/25000, total loss = -1.131, Fit loss U = -5834.120, Fit loss F = 144.083, KL loss = 23310.328\n",
      "Epoch:  4801/25000, lambda1_mu = 0.468, lambda2_mu = 0.005, lambda1_std = 0.010, lambda2_std = 0.017\n",
      "Epoch:  4801/25000, error_25 = 0.21200, error_train = 0.23836\n",
      "\n",
      "Epoch:  4901/25000, total loss = -1.114, Fit loss U = -5782.360, Fit loss F = 158.984, KL loss = 23337.098\n",
      "Epoch:  4901/25000, lambda1_mu = 0.478, lambda2_mu = 0.005, lambda1_std = 0.009, lambda2_std = 0.017\n",
      "Epoch:  4901/25000, error_25 = 0.19256, error_train = 0.22860\n",
      "\n",
      "Epoch:  5001/25000, total loss = -1.217, Fit loss U = -6194.246, Fit loss F = 156.107, KL loss = 23362.879\n",
      "Epoch:  5001/25000, lambda1_mu = 0.480, lambda2_mu = 0.005, lambda1_std = 0.009, lambda2_std = 0.016\n",
      "Epoch:  5001/25000, error_25 = 0.18644, error_train = 0.22577\n",
      "\n",
      "Epoch:  5101/25000, total loss = -1.247, Fit loss U = -6353.065, Fit loss F = 196.074, KL loss = 23392.762\n",
      "Epoch:  5101/25000, lambda1_mu = 0.484, lambda2_mu = 0.005, lambda1_std = 0.009, lambda2_std = 0.016\n",
      "Epoch:  5101/25000, error_25 = 0.17999, error_train = 0.21625\n",
      "\n",
      "Epoch:  5201/25000, total loss = -1.170, Fit loss U = -6035.541, Fit loss F = 186.441, KL loss = 23418.910\n",
      "Epoch:  5201/25000, lambda1_mu = 0.491, lambda2_mu = 0.005, lambda1_std = 0.008, lambda2_std = 0.015\n",
      "Epoch:  5201/25000, error_25 = 0.18003, error_train = 0.21425\n",
      "\n",
      "Epoch:  5301/25000, total loss = -1.286, Fit loss U = -6506.278, Fit loss F = 191.283, KL loss = 23448.338\n",
      "Epoch:  5301/25000, lambda1_mu = 0.497, lambda2_mu = 0.005, lambda1_std = 0.008, lambda2_std = 0.015\n",
      "Epoch:  5301/25000, error_25 = 0.16814, error_train = 0.21512\n",
      "\n",
      "Epoch:  5401/25000, total loss = -1.308, Fit loss U = -6593.290, Fit loss F = 186.959, KL loss = 23477.432\n",
      "Epoch:  5401/25000, lambda1_mu = 0.495, lambda2_mu = 0.005, lambda1_std = 0.008, lambda2_std = 0.014\n",
      "Epoch:  5401/25000, error_25 = 0.16477, error_train = 0.20985\n",
      "\n",
      "Epoch:  5501/25000, total loss = -1.287, Fit loss U = -6554.870, Fit loss F = 231.198, KL loss = 23509.492\n",
      "Epoch:  5501/25000, lambda1_mu = 0.506, lambda2_mu = 0.005, lambda1_std = 0.007, lambda2_std = 0.014\n",
      "Epoch:  5501/25000, error_25 = 0.16572, error_train = 0.19844\n",
      "\n",
      "Epoch:  5601/25000, total loss = -1.358, Fit loss U = -6838.214, Fit loss F = 228.090, KL loss = 23539.818\n",
      "Epoch:  5601/25000, lambda1_mu = 0.510, lambda2_mu = 0.004, lambda1_std = 0.007, lambda2_std = 0.014\n",
      "Epoch:  5601/25000, error_25 = 0.15458, error_train = 0.19231\n",
      "\n",
      "Epoch:  5701/25000, total loss = -1.372, Fit loss U = -6913.589, Fit loss F = 248.791, KL loss = 23571.930\n",
      "Epoch:  5701/25000, lambda1_mu = 0.516, lambda2_mu = 0.004, lambda1_std = 0.007, lambda2_std = 0.013\n",
      "Epoch:  5701/25000, error_25 = 0.14145, error_train = 0.18240\n",
      "\n",
      "Epoch:  5801/25000, total loss = -1.430, Fit loss U = -7147.415, Fit loss F = 248.786, KL loss = 23603.639\n",
      "Epoch:  5801/25000, lambda1_mu = 0.522, lambda2_mu = 0.004, lambda1_std = 0.007, lambda2_std = 0.013\n",
      "Epoch:  5801/25000, error_25 = 0.13439, error_train = 0.18187\n",
      "\n",
      "Epoch:  5901/25000, total loss = -1.472, Fit loss U = -7334.655, Fit loss F = 263.747, KL loss = 23636.195\n",
      "Epoch:  5901/25000, lambda1_mu = 0.530, lambda2_mu = 0.004, lambda1_std = 0.006, lambda2_std = 0.012\n",
      "Epoch:  5901/25000, error_25 = 0.12695, error_train = 0.16961\n",
      "\n",
      "Epoch:  6001/25000, total loss = -1.417, Fit loss U = -7122.888, Fit loss F = 273.038, KL loss = 23671.223\n",
      "Epoch:  6001/25000, lambda1_mu = 0.535, lambda2_mu = 0.004, lambda1_std = 0.006, lambda2_std = 0.012\n",
      "Epoch:  6001/25000, error_25 = 0.10959, error_train = 0.16041\n",
      "\n",
      "Epoch:  6101/25000, total loss = -1.568, Fit loss U = -7718.523, Fit loss F = 261.882, KL loss = 23703.920\n",
      "Epoch:  6101/25000, lambda1_mu = 0.544, lambda2_mu = 0.004, lambda1_std = 0.006, lambda2_std = 0.012\n",
      "Epoch:  6101/25000, error_25 = 0.10986, error_train = 0.16313\n",
      "\n",
      "Epoch:  6201/25000, total loss = -1.372, Fit loss U = -6947.098, Fit loss F = 272.627, KL loss = 23740.498\n",
      "Epoch:  6201/25000, lambda1_mu = 0.549, lambda2_mu = 0.004, lambda1_std = 0.006, lambda2_std = 0.011\n",
      "Epoch:  6201/25000, error_25 = 0.10053, error_train = 0.15856\n",
      "\n",
      "Epoch:  6301/25000, total loss = -1.570, Fit loss U = -7807.752, Fit loss F = 338.369, KL loss = 23776.482\n",
      "Epoch:  6301/25000, lambda1_mu = 0.552, lambda2_mu = 0.004, lambda1_std = 0.006, lambda2_std = 0.011\n",
      "Epoch:  6301/25000, error_25 = 0.10525, error_train = 0.15279\n",
      "\n",
      "Epoch:  6401/25000, total loss = -1.614, Fit loss U = -7954.977, Fit loss F = 309.140, KL loss = 23812.664\n",
      "Epoch:  6401/25000, lambda1_mu = 0.559, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.011\n",
      "Epoch:  6401/25000, error_25 = 0.10723, error_train = 0.15381\n",
      "\n",
      "Epoch:  6501/25000, total loss = -1.596, Fit loss U = -7872.323, Fit loss F = 295.397, KL loss = 23847.367\n",
      "Epoch:  6501/25000, lambda1_mu = 0.563, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.010\n",
      "Epoch:  6501/25000, error_25 = 0.09061, error_train = 0.14562\n",
      "\n",
      "Epoch:  6601/25000, total loss = -1.687, Fit loss U = -8256.485, Fit loss F = 315.578, KL loss = 23881.809\n",
      "Epoch:  6601/25000, lambda1_mu = 0.570, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.010\n",
      "Epoch:  6601/25000, error_25 = 0.08576, error_train = 0.14214\n",
      "\n",
      "Epoch:  6701/25000, total loss = -1.639, Fit loss U = -8086.725, Fit loss F = 336.507, KL loss = 23914.623\n",
      "Epoch:  6701/25000, lambda1_mu = 0.576, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.010\n",
      "Epoch:  6701/25000, error_25 = 0.08241, error_train = 0.13745\n",
      "\n",
      "Epoch:  6801/25000, total loss = -1.563, Fit loss U = -7779.567, Fit loss F = 331.833, KL loss = 23949.893\n",
      "Epoch:  6801/25000, lambda1_mu = 0.579, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.009\n",
      "Epoch:  6801/25000, error_25 = 0.08447, error_train = 0.14006\n",
      "\n",
      "Epoch:  6901/25000, total loss = -1.650, Fit loss U = -8108.789, Fit loss F = 310.326, KL loss = 23981.561\n",
      "Epoch:  6901/25000, lambda1_mu = 0.578, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.009\n",
      "Epoch:  6901/25000, error_25 = 0.08518, error_train = 0.13607\n",
      "\n",
      "Epoch:  7001/25000, total loss = -1.753, Fit loss U = -8541.804, Fit loss F = 330.955, KL loss = 24014.076\n",
      "Epoch:  7001/25000, lambda1_mu = 0.586, lambda2_mu = 0.004, lambda1_std = 0.005, lambda2_std = 0.009\n",
      "Epoch:  7001/25000, error_25 = 0.07353, error_train = 0.13093\n",
      "\n",
      "Epoch:  7101/25000, total loss = -1.676, Fit loss U = -8224.733, Fit loss F = 317.769, KL loss = 24045.086\n",
      "Epoch:  7101/25000, lambda1_mu = 0.589, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.009\n",
      "Epoch:  7101/25000, error_25 = 0.07179, error_train = 0.12764\n",
      "\n",
      "Epoch:  7201/25000, total loss = -1.758, Fit loss U = -8565.695, Fit loss F = 328.693, KL loss = 24080.807\n",
      "Epoch:  7201/25000, lambda1_mu = 0.594, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.008\n",
      "Epoch:  7201/25000, error_25 = 0.07355, error_train = 0.12594\n",
      "\n",
      "Epoch:  7301/25000, total loss = -1.802, Fit loss U = -8718.005, Fit loss F = 305.677, KL loss = 24114.322\n",
      "Epoch:  7301/25000, lambda1_mu = 0.597, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.008\n",
      "Epoch:  7301/25000, error_25 = 0.07501, error_train = 0.12803\n",
      "\n",
      "Epoch:  7401/25000, total loss = -1.788, Fit loss U = -8683.357, Fit loss F = 324.603, KL loss = 24149.002\n",
      "Epoch:  7401/25000, lambda1_mu = 0.600, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.008\n",
      "Epoch:  7401/25000, error_25 = 0.07777, error_train = 0.13344\n",
      "\n",
      "Epoch:  7501/25000, total loss = -1.759, Fit loss U = -8577.381, Fit loss F = 330.451, KL loss = 24178.834\n",
      "Epoch:  7501/25000, lambda1_mu = 0.605, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.008\n",
      "Epoch:  7501/25000, error_25 = 0.07070, error_train = 0.12493\n",
      "\n",
      "Epoch:  7601/25000, total loss = -1.789, Fit loss U = -8685.439, Fit loss F = 317.542, KL loss = 24209.535\n",
      "Epoch:  7601/25000, lambda1_mu = 0.606, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.008\n",
      "Epoch:  7601/25000, error_25 = 0.06790, error_train = 0.12284\n",
      "\n",
      "Epoch:  7701/25000, total loss = -1.808, Fit loss U = -8753.821, Fit loss F = 307.876, KL loss = 24240.854\n",
      "Epoch:  7701/25000, lambda1_mu = 0.612, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.007\n",
      "Epoch:  7701/25000, error_25 = 0.06932, error_train = 0.12028\n",
      "\n",
      "Epoch:  7801/25000, total loss = -1.867, Fit loss U = -8992.012, Fit loss F = 311.000, KL loss = 24269.840\n",
      "Epoch:  7801/25000, lambda1_mu = 0.618, lambda2_mu = 0.004, lambda1_std = 0.004, lambda2_std = 0.007\n",
      "Epoch:  7801/25000, error_25 = 0.06407, error_train = 0.11893\n",
      "\n",
      "Epoch:  7901/25000, total loss = -1.819, Fit loss U = -8794.231, Fit loss F = 302.295, KL loss = 24298.543\n",
      "Epoch:  7901/25000, lambda1_mu = 0.626, lambda2_mu = 0.005, lambda1_std = 0.004, lambda2_std = 0.007\n",
      "Epoch:  7901/25000, error_25 = 0.06808, error_train = 0.11958\n",
      "\n",
      "Epoch:  8001/25000, total loss = -1.889, Fit loss U = -9076.276, Fit loss F = 302.124, KL loss = 24324.705\n",
      "Epoch:  8001/25000, lambda1_mu = 0.627, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.007\n",
      "Epoch:  8001/25000, error_25 = 0.06764, error_train = 0.11912\n",
      "\n",
      "Epoch:  8101/25000, total loss = -1.839, Fit loss U = -8875.028, Fit loss F = 302.197, KL loss = 24353.600\n",
      "Epoch:  8101/25000, lambda1_mu = 0.633, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.007\n",
      "Epoch:  8101/25000, error_25 = 0.06350, error_train = 0.11768\n",
      "\n",
      "Epoch:  8201/25000, total loss = -1.958, Fit loss U = -9347.253, Fit loss F = 295.367, KL loss = 24383.555\n",
      "Epoch:  8201/25000, lambda1_mu = 0.635, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8201/25000, error_25 = 0.06755, error_train = 0.11465\n",
      "\n",
      "Epoch:  8301/25000, total loss = -1.964, Fit loss U = -9360.401, Fit loss F = 284.199, KL loss = 24411.191\n",
      "Epoch:  8301/25000, lambda1_mu = 0.639, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8301/25000, error_25 = 0.06756, error_train = 0.11510\n",
      "\n",
      "Epoch:  8401/25000, total loss = -1.990, Fit loss U = -9497.062, Fit loss F = 316.095, KL loss = 24437.936\n",
      "Epoch:  8401/25000, lambda1_mu = 0.644, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8401/25000, error_25 = 0.05973, error_train = 0.11218\n",
      "\n",
      "Epoch:  8501/25000, total loss = -1.883, Fit loss U = -9038.033, Fit loss F = 284.237, KL loss = 24465.385\n",
      "Epoch:  8501/25000, lambda1_mu = 0.646, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8501/25000, error_25 = 0.06221, error_train = 0.11303\n",
      "\n",
      "Epoch:  8601/25000, total loss = -1.969, Fit loss U = -9376.955, Fit loss F = 274.901, KL loss = 24490.658\n",
      "Epoch:  8601/25000, lambda1_mu = 0.651, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8601/25000, error_25 = 0.06167, error_train = 0.11214\n",
      "\n",
      "Epoch:  8701/25000, total loss = -2.023, Fit loss U = -9610.771, Fit loss F = 292.251, KL loss = 24512.479\n",
      "Epoch:  8701/25000, lambda1_mu = 0.651, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8701/25000, error_25 = 0.06508, error_train = 0.11182\n",
      "\n",
      "Epoch:  8801/25000, total loss = -2.049, Fit loss U = -9683.632, Fit loss F = 259.521, KL loss = 24536.527\n",
      "Epoch:  8801/25000, lambda1_mu = 0.655, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.006\n",
      "Epoch:  8801/25000, error_25 = 0.06803, error_train = 0.11271\n",
      "\n",
      "Epoch:  8901/25000, total loss = -2.019, Fit loss U = -9590.088, Fit loss F = 286.423, KL loss = 24559.504\n",
      "Epoch:  8901/25000, lambda1_mu = 0.658, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  8901/25000, error_25 = 0.06449, error_train = 0.11198\n",
      "\n",
      "Epoch:  9001/25000, total loss = -1.961, Fit loss U = -9355.397, Fit loss F = 280.617, KL loss = 24583.875\n",
      "Epoch:  9001/25000, lambda1_mu = 0.660, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9001/25000, error_25 = 0.06027, error_train = 0.10893\n",
      "\n",
      "Epoch:  9101/25000, total loss = -2.048, Fit loss U = -9703.053, Fit loss F = 280.664, KL loss = 24609.068\n",
      "Epoch:  9101/25000, lambda1_mu = 0.663, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9101/25000, error_25 = 0.06252, error_train = 0.10805\n",
      "\n",
      "Epoch:  9201/25000, total loss = -2.102, Fit loss U = -9912.444, Fit loss F = 273.341, KL loss = 24629.371\n",
      "Epoch:  9201/25000, lambda1_mu = 0.666, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9201/25000, error_25 = 0.06194, error_train = 0.10766\n",
      "\n",
      "Epoch:  9301/25000, total loss = -1.993, Fit loss U = -9487.218, Fit loss F = 283.370, KL loss = 24651.332\n",
      "Epoch:  9301/25000, lambda1_mu = 0.668, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9301/25000, error_25 = 0.06031, error_train = 0.10961\n",
      "\n",
      "Epoch:  9401/25000, total loss = -2.108, Fit loss U = -9931.760, Fit loss F = 266.987, KL loss = 24671.088\n",
      "Epoch:  9401/25000, lambda1_mu = 0.669, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9401/25000, error_25 = 0.06046, error_train = 0.10802\n",
      "\n",
      "Epoch:  9501/25000, total loss = -1.924, Fit loss U = -9207.171, Fit loss F = 275.240, KL loss = 24689.527\n",
      "Epoch:  9501/25000, lambda1_mu = 0.673, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9501/25000, error_25 = 0.05951, error_train = 0.10682\n",
      "\n",
      "Epoch:  9601/25000, total loss = -2.021, Fit loss U = -9595.793, Fit loss F = 274.992, KL loss = 24708.604\n",
      "Epoch:  9601/25000, lambda1_mu = 0.674, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9601/25000, error_25 = 0.06046, error_train = 0.10703\n",
      "\n",
      "Epoch:  9701/25000, total loss = -2.144, Fit loss U = -10062.152, Fit loss F = 251.098, KL loss = 24729.631\n",
      "Epoch:  9701/25000, lambda1_mu = 0.675, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9701/25000, error_25 = 0.06279, error_train = 0.10612\n",
      "\n",
      "Epoch:  9801/25000, total loss = -2.080, Fit loss U = -9814.684, Fit loss F = 259.176, KL loss = 24747.557\n",
      "Epoch:  9801/25000, lambda1_mu = 0.679, lambda2_mu = 0.005, lambda1_std = 0.003, lambda2_std = 0.005\n",
      "Epoch:  9801/25000, error_25 = 0.05906, error_train = 0.10502\n",
      "\n",
      "Epoch:  9901/25000, total loss = -2.096, Fit loss U = -9902.973, Fit loss F = 281.466, KL loss = 24769.043\n",
      "Epoch:  9901/25000, lambda1_mu = 0.681, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.005\n",
      "Epoch:  9901/25000, error_25 = 0.05825, error_train = 0.10602\n",
      "\n",
      "Epoch: 10001/25000, total loss = -2.113, Fit loss U = -9941.413, Fit loss F = 248.910, KL loss = 24785.031\n",
      "Epoch: 10001/25000, lambda1_mu = 0.684, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.005\n",
      "Epoch: 10001/25000, error_25 = 0.06607, error_train = 0.10851\n",
      "\n",
      "Epoch: 10101/25000, total loss = -2.149, Fit loss U = -10090.654, Fit loss F = 253.899, KL loss = 24803.564\n",
      "Epoch: 10101/25000, lambda1_mu = 0.686, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10101/25000, error_25 = 0.05748, error_train = 0.10342\n",
      "\n",
      "Epoch: 10201/25000, total loss = -2.115, Fit loss U = -9944.520, Fit loss F = 243.217, KL loss = 24820.186\n",
      "Epoch: 10201/25000, lambda1_mu = 0.688, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10201/25000, error_25 = 0.06146, error_train = 0.10492\n",
      "\n",
      "Epoch: 10301/25000, total loss = -2.185, Fit loss U = -10225.011, Fit loss F = 243.682, KL loss = 24836.047\n",
      "Epoch: 10301/25000, lambda1_mu = 0.690, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10301/25000, error_25 = 0.05816, error_train = 0.10503\n",
      "\n",
      "Epoch: 10401/25000, total loss = -2.252, Fit loss U = -10493.448, Fit loss F = 241.750, KL loss = 24853.053\n",
      "Epoch: 10401/25000, lambda1_mu = 0.691, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10401/25000, error_25 = 0.05961, error_train = 0.10419\n",
      "\n",
      "Epoch: 10501/25000, total loss = -2.235, Fit loss U = -10449.015, Fit loss F = 263.840, KL loss = 24869.838\n",
      "Epoch: 10501/25000, lambda1_mu = 0.694, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10501/25000, error_25 = 0.05651, error_train = 0.10368\n",
      "\n",
      "Epoch: 10601/25000, total loss = -2.120, Fit loss U = -9963.469, Fit loss F = 239.958, KL loss = 24883.111\n",
      "Epoch: 10601/25000, lambda1_mu = 0.699, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10601/25000, error_25 = 0.05941, error_train = 0.10311\n",
      "\n",
      "Epoch: 10701/25000, total loss = -2.223, Fit loss U = -10390.667, Fit loss F = 253.268, KL loss = 24898.652\n",
      "Epoch: 10701/25000, lambda1_mu = 0.699, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10701/25000, error_25 = 0.06087, error_train = 0.10273\n",
      "\n",
      "Epoch: 10801/25000, total loss = -2.241, Fit loss U = -10439.738, Fit loss F = 229.985, KL loss = 24911.725\n",
      "Epoch: 10801/25000, lambda1_mu = 0.702, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10801/25000, error_25 = 0.05817, error_train = 0.10300\n",
      "\n",
      "Epoch: 10901/25000, total loss = -2.213, Fit loss U = -10331.401, Fit loss F = 233.487, KL loss = 24926.939\n",
      "Epoch: 10901/25000, lambda1_mu = 0.702, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 10901/25000, error_25 = 0.05919, error_train = 0.10502\n",
      "\n",
      "Epoch: 11001/25000, total loss = -2.241, Fit loss U = -10446.331, Fit loss F = 235.390, KL loss = 24943.555\n",
      "Epoch: 11001/25000, lambda1_mu = 0.708, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11001/25000, error_25 = 0.05840, error_train = 0.10094\n",
      "\n",
      "Epoch: 11101/25000, total loss = -2.247, Fit loss U = -10468.162, Fit loss F = 231.172, KL loss = 24956.688\n",
      "Epoch: 11101/25000, lambda1_mu = 0.708, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11101/25000, error_25 = 0.05772, error_train = 0.10101\n",
      "\n",
      "Epoch: 11201/25000, total loss = -2.259, Fit loss U = -10520.646, Fit loss F = 235.108, KL loss = 24972.270\n",
      "Epoch: 11201/25000, lambda1_mu = 0.710, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11201/25000, error_25 = 0.06001, error_train = 0.10301\n",
      "\n",
      "Epoch: 11301/25000, total loss = -2.301, Fit loss U = -10680.284, Fit loss F = 228.140, KL loss = 24985.059\n",
      "Epoch: 11301/25000, lambda1_mu = 0.714, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11301/25000, error_25 = 0.05647, error_train = 0.10106\n",
      "\n",
      "Epoch: 11401/25000, total loss = -2.291, Fit loss U = -10627.381, Fit loss F = 215.221, KL loss = 24998.713\n",
      "Epoch: 11401/25000, lambda1_mu = 0.714, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11401/25000, error_25 = 0.05623, error_train = 0.10100\n",
      "\n",
      "Epoch: 11501/25000, total loss = -2.298, Fit loss U = -10673.407, Fit loss F = 229.304, KL loss = 25012.832\n",
      "Epoch: 11501/25000, lambda1_mu = 0.716, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11501/25000, error_25 = 0.05596, error_train = 0.09971\n",
      "\n",
      "Epoch: 11601/25000, total loss = -2.233, Fit loss U = -10411.083, Fit loss F = 226.323, KL loss = 25028.994\n",
      "Epoch: 11601/25000, lambda1_mu = 0.719, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.004\n",
      "Epoch: 11601/25000, error_25 = 0.05735, error_train = 0.09991\n",
      "\n",
      "Epoch: 11701/25000, total loss = -2.291, Fit loss U = -10649.314, Fit loss F = 233.383, KL loss = 25042.266\n",
      "Epoch: 11701/25000, lambda1_mu = 0.720, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 11701/25000, error_25 = 0.05444, error_train = 0.09969\n",
      "\n",
      "Epoch: 11801/25000, total loss = -2.308, Fit loss U = -10702.801, Fit loss F = 217.776, KL loss = 25054.312\n",
      "Epoch: 11801/25000, lambda1_mu = 0.722, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 11801/25000, error_25 = 0.05611, error_train = 0.10033\n",
      "\n",
      "Epoch: 11901/25000, total loss = -2.288, Fit loss U = -10636.920, Fit loss F = 230.948, KL loss = 25068.232\n",
      "Epoch: 11901/25000, lambda1_mu = 0.724, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 11901/25000, error_25 = 0.05662, error_train = 0.09910\n",
      "\n",
      "Epoch: 12001/25000, total loss = -2.332, Fit loss U = -10806.838, Fit loss F = 224.523, KL loss = 25078.158\n",
      "Epoch: 12001/25000, lambda1_mu = 0.729, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12001/25000, error_25 = 0.05585, error_train = 0.09875\n",
      "\n",
      "Epoch: 12101/25000, total loss = -2.294, Fit loss U = -10652.136, Fit loss F = 220.487, KL loss = 25088.816\n",
      "Epoch: 12101/25000, lambda1_mu = 0.731, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12101/25000, error_25 = 0.05608, error_train = 0.10003\n",
      "\n",
      "Epoch: 12201/25000, total loss = -2.344, Fit loss U = -10853.146, Fit loss F = 222.889, KL loss = 25098.135\n",
      "Epoch: 12201/25000, lambda1_mu = 0.732, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12201/25000, error_25 = 0.05653, error_train = 0.09959\n",
      "\n",
      "Epoch: 12301/25000, total loss = -2.298, Fit loss U = -10667.241, Fit loss F = 217.738, KL loss = 25110.131\n",
      "Epoch: 12301/25000, lambda1_mu = 0.734, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12301/25000, error_25 = 0.05478, error_train = 0.09832\n",
      "\n",
      "Epoch: 12401/25000, total loss = -2.362, Fit loss U = -10918.986, Fit loss F = 214.597, KL loss = 25122.863\n",
      "Epoch: 12401/25000, lambda1_mu = 0.738, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12401/25000, error_25 = 0.05510, error_train = 0.10039\n",
      "\n",
      "Epoch: 12501/25000, total loss = -2.405, Fit loss U = -11093.025, Fit loss F = 216.505, KL loss = 25134.215\n",
      "Epoch: 12501/25000, lambda1_mu = 0.738, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12501/25000, error_25 = 0.05525, error_train = 0.09943\n",
      "\n",
      "Epoch: 12601/25000, total loss = -2.361, Fit loss U = -10918.111, Fit loss F = 216.639, KL loss = 25146.863\n",
      "Epoch: 12601/25000, lambda1_mu = 0.740, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12601/25000, error_25 = 0.05387, error_train = 0.09824\n",
      "\n",
      "Epoch: 12701/25000, total loss = -2.396, Fit loss U = -11045.581, Fit loss F = 204.052, KL loss = 25155.957\n",
      "Epoch: 12701/25000, lambda1_mu = 0.744, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12701/25000, error_25 = 0.05518, error_train = 0.09838\n",
      "\n",
      "Epoch: 12801/25000, total loss = -2.322, Fit loss U = -10747.099, Fit loss F = 200.190, KL loss = 25164.730\n",
      "Epoch: 12801/25000, lambda1_mu = 0.747, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12801/25000, error_25 = 0.05553, error_train = 0.09968\n",
      "\n",
      "Epoch: 12901/25000, total loss = -2.343, Fit loss U = -10832.035, Fit loss F = 202.418, KL loss = 25174.943\n",
      "Epoch: 12901/25000, lambda1_mu = 0.747, lambda2_mu = 0.005, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 12901/25000, error_25 = 0.05626, error_train = 0.09824\n",
      "\n",
      "Epoch: 13001/25000, total loss = -2.421, Fit loss U = -11151.987, Fit loss F = 208.149, KL loss = 25183.307\n",
      "Epoch: 13001/25000, lambda1_mu = 0.750, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13001/25000, error_25 = 0.05534, error_train = 0.09832\n",
      "\n",
      "Epoch: 13101/25000, total loss = -2.347, Fit loss U = -10849.564, Fit loss F = 203.056, KL loss = 25192.512\n",
      "Epoch: 13101/25000, lambda1_mu = 0.753, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13101/25000, error_25 = 0.05323, error_train = 0.09719\n",
      "\n",
      "Epoch: 13201/25000, total loss = -2.423, Fit loss U = -11155.862, Fit loss F = 201.865, KL loss = 25203.029\n",
      "Epoch: 13201/25000, lambda1_mu = 0.752, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13201/25000, error_25 = 0.05636, error_train = 0.09971\n",
      "\n",
      "Epoch: 13301/25000, total loss = -2.389, Fit loss U = -11009.500, Fit loss F = 193.200, KL loss = 25213.854\n",
      "Epoch: 13301/25000, lambda1_mu = 0.757, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13301/25000, error_25 = 0.05283, error_train = 0.09701\n",
      "\n",
      "Epoch: 13401/25000, total loss = -2.457, Fit loss U = -11285.601, Fit loss F = 197.845, KL loss = 25221.209\n",
      "Epoch: 13401/25000, lambda1_mu = 0.758, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13401/25000, error_25 = 0.05267, error_train = 0.09702\n",
      "\n",
      "Epoch: 13501/25000, total loss = -2.384, Fit loss U = -10991.374, Fit loss F = 195.872, KL loss = 25228.387\n",
      "Epoch: 13501/25000, lambda1_mu = 0.761, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13501/25000, error_25 = 0.05470, error_train = 0.09809\n",
      "\n",
      "Epoch: 13601/25000, total loss = -2.431, Fit loss U = -11189.375, Fit loss F = 204.182, KL loss = 25238.068\n",
      "Epoch: 13601/25000, lambda1_mu = 0.763, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13601/25000, error_25 = 0.05329, error_train = 0.09873\n",
      "\n",
      "Epoch: 13701/25000, total loss = -2.376, Fit loss U = -10963.566, Fit loss F = 196.039, KL loss = 25245.346\n",
      "Epoch: 13701/25000, lambda1_mu = 0.763, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13701/25000, error_25 = 0.05382, error_train = 0.09555\n",
      "\n",
      "Epoch: 13801/25000, total loss = -2.408, Fit loss U = -11078.523, Fit loss F = 185.462, KL loss = 25250.979\n",
      "Epoch: 13801/25000, lambda1_mu = 0.766, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13801/25000, error_25 = 0.05349, error_train = 0.09636\n",
      "\n",
      "Epoch: 13901/25000, total loss = -2.423, Fit loss U = -11146.348, Fit loss F = 191.826, KL loss = 25256.615\n",
      "Epoch: 13901/25000, lambda1_mu = 0.767, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 13901/25000, error_25 = 0.05195, error_train = 0.09552\n",
      "\n",
      "Epoch: 14001/25000, total loss = -2.398, Fit loss U = -11029.665, Fit loss F = 173.501, KL loss = 25263.693\n",
      "Epoch: 14001/25000, lambda1_mu = 0.770, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14001/25000, error_25 = 0.05202, error_train = 0.09679\n",
      "\n",
      "Epoch: 14101/25000, total loss = -2.442, Fit loss U = -11214.639, Fit loss F = 183.785, KL loss = 25268.131\n",
      "Epoch: 14101/25000, lambda1_mu = 0.773, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14101/25000, error_25 = 0.05284, error_train = 0.09822\n",
      "\n",
      "Epoch: 14201/25000, total loss = -2.475, Fit loss U = -11343.026, Fit loss F = 180.122, KL loss = 25275.623\n",
      "Epoch: 14201/25000, lambda1_mu = 0.773, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14201/25000, error_25 = 0.05141, error_train = 0.09538\n",
      "\n",
      "Epoch: 14301/25000, total loss = -2.450, Fit loss U = -11242.394, Fit loss F = 178.593, KL loss = 25281.975\n",
      "Epoch: 14301/25000, lambda1_mu = 0.778, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14301/25000, error_25 = 0.05139, error_train = 0.09488\n",
      "\n",
      "Epoch: 14401/25000, total loss = -2.483, Fit loss U = -11375.602, Fit loss F = 177.355, KL loss = 25288.354\n",
      "Epoch: 14401/25000, lambda1_mu = 0.780, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14401/25000, error_25 = 0.05219, error_train = 0.09829\n",
      "\n",
      "Epoch: 14501/25000, total loss = -2.506, Fit loss U = -11468.615, Fit loss F = 179.153, KL loss = 25290.861\n",
      "Epoch: 14501/25000, lambda1_mu = 0.781, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14501/25000, error_25 = 0.05165, error_train = 0.09546\n",
      "\n",
      "Epoch: 14601/25000, total loss = -2.517, Fit loss U = -11508.747, Fit loss F = 175.037, KL loss = 25296.988\n",
      "Epoch: 14601/25000, lambda1_mu = 0.783, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14601/25000, error_25 = 0.05153, error_train = 0.09663\n",
      "\n",
      "Epoch: 14701/25000, total loss = -2.513, Fit loss U = -11488.929, Fit loss F = 169.823, KL loss = 25303.959\n",
      "Epoch: 14701/25000, lambda1_mu = 0.786, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14701/25000, error_25 = 0.05171, error_train = 0.09648\n",
      "\n",
      "Epoch: 14801/25000, total loss = -2.498, Fit loss U = -11433.967, Fit loss F = 175.886, KL loss = 25306.123\n",
      "Epoch: 14801/25000, lambda1_mu = 0.787, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 14801/25000, error_25 = 0.05177, error_train = 0.09465\n",
      "\n",
      "Epoch: 14901/25000, total loss = -2.571, Fit loss U = -11728.419, Fit loss F = 177.560, KL loss = 25310.197\n",
      "Epoch: 14901/25000, lambda1_mu = 0.789, lambda2_mu = 0.006, lambda1_std = 0.001, lambda2_std = 0.003\n",
      "Epoch: 14901/25000, error_25 = 0.05237, error_train = 0.09483\n",
      "\n",
      "Epoch: 15001/25000, total loss = -2.540, Fit loss U = -11589.622, Fit loss F = 165.250, KL loss = 25314.189\n",
      "Epoch: 15001/25000, lambda1_mu = 0.790, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 15001/25000, error_25 = 0.05070, error_train = 0.09680\n",
      "\n",
      "Epoch: 15101/25000, total loss = -2.517, Fit loss U = -11501.146, Fit loss F = 168.146, KL loss = 25317.986\n",
      "Epoch: 15101/25000, lambda1_mu = 0.794, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.003\n",
      "Epoch: 15101/25000, error_25 = 0.05146, error_train = 0.09672\n",
      "\n",
      "Epoch: 15201/25000, total loss = -2.482, Fit loss U = -11366.431, Fit loss F = 171.895, KL loss = 25320.826\n",
      "Epoch: 15201/25000, lambda1_mu = 0.795, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15201/25000, error_25 = 0.05087, error_train = 0.09367\n",
      "\n",
      "Epoch: 15301/25000, total loss = -2.500, Fit loss U = -11426.555, Fit loss F = 160.258, KL loss = 25323.244\n",
      "Epoch: 15301/25000, lambda1_mu = 0.798, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15301/25000, error_25 = 0.05216, error_train = 0.09589\n",
      "\n",
      "Epoch: 15401/25000, total loss = -2.478, Fit loss U = -11346.216, Fit loss F = 166.562, KL loss = 25323.410\n",
      "Epoch: 15401/25000, lambda1_mu = 0.800, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15401/25000, error_25 = 0.05048, error_train = 0.09479\n",
      "\n",
      "Epoch: 15501/25000, total loss = -2.527, Fit loss U = -11534.706, Fit loss F = 162.035, KL loss = 25325.365\n",
      "Epoch: 15501/25000, lambda1_mu = 0.800, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15501/25000, error_25 = 0.05144, error_train = 0.09419\n",
      "\n",
      "Epoch: 15601/25000, total loss = -2.473, Fit loss U = -11324.955, Fit loss F = 166.603, KL loss = 25326.219\n",
      "Epoch: 15601/25000, lambda1_mu = 0.804, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15601/25000, error_25 = 0.05235, error_train = 0.09631\n",
      "\n",
      "Epoch: 15701/25000, total loss = -2.542, Fit loss U = -11593.026, Fit loss F = 160.193, KL loss = 25326.469\n",
      "Epoch: 15701/25000, lambda1_mu = 0.805, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15701/25000, error_25 = 0.05013, error_train = 0.09585\n",
      "\n",
      "Epoch: 15801/25000, total loss = -2.516, Fit loss U = -11491.936, Fit loss F = 160.869, KL loss = 25329.338\n",
      "Epoch: 15801/25000, lambda1_mu = 0.807, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15801/25000, error_25 = 0.05049, error_train = 0.09345\n",
      "\n",
      "Epoch: 15901/25000, total loss = -2.576, Fit loss U = -11727.730, Fit loss F = 157.779, KL loss = 25333.701\n",
      "Epoch: 15901/25000, lambda1_mu = 0.810, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 15901/25000, error_25 = 0.05074, error_train = 0.09377\n",
      "\n",
      "Epoch: 16001/25000, total loss = -2.572, Fit loss U = -11709.533, Fit loss F = 153.756, KL loss = 25333.277\n",
      "Epoch: 16001/25000, lambda1_mu = 0.811, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 16001/25000, error_25 = 0.05036, error_train = 0.09460\n",
      "\n",
      "Epoch: 16101/25000, total loss = -2.590, Fit loss U = -11778.355, Fit loss F = 151.650, KL loss = 25337.508\n",
      "Epoch: 16101/25000, lambda1_mu = 0.816, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 16101/25000, error_25 = 0.05002, error_train = 0.09480\n",
      "\n",
      "Epoch: 16201/25000, total loss = -2.541, Fit loss U = -11591.253, Fit loss F = 160.417, KL loss = 25339.553\n",
      "Epoch: 16201/25000, lambda1_mu = 0.815, lambda2_mu = 0.006, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 16201/25000, error_25 = 0.05090, error_train = 0.09556\n",
      "\n",
      "Epoch: 16301/25000, total loss = -2.616, Fit loss U = -11885.136, Fit loss F = 153.931, KL loss = 25341.932\n",
      "Epoch: 16301/25000, lambda1_mu = 0.818, lambda2_mu = 0.006, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16301/25000, error_25 = 0.04965, error_train = 0.09443\n",
      "\n",
      "Epoch: 16401/25000, total loss = -2.611, Fit loss U = -11857.911, Fit loss F = 146.787, KL loss = 25344.240\n",
      "Epoch: 16401/25000, lambda1_mu = 0.821, lambda2_mu = 0.006, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16401/25000, error_25 = 0.05017, error_train = 0.09510\n",
      "\n",
      "Epoch: 16501/25000, total loss = -2.598, Fit loss U = -11807.368, Fit loss F = 148.005, KL loss = 25344.152\n",
      "Epoch: 16501/25000, lambda1_mu = 0.822, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16501/25000, error_25 = 0.04957, error_train = 0.09453\n",
      "\n",
      "Epoch: 16601/25000, total loss = -2.590, Fit loss U = -11774.173, Fit loss F = 146.998, KL loss = 25345.494\n",
      "Epoch: 16601/25000, lambda1_mu = 0.824, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16601/25000, error_25 = 0.04993, error_train = 0.09516\n",
      "\n",
      "Epoch: 16701/25000, total loss = -2.619, Fit loss U = -11885.045, Fit loss F = 141.030, KL loss = 25350.244\n",
      "Epoch: 16701/25000, lambda1_mu = 0.829, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16701/25000, error_25 = 0.05031, error_train = 0.09510\n",
      "\n",
      "Epoch: 16801/25000, total loss = -2.607, Fit loss U = -11839.848, Fit loss F = 144.003, KL loss = 25352.594\n",
      "Epoch: 16801/25000, lambda1_mu = 0.829, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16801/25000, error_25 = 0.04991, error_train = 0.09550\n",
      "\n",
      "Epoch: 16901/25000, total loss = -2.605, Fit loss U = -11835.906, Fit loss F = 147.804, KL loss = 25352.299\n",
      "Epoch: 16901/25000, lambda1_mu = 0.832, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 16901/25000, error_25 = 0.05016, error_train = 0.09377\n",
      "\n",
      "Epoch: 17001/25000, total loss = -2.565, Fit loss U = -11668.957, Fit loss F = 142.557, KL loss = 25353.434\n",
      "Epoch: 17001/25000, lambda1_mu = 0.833, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17001/25000, error_25 = 0.05144, error_train = 0.09374\n",
      "\n",
      "Epoch: 17101/25000, total loss = -2.583, Fit loss U = -11736.386, Fit loss F = 136.569, KL loss = 25350.932\n",
      "Epoch: 17101/25000, lambda1_mu = 0.836, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17101/25000, error_25 = 0.04973, error_train = 0.09247\n",
      "\n",
      "Epoch: 17201/25000, total loss = -2.616, Fit loss U = -11874.357, Fit loss F = 141.314, KL loss = 25351.227\n",
      "Epoch: 17201/25000, lambda1_mu = 0.837, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17201/25000, error_25 = 0.05018, error_train = 0.09350\n",
      "\n",
      "Epoch: 17301/25000, total loss = -2.614, Fit loss U = -11861.211, Fit loss F = 139.312, KL loss = 25352.850\n",
      "Epoch: 17301/25000, lambda1_mu = 0.838, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17301/25000, error_25 = 0.04916, error_train = 0.09467\n",
      "\n",
      "Epoch: 17401/25000, total loss = -2.663, Fit loss U = -12056.076, Fit loss F = 138.368, KL loss = 25350.975\n",
      "Epoch: 17401/25000, lambda1_mu = 0.840, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17401/25000, error_25 = 0.05002, error_train = 0.09329\n",
      "\n",
      "Epoch: 17501/25000, total loss = -2.627, Fit loss U = -11911.487, Fit loss F = 136.673, KL loss = 25350.217\n",
      "Epoch: 17501/25000, lambda1_mu = 0.843, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17501/25000, error_25 = 0.04947, error_train = 0.09305\n",
      "\n",
      "Epoch: 17601/25000, total loss = -2.636, Fit loss U = -11947.362, Fit loss F = 137.150, KL loss = 25345.668\n",
      "Epoch: 17601/25000, lambda1_mu = 0.844, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17601/25000, error_25 = 0.05027, error_train = 0.09162\n",
      "\n",
      "Epoch: 17701/25000, total loss = -2.664, Fit loss U = -12062.233, Fit loss F = 137.828, KL loss = 25344.750\n",
      "Epoch: 17701/25000, lambda1_mu = 0.845, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17701/25000, error_25 = 0.04944, error_train = 0.09397\n",
      "\n",
      "Epoch: 17801/25000, total loss = -2.591, Fit loss U = -11764.750, Fit loss F = 133.546, KL loss = 25340.934\n",
      "Epoch: 17801/25000, lambda1_mu = 0.847, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17801/25000, error_25 = 0.04892, error_train = 0.09489\n",
      "\n",
      "Epoch: 17901/25000, total loss = -2.603, Fit loss U = -11810.444, Fit loss F = 132.877, KL loss = 25338.873\n",
      "Epoch: 17901/25000, lambda1_mu = 0.849, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 17901/25000, error_25 = 0.04875, error_train = 0.09338\n",
      "\n",
      "Epoch: 18001/25000, total loss = -2.680, Fit loss U = -12120.970, Fit loss F = 135.752, KL loss = 25338.086\n",
      "Epoch: 18001/25000, lambda1_mu = 0.852, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18001/25000, error_25 = 0.04884, error_train = 0.09293\n",
      "\n",
      "Epoch: 18101/25000, total loss = -2.675, Fit loss U = -12099.567, Fit loss F = 131.127, KL loss = 25332.152\n",
      "Epoch: 18101/25000, lambda1_mu = 0.853, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18101/25000, error_25 = 0.04972, error_train = 0.09172\n",
      "\n",
      "Epoch: 18201/25000, total loss = -2.616, Fit loss U = -11866.933, Fit loss F = 136.559, KL loss = 25327.373\n",
      "Epoch: 18201/25000, lambda1_mu = 0.855, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18201/25000, error_25 = 0.04903, error_train = 0.09370\n",
      "\n",
      "Epoch: 18301/25000, total loss = -2.685, Fit loss U = -12134.040, Fit loss F = 128.634, KL loss = 25323.260\n",
      "Epoch: 18301/25000, lambda1_mu = 0.855, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18301/25000, error_25 = 0.04880, error_train = 0.09532\n",
      "\n",
      "Epoch: 18401/25000, total loss = -2.698, Fit loss U = -12185.265, Fit loss F = 126.983, KL loss = 25320.324\n",
      "Epoch: 18401/25000, lambda1_mu = 0.859, lambda2_mu = 0.007, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 18401/25000, error_25 = 0.04834, error_train = 0.09319\n",
      "\n",
      "Epoch: 18501/25000, total loss = -2.667, Fit loss U = -12066.254, Fit loss F = 131.271, KL loss = 25325.189\n",
      "Epoch: 18501/25000, lambda1_mu = 0.859, lambda2_mu = 0.007, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 18501/25000, error_25 = 0.04857, error_train = 0.09394\n",
      "\n",
      "Epoch: 18601/25000, total loss = -2.657, Fit loss U = -12027.468, Fit loss F = 133.258, KL loss = 25320.760\n",
      "Epoch: 18601/25000, lambda1_mu = 0.860, lambda2_mu = 0.007, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 18601/25000, error_25 = 0.04836, error_train = 0.09490\n",
      "\n",
      "Epoch: 18701/25000, total loss = -2.652, Fit loss U = -11999.986, Fit loss F = 127.558, KL loss = 25317.980\n",
      "Epoch: 18701/25000, lambda1_mu = 0.862, lambda2_mu = 0.007, lambda1_std = 0.002, lambda2_std = 0.002\n",
      "Epoch: 18701/25000, error_25 = 0.04842, error_train = 0.09308\n",
      "\n",
      "Epoch: 18801/25000, total loss = -2.719, Fit loss U = -12264.808, Fit loss F = 124.767, KL loss = 25315.354\n",
      "Epoch: 18801/25000, lambda1_mu = 0.865, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18801/25000, error_25 = 0.04852, error_train = 0.09289\n",
      "\n",
      "Epoch: 18901/25000, total loss = -2.703, Fit loss U = -12200.795, Fit loss F = 124.755, KL loss = 25311.809\n",
      "Epoch: 18901/25000, lambda1_mu = 0.865, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 18901/25000, error_25 = 0.04873, error_train = 0.09605\n",
      "\n",
      "Epoch: 19001/25000, total loss = -2.652, Fit loss U = -11997.212, Fit loss F = 123.732, KL loss = 25309.512\n",
      "Epoch: 19001/25000, lambda1_mu = 0.868, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19001/25000, error_25 = 0.04862, error_train = 0.09330\n",
      "\n",
      "Epoch: 19101/25000, total loss = -2.662, Fit loss U = -12036.670, Fit loss F = 123.538, KL loss = 25309.719\n",
      "Epoch: 19101/25000, lambda1_mu = 0.869, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19101/25000, error_25 = 0.04829, error_train = 0.09568\n",
      "\n",
      "Epoch: 19201/25000, total loss = -2.696, Fit loss U = -12175.974, Fit loss F = 127.268, KL loss = 25307.213\n",
      "Epoch: 19201/25000, lambda1_mu = 0.872, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19201/25000, error_25 = 0.04925, error_train = 0.09382\n",
      "\n",
      "Epoch: 19301/25000, total loss = -2.687, Fit loss U = -12139.013, Fit loss F = 124.086, KL loss = 25302.260\n",
      "Epoch: 19301/25000, lambda1_mu = 0.872, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19301/25000, error_25 = 0.04874, error_train = 0.09315\n",
      "\n",
      "Epoch: 19401/25000, total loss = -2.714, Fit loss U = -12249.450, Fit loss F = 130.457, KL loss = 25296.859\n",
      "Epoch: 19401/25000, lambda1_mu = 0.874, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19401/25000, error_25 = 0.04857, error_train = 0.09390\n",
      "\n",
      "Epoch: 19501/25000, total loss = -2.689, Fit loss U = -12141.997, Fit loss F = 121.125, KL loss = 25294.336\n",
      "Epoch: 19501/25000, lambda1_mu = 0.875, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19501/25000, error_25 = 0.04832, error_train = 0.09661\n",
      "\n",
      "Epoch: 19601/25000, total loss = -2.727, Fit loss U = -12293.331, Fit loss F = 121.701, KL loss = 25286.127\n",
      "Epoch: 19601/25000, lambda1_mu = 0.877, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19601/25000, error_25 = 0.04806, error_train = 0.09530\n",
      "\n",
      "Epoch: 19701/25000, total loss = -2.731, Fit loss U = -12308.677, Fit loss F = 122.136, KL loss = 25281.707\n",
      "Epoch: 19701/25000, lambda1_mu = 0.878, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19701/25000, error_25 = 0.04883, error_train = 0.09342\n",
      "\n",
      "Epoch: 19801/25000, total loss = -2.730, Fit loss U = -12306.104, Fit loss F = 121.622, KL loss = 25282.129\n",
      "Epoch: 19801/25000, lambda1_mu = 0.880, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19801/25000, error_25 = 0.04779, error_train = 0.09528\n",
      "\n",
      "Epoch: 19901/25000, total loss = -2.686, Fit loss U = -12129.604, Fit loss F = 121.282, KL loss = 25275.998\n",
      "Epoch: 19901/25000, lambda1_mu = 0.881, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 19901/25000, error_25 = 0.04785, error_train = 0.09304\n",
      "\n",
      "Epoch: 20001/25000, total loss = -2.705, Fit loss U = -12200.970, Fit loss F = 118.277, KL loss = 25272.299\n",
      "Epoch: 20001/25000, lambda1_mu = 0.886, lambda2_mu = 0.007, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20001/25000, error_25 = 0.04805, error_train = 0.09435\n",
      "\n",
      "Epoch: 20101/25000, total loss = -2.732, Fit loss U = -12312.699, Fit loss F = 123.205, KL loss = 25266.924\n",
      "Epoch: 20101/25000, lambda1_mu = 0.884, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20101/25000, error_25 = 0.04780, error_train = 0.09209\n",
      "\n",
      "Epoch: 20201/25000, total loss = -2.734, Fit loss U = -12321.459, Fit loss F = 121.530, KL loss = 25260.111\n",
      "Epoch: 20201/25000, lambda1_mu = 0.884, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20201/25000, error_25 = 0.04835, error_train = 0.09500\n",
      "\n",
      "Epoch: 20301/25000, total loss = -2.756, Fit loss U = -12404.490, Fit loss F = 117.191, KL loss = 25258.189\n",
      "Epoch: 20301/25000, lambda1_mu = 0.888, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20301/25000, error_25 = 0.04796, error_train = 0.09254\n",
      "\n",
      "Epoch: 20401/25000, total loss = -2.714, Fit loss U = -12237.977, Fit loss F = 118.148, KL loss = 25254.607\n",
      "Epoch: 20401/25000, lambda1_mu = 0.888, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20401/25000, error_25 = 0.04773, error_train = 0.09355\n",
      "\n",
      "Epoch: 20501/25000, total loss = -2.716, Fit loss U = -12248.661, Fit loss F = 120.496, KL loss = 25254.377\n",
      "Epoch: 20501/25000, lambda1_mu = 0.890, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20501/25000, error_25 = 0.04831, error_train = 0.09610\n",
      "\n",
      "Epoch: 20601/25000, total loss = -2.772, Fit loss U = -12467.545, Fit loss F = 115.770, KL loss = 25256.752\n",
      "Epoch: 20601/25000, lambda1_mu = 0.890, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20601/25000, error_25 = 0.04786, error_train = 0.09430\n",
      "\n",
      "Epoch: 20701/25000, total loss = -2.719, Fit loss U = -12254.379, Fit loss F = 117.745, KL loss = 25251.947\n",
      "Epoch: 20701/25000, lambda1_mu = 0.892, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20701/25000, error_25 = 0.04809, error_train = 0.09572\n",
      "\n",
      "Epoch: 20801/25000, total loss = -2.729, Fit loss U = -12297.056, Fit loss F = 119.122, KL loss = 25248.508\n",
      "Epoch: 20801/25000, lambda1_mu = 0.892, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20801/25000, error_25 = 0.04757, error_train = 0.09377\n",
      "\n",
      "Epoch: 20901/25000, total loss = -2.780, Fit loss U = -12501.577, Fit loss F = 118.239, KL loss = 25244.451\n",
      "Epoch: 20901/25000, lambda1_mu = 0.894, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 20901/25000, error_25 = 0.04811, error_train = 0.09415\n",
      "\n",
      "Epoch: 21001/25000, total loss = -2.731, Fit loss U = -12301.095, Fit loss F = 113.893, KL loss = 25244.572\n",
      "Epoch: 21001/25000, lambda1_mu = 0.896, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21001/25000, error_25 = 0.04763, error_train = 0.09318\n",
      "\n",
      "Epoch: 21101/25000, total loss = -2.776, Fit loss U = -12480.776, Fit loss F = 113.602, KL loss = 25241.613\n",
      "Epoch: 21101/25000, lambda1_mu = 0.898, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21101/25000, error_25 = 0.04771, error_train = 0.09297\n",
      "\n",
      "Epoch: 21201/25000, total loss = -2.748, Fit loss U = -12368.155, Fit loss F = 113.155, KL loss = 25239.557\n",
      "Epoch: 21201/25000, lambda1_mu = 0.899, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21201/25000, error_25 = 0.04810, error_train = 0.09586\n",
      "\n",
      "Epoch: 21301/25000, total loss = -2.726, Fit loss U = -12275.538, Fit loss F = 111.622, KL loss = 25235.600\n",
      "Epoch: 21301/25000, lambda1_mu = 0.899, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21301/25000, error_25 = 0.04772, error_train = 0.09338\n",
      "\n",
      "Epoch: 21401/25000, total loss = -2.737, Fit loss U = -12322.165, Fit loss F = 112.162, KL loss = 25231.822\n",
      "Epoch: 21401/25000, lambda1_mu = 0.899, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21401/25000, error_25 = 0.04883, error_train = 0.09382\n",
      "\n",
      "Epoch: 21501/25000, total loss = -2.781, Fit loss U = -12497.096, Fit loss F = 111.665, KL loss = 25228.033\n",
      "Epoch: 21501/25000, lambda1_mu = 0.901, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21501/25000, error_25 = 0.04856, error_train = 0.09563\n",
      "\n",
      "Epoch: 21601/25000, total loss = -2.764, Fit loss U = -12427.763, Fit loss F = 110.068, KL loss = 25216.137\n",
      "Epoch: 21601/25000, lambda1_mu = 0.902, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21601/25000, error_25 = 0.04777, error_train = 0.09167\n",
      "\n",
      "Epoch: 21701/25000, total loss = -2.760, Fit loss U = -12414.887, Fit loss F = 113.113, KL loss = 25209.166\n",
      "Epoch: 21701/25000, lambda1_mu = 0.903, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21701/25000, error_25 = 0.04772, error_train = 0.09513\n",
      "\n",
      "Epoch: 21801/25000, total loss = -2.758, Fit loss U = -12402.628, Fit loss F = 112.185, KL loss = 25202.098\n",
      "Epoch: 21801/25000, lambda1_mu = 0.905, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21801/25000, error_25 = 0.04776, error_train = 0.09370\n",
      "\n",
      "Epoch: 21901/25000, total loss = -2.788, Fit loss U = -12522.847, Fit loss F = 110.737, KL loss = 25197.879\n",
      "Epoch: 21901/25000, lambda1_mu = 0.904, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 21901/25000, error_25 = 0.04810, error_train = 0.09333\n",
      "\n",
      "Epoch: 22001/25000, total loss = -2.778, Fit loss U = -12484.246, Fit loss F = 111.095, KL loss = 25197.723\n",
      "Epoch: 22001/25000, lambda1_mu = 0.906, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22001/25000, error_25 = 0.04751, error_train = 0.09454\n",
      "\n",
      "Epoch: 22101/25000, total loss = -2.788, Fit loss U = -12521.042, Fit loss F = 110.930, KL loss = 25199.439\n",
      "Epoch: 22101/25000, lambda1_mu = 0.907, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22101/25000, error_25 = 0.04835, error_train = 0.09502\n",
      "\n",
      "Epoch: 22201/25000, total loss = -2.784, Fit loss U = -12504.698, Fit loss F = 110.096, KL loss = 25199.764\n",
      "Epoch: 22201/25000, lambda1_mu = 0.910, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22201/25000, error_25 = 0.04805, error_train = 0.09377\n",
      "\n",
      "Epoch: 22301/25000, total loss = -2.805, Fit loss U = -12587.439, Fit loss F = 109.766, KL loss = 25192.885\n",
      "Epoch: 22301/25000, lambda1_mu = 0.912, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22301/25000, error_25 = 0.04791, error_train = 0.09360\n",
      "\n",
      "Epoch: 22401/25000, total loss = -2.800, Fit loss U = -12569.058, Fit loss F = 108.415, KL loss = 25194.893\n",
      "Epoch: 22401/25000, lambda1_mu = 0.909, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22401/25000, error_25 = 0.04865, error_train = 0.09062\n",
      "\n",
      "Epoch: 22501/25000, total loss = -2.815, Fit loss U = -12627.655, Fit loss F = 108.642, KL loss = 25184.949\n",
      "Epoch: 22501/25000, lambda1_mu = 0.912, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22501/25000, error_25 = 0.04820, error_train = 0.09278\n",
      "\n",
      "Epoch: 22601/25000, total loss = -2.784, Fit loss U = -12500.687, Fit loss F = 106.265, KL loss = 25179.291\n",
      "Epoch: 22601/25000, lambda1_mu = 0.913, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22601/25000, error_25 = 0.04785, error_train = 0.09290\n",
      "\n",
      "Epoch: 22701/25000, total loss = -2.792, Fit loss U = -12535.081, Fit loss F = 107.184, KL loss = 25178.836\n",
      "Epoch: 22701/25000, lambda1_mu = 0.914, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22701/25000, error_25 = 0.04785, error_train = 0.09357\n",
      "\n",
      "Epoch: 22801/25000, total loss = -2.758, Fit loss U = -12397.338, Fit loss F = 107.124, KL loss = 25174.422\n",
      "Epoch: 22801/25000, lambda1_mu = 0.914, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22801/25000, error_25 = 0.04811, error_train = 0.09526\n",
      "\n",
      "Epoch: 22901/25000, total loss = -2.785, Fit loss U = -12505.035, Fit loss F = 104.882, KL loss = 25173.490\n",
      "Epoch: 22901/25000, lambda1_mu = 0.916, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 22901/25000, error_25 = 0.04861, error_train = 0.09144\n",
      "\n",
      "Epoch: 23001/25000, total loss = -2.803, Fit loss U = -12578.155, Fit loss F = 107.831, KL loss = 25173.754\n",
      "Epoch: 23001/25000, lambda1_mu = 0.916, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23001/25000, error_25 = 0.04785, error_train = 0.09427\n",
      "\n",
      "Epoch: 23101/25000, total loss = -2.804, Fit loss U = -12584.854, Fit loss F = 108.597, KL loss = 25171.793\n",
      "Epoch: 23101/25000, lambda1_mu = 0.918, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23101/25000, error_25 = 0.04826, error_train = 0.09376\n",
      "\n",
      "Epoch: 23201/25000, total loss = -2.807, Fit loss U = -12592.122, Fit loss F = 105.868, KL loss = 25171.260\n",
      "Epoch: 23201/25000, lambda1_mu = 0.919, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23201/25000, error_25 = 0.04816, error_train = 0.09499\n",
      "\n",
      "Epoch: 23301/25000, total loss = -2.827, Fit loss U = -12671.639, Fit loss F = 106.512, KL loss = 25162.631\n",
      "Epoch: 23301/25000, lambda1_mu = 0.919, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23301/25000, error_25 = 0.04781, error_train = 0.09176\n",
      "\n",
      "Epoch: 23401/25000, total loss = -2.759, Fit loss U = -12401.532, Fit loss F = 108.688, KL loss = 25163.016\n",
      "Epoch: 23401/25000, lambda1_mu = 0.919, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23401/25000, error_25 = 0.04793, error_train = 0.09093\n",
      "\n",
      "Epoch: 23501/25000, total loss = -2.815, Fit loss U = -12622.698, Fit loss F = 105.639, KL loss = 25158.967\n",
      "Epoch: 23501/25000, lambda1_mu = 0.920, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23501/25000, error_25 = 0.04840, error_train = 0.09240\n",
      "\n",
      "Epoch: 23601/25000, total loss = -2.810, Fit loss U = -12604.299, Fit loss F = 105.670, KL loss = 25154.641\n",
      "Epoch: 23601/25000, lambda1_mu = 0.922, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23601/25000, error_25 = 0.04781, error_train = 0.09286\n",
      "\n",
      "Epoch: 23701/25000, total loss = -2.812, Fit loss U = -12611.610, Fit loss F = 105.465, KL loss = 25147.420\n",
      "Epoch: 23701/25000, lambda1_mu = 0.921, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23701/25000, error_25 = 0.04770, error_train = 0.09016\n",
      "\n",
      "Epoch: 23801/25000, total loss = -2.839, Fit loss U = -12722.513, Fit loss F = 109.611, KL loss = 25150.555\n",
      "Epoch: 23801/25000, lambda1_mu = 0.922, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23801/25000, error_25 = 0.04844, error_train = 0.09442\n",
      "\n",
      "Epoch: 23901/25000, total loss = -2.719, Fit loss U = -12241.285, Fit loss F = 106.774, KL loss = 25155.475\n",
      "Epoch: 23901/25000, lambda1_mu = 0.922, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 23901/25000, error_25 = 0.04855, error_train = 0.09233\n",
      "\n",
      "Epoch: 24001/25000, total loss = -2.820, Fit loss U = -12641.483, Fit loss F = 104.508, KL loss = 25148.629\n",
      "Epoch: 24001/25000, lambda1_mu = 0.923, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 24001/25000, error_25 = 0.04805, error_train = 0.09254\n",
      "\n",
      "Epoch: 24101/25000, total loss = -2.819, Fit loss U = -12641.212, Fit loss F = 107.144, KL loss = 25143.812\n",
      "Epoch: 24101/25000, lambda1_mu = 0.925, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 24101/25000, error_25 = 0.04775, error_train = 0.09111\n",
      "\n",
      "Epoch: 24201/25000, total loss = -2.829, Fit loss U = -12674.337, Fit loss F = 103.551, KL loss = 25133.789\n",
      "Epoch: 24201/25000, lambda1_mu = 0.925, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 24201/25000, error_25 = 0.04826, error_train = 0.09243\n",
      "\n",
      "Epoch: 24301/25000, total loss = -2.847, Fit loss U = -12746.650, Fit loss F = 102.911, KL loss = 25126.598\n",
      "Epoch: 24301/25000, lambda1_mu = 0.925, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 24301/25000, error_25 = 0.04800, error_train = 0.09160\n",
      "\n",
      "Epoch: 24401/25000, total loss = -2.840, Fit loss U = -12720.511, Fit loss F = 103.878, KL loss = 25121.324\n",
      "Epoch: 24401/25000, lambda1_mu = 0.926, lambda2_mu = 0.008, lambda1_std = 0.001, lambda2_std = 0.002\n",
      "Epoch: 24401/25000, error_25 = 0.04771, error_train = 0.09055\n",
      "\n",
      "Epoch: 24501/25000, total loss = -2.840, Fit loss U = -12719.913, Fit loss F = 103.309, KL loss = 25115.186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m u_pred_25 \u001b[39m=\u001b[39m samples_25\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m error_25 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(target_25\u001b[39m-\u001b[39mu_pred_25, \u001b[39m2\u001b[39m)\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(target_25, \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m samples_train \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mpredict(X_u_train, \u001b[39m100\u001b[39;49m, net\u001b[39m.\u001b[39;49mnetwork)\n\u001b[1;32m     43\u001b[0m u_pred_train \u001b[39m=\u001b[39m samples_train\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     44\u001b[0m error_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(u_train\u001b[39m-\u001b[39mu_pred_train, \u001b[39m2\u001b[39m)\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(u_train, \u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 139\u001b[0m, in \u001b[0;36mBBP_Model_PINN.predict\u001b[0;34m(self, xt, no_sample, best_net)\u001b[0m\n\u001b[1;32m    137\u001b[0m     u_pred, _, \u001b[39m=\u001b[39m best_net(xt)\n\u001b[1;32m    138\u001b[0m     u_pred \u001b[39m=\u001b[39m u_pred\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_ub\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_lb) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_lb \u001b[39m# reverse scaling\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     sample\u001b[39m.\u001b[39mappend(u_pred\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(sample)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(comment = '_test3_with_singlevar')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    EU, EF, KL_loss, total_loss = net.fit(X, t, U, no_samples = 20)\n",
    "    \n",
    "    fit_loss_U_train[i] = EU.item()\n",
    "    fit_loss_F_train[i] = EF.item()\n",
    "    KL_loss_train[i] = KL_loss.item()\n",
    "    loss[i] = total_loss.item()\n",
    "\n",
    "    writer.add_scalar(\"loss/total_loss\", loss[i], i)\n",
    "    writer.add_scalar(\"loss/U_loss\", fit_loss_U_train[i], i)\n",
    "    writer.add_scalar(\"loss/F_loss\", fit_loss_F_train[i], i)\n",
    "    writer.add_scalar(\"loss/KL_loss\", KL_loss_train[i], i)\n",
    "    \n",
    "\n",
    "    if fit_loss_U_train[i] + fit_loss_F_train[i] < best_loss:\n",
    "        best_loss = fit_loss_U_train[i] + fit_loss_F_train[i]\n",
    "        best_net = copy.deepcopy(net.network)\n",
    "\n",
    "    if i % 100 == 0 or i == num_epochs - 1:\n",
    "\n",
    "        print(\"Epoch: {:5d}/{:5d}, total loss = {:.3f}, Fit loss U = {:.3f}, Fit loss F = {:.3f}, KL loss = {:.3f}\".format(i + 1, num_epochs, \n",
    "               loss[i], fit_loss_U_train[i], fit_loss_F_train[i], KL_loss_train[i]))\n",
    "\n",
    "    \n",
    "        lambda1_mus = net.lambda1_mus.item()\n",
    "        lambda1_stds = torch.log(1 + torch.exp(net.lambda1_rhos)).item()\n",
    "        \n",
    "        lambda2_mus = np.exp(net.lambda2_mus.item())\n",
    "        lambda2_stds = torch.log(1 + torch.exp(net.lambda2_rhos)).item()\n",
    "\n",
    "        # noise_f = net.log_noise_u.exp().item()\n",
    "        # noise_u = net.log_noise_u.exp().item()\n",
    "        \n",
    "        samples_25 = net.predict(X_u_test_25, 100, net.network)\n",
    "        u_pred_25 = samples_25.mean(axis=0)\n",
    "        error_25 = np.linalg.norm(target_25-u_pred_25, 2)/np.linalg.norm(target_25, 2)\n",
    "\n",
    "        samples_train = net.predict(X_u_train, 100, net.network)\n",
    "        u_pred_train = samples_train.mean(axis=0)\n",
    "        error_train = np.linalg.norm(u_train-u_pred_train, 2)/np.linalg.norm(u_train, 2)\n",
    "\n",
    "\n",
    "        # writer.add_scalars(\"loss/train_test\", {'train':error_train, 'test':error_25}, i)\n",
    "        # writer.add_scalars(\"loss/f_u\", {'noise_f':noise_f, 'noise_u':noise_u}, i)\n",
    "       \n",
    "        print(\"Epoch: {:5d}/{:5d}, lambda1_mu = {:.3f}, lambda2_mu = {:.3f}, lambda1_std = {:.3f}, lambda2_std = {:.3f}\".format(i + 1, num_epochs,\n",
    "                                                                                                                        lambda1_mus, lambda2_mus,\n",
    "                                                                                                                        lambda1_stds, lambda2_stds))\n",
    "        print(\"Epoch: {:5d}/{:5d}, error_25 = {:.5f}, error_train = {:.5f}\".format(i+1, num_epochs, error_25, error_train))\n",
    "        # print(\"Epoch: {:5d}/{:5d}, noise_f = {:.5f}, noise_u = {:.5f}\".format(i+1, num_epochs, noise_f, noise_u))\n",
    "        print()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1, 1.1, -0.9590080097850915, 1.2409919902149087)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_u_test_25 = np.hstack([x, 0.25*np.ones_like((x))]); u_test_25 = Exact[25]\n",
    "X_u_test_50 = np.hstack([x, 0.50*np.ones_like((x))]); u_test_50 = Exact[50]\n",
    "X_u_test_75 = np.hstack([x, 0.75*np.ones_like((x))]); u_test_75 = Exact[75]\n",
    "\n",
    "\n",
    "def get_total_uncertainty(samples):\n",
    "    aleatoric = net.log_noise.exp().cpu().data.numpy() # standard deviation\n",
    "    epistemic = samples.var(axis = 0)**0.5\n",
    "    total_unc = (aleatoric**2 + epistemic**2)**0.5\n",
    "    return total_unc\n",
    "\n",
    "samples_25 = net.predict(X_u_test_25, 100, net.network)\n",
    "samples_50 = net.predict(X_u_test_50, 100, net.network)\n",
    "samples_75 = net.predict(X_u_test_75, 100, net.network)\n",
    "\n",
    "\n",
    "u_pred_25 = samples_25.mean(axis = 0)\n",
    "u_pred_50 = samples_50.mean(axis = 0)\n",
    "u_pred_75 = samples_75.mean(axis = 0)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15,4))\n",
    "axs[0].plot(x,u_test_25, 'b-', linewidth = 2, label = 'Exact')\n",
    "axs[0].plot(x,u_pred_25, 'r--', linewidth = 2, label = 'Prediction')\n",
    "axs[0].set_xlabel('$x$')\n",
    "axs[0].set_ylabel('$u(t,x)$')\n",
    "axs[0].set_title('$t = 0.25$', fontsize = 10)\n",
    "axs[0].axis('square')\n",
    "#ax.set_xlim([-1.1,1.1])\n",
    "#ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "\n",
    "axs[1].plot(x,u_test_50, 'b-', linewidth = 2, label = 'Exact')\n",
    "axs[1].plot(x,u_pred_50, 'r--', linewidth = 2, label = 'Prediction')\n",
    "axs[1].set_xlabel('$x$')\n",
    "axs[1].set_ylabel('$u(t,x)$')\n",
    "axs[1].set_title('$t = 0.5$', fontsize = 10)\n",
    "axs[1].axis('square')\n",
    "\n",
    "\n",
    "axs[2].plot(x,u_test_75, 'b-', linewidth = 2, label = 'Exact')\n",
    "axs[2].plot(x,u_pred_75, 'r--', linewidth = 2, label = 'Prediction')\n",
    "axs[2].set_xlabel('$x$')\n",
    "axs[2].set_ylabel('$u(t,x)$')\n",
    "axs[2].set_title('$t = 0.75$', fontsize = 10)\n",
    "axs[2].axis('square')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00947837],\n",
       "       [0.00941755],\n",
       "       [0.00926923],\n",
       "       [0.00904689],\n",
       "       [0.00877711],\n",
       "       [0.00849635],\n",
       "       [0.00824475],\n",
       "       [0.00805872],\n",
       "       [0.00796333],\n",
       "       [0.00796673],\n",
       "       [0.00805723],\n",
       "       [0.00820433],\n",
       "       [0.00836431],\n",
       "       [0.00849048],\n",
       "       [0.00854546],\n",
       "       [0.0085113 ],\n",
       "       [0.00839209],\n",
       "       [0.00820884],\n",
       "       [0.00798886],\n",
       "       [0.00775539],\n",
       "       [0.00752157],\n",
       "       [0.00728998],\n",
       "       [0.00705677],\n",
       "       [0.00681782],\n",
       "       [0.00657313],\n",
       "       [0.00632864],\n",
       "       [0.00609437],\n",
       "       [0.00588128],\n",
       "       [0.00569799],\n",
       "       [0.00554917],\n",
       "       [0.00543526],\n",
       "       [0.00535323],\n",
       "       [0.00529758],\n",
       "       [0.00526103],\n",
       "       [0.00523561],\n",
       "       [0.00521315],\n",
       "       [0.00518649],\n",
       "       [0.00514988],\n",
       "       [0.00509991],\n",
       "       [0.00503551],\n",
       "       [0.00495792],\n",
       "       [0.00487021],\n",
       "       [0.00477651],\n",
       "       [0.00468136],\n",
       "       [0.00458875],\n",
       "       [0.00450196],\n",
       "       [0.00442296],\n",
       "       [0.00435267],\n",
       "       [0.00429092],\n",
       "       [0.00423692],\n",
       "       [0.00418942],\n",
       "       [0.00414705],\n",
       "       [0.00410854],\n",
       "       [0.00407291],\n",
       "       [0.0040395 ],\n",
       "       [0.00400802],\n",
       "       [0.00397855],\n",
       "       [0.00395137],\n",
       "       [0.00392704],\n",
       "       [0.00390608],\n",
       "       [0.00388901],\n",
       "       [0.00387626],\n",
       "       [0.00386794],\n",
       "       [0.00386398],\n",
       "       [0.00386403],\n",
       "       [0.00386741],\n",
       "       [0.00387322],\n",
       "       [0.00388034],\n",
       "       [0.00388743],\n",
       "       [0.00389314],\n",
       "       [0.00389602],\n",
       "       [0.00389456],\n",
       "       [0.0038874 ],\n",
       "       [0.00387334],\n",
       "       [0.00385131],\n",
       "       [0.0038205 ],\n",
       "       [0.00378039],\n",
       "       [0.00373068],\n",
       "       [0.00367147],\n",
       "       [0.00360306],\n",
       "       [0.00352604],\n",
       "       [0.00344122],\n",
       "       [0.00334959],\n",
       "       [0.00325229],\n",
       "       [0.00315048],\n",
       "       [0.00304549],\n",
       "       [0.00293848],\n",
       "       [0.00283081],\n",
       "       [0.00272371],\n",
       "       [0.00261857],\n",
       "       [0.00251694],\n",
       "       [0.00242062],\n",
       "       [0.002332  ],\n",
       "       [0.0022543 ],\n",
       "       [0.00219178],\n",
       "       [0.00215019],\n",
       "       [0.00213682],\n",
       "       [0.00216015],\n",
       "       [0.00222912],\n",
       "       [0.00235172],\n",
       "       [0.00253355],\n",
       "       [0.0027769 ],\n",
       "       [0.00308048],\n",
       "       [0.0034398 ],\n",
       "       [0.00384769],\n",
       "       [0.00429498],\n",
       "       [0.00477137],\n",
       "       [0.00526628],\n",
       "       [0.00577039],\n",
       "       [0.00627671],\n",
       "       [0.00678188],\n",
       "       [0.00728692],\n",
       "       [0.00779673],\n",
       "       [0.00831884],\n",
       "       [0.00886037],\n",
       "       [0.00942451],\n",
       "       [0.01000649],\n",
       "       [0.0105917 ],\n",
       "       [0.01115953],\n",
       "       [0.01169439],\n",
       "       [0.01219963],\n",
       "       [0.01270447],\n",
       "       [0.01324905],\n",
       "       [0.01384424],\n",
       "       [0.01441355],\n",
       "       [0.01474619],\n",
       "       [0.01455766],\n",
       "       [0.01376169],\n",
       "       [0.01272189],\n",
       "       [0.01196067],\n",
       "       [0.01156174],\n",
       "       [0.01123297],\n",
       "       [0.01084   ],\n",
       "       [0.01035589],\n",
       "       [0.00963996],\n",
       "       [0.00866132],\n",
       "       [0.00759942],\n",
       "       [0.00665017],\n",
       "       [0.00589943],\n",
       "       [0.00534297],\n",
       "       [0.0049413 ],\n",
       "       [0.00465202],\n",
       "       [0.0044407 ],\n",
       "       [0.00428213],\n",
       "       [0.00415864],\n",
       "       [0.0040581 ],\n",
       "       [0.00397222],\n",
       "       [0.00389571],\n",
       "       [0.00382529],\n",
       "       [0.00375912],\n",
       "       [0.00369637],\n",
       "       [0.00363694],\n",
       "       [0.00358114],\n",
       "       [0.00352951],\n",
       "       [0.00348269],\n",
       "       [0.00344132],\n",
       "       [0.0034061 ],\n",
       "       [0.00337752],\n",
       "       [0.00335604],\n",
       "       [0.00334206],\n",
       "       [0.00333584],\n",
       "       [0.00333769],\n",
       "       [0.00334777],\n",
       "       [0.00336621],\n",
       "       [0.00339314],\n",
       "       [0.00342855],\n",
       "       [0.00347247],\n",
       "       [0.00352473],\n",
       "       [0.0035851 ],\n",
       "       [0.00365318],\n",
       "       [0.00372835],\n",
       "       [0.00380967],\n",
       "       [0.00389608],\n",
       "       [0.00398602],\n",
       "       [0.00407767],\n",
       "       [0.00416895],\n",
       "       [0.00425733],\n",
       "       [0.00434025],\n",
       "       [0.004415  ],\n",
       "       [0.00447893],\n",
       "       [0.00452983],\n",
       "       [0.00456584],\n",
       "       [0.00458585],\n",
       "       [0.00458959],\n",
       "       [0.00457775],\n",
       "       [0.00455183],\n",
       "       [0.0045142 ],\n",
       "       [0.00446779],\n",
       "       [0.00441591],\n",
       "       [0.00436188],\n",
       "       [0.0043089 ],\n",
       "       [0.00425975],\n",
       "       [0.00421669],\n",
       "       [0.00418143],\n",
       "       [0.00415511],\n",
       "       [0.00413839],\n",
       "       [0.00413159],\n",
       "       [0.0041347 ],\n",
       "       [0.00414754],\n",
       "       [0.00416985],\n",
       "       [0.00420117],\n",
       "       [0.004241  ],\n",
       "       [0.00428871],\n",
       "       [0.00434339],\n",
       "       [0.00440384],\n",
       "       [0.00446862],\n",
       "       [0.00453579],\n",
       "       [0.00460321],\n",
       "       [0.00466847],\n",
       "       [0.00472913],\n",
       "       [0.00478306],\n",
       "       [0.0048287 ],\n",
       "       [0.00486539],\n",
       "       [0.00489368],\n",
       "       [0.0049155 ],\n",
       "       [0.00493426],\n",
       "       [0.00495469],\n",
       "       [0.00498267],\n",
       "       [0.00502476],\n",
       "       [0.0050878 ],\n",
       "       [0.00517823],\n",
       "       [0.00530154],\n",
       "       [0.00546145],\n",
       "       [0.00565923],\n",
       "       [0.00589291],\n",
       "       [0.00615668],\n",
       "       [0.00644058],\n",
       "       [0.00673113],\n",
       "       [0.00701289],\n",
       "       [0.00727093],\n",
       "       [0.00749364],\n",
       "       [0.00767424],\n",
       "       [0.00781087],\n",
       "       [0.0079051 ],\n",
       "       [0.00795988],\n",
       "       [0.00797814],\n",
       "       [0.00796276],\n",
       "       [0.00791721],\n",
       "       [0.00784654],\n",
       "       [0.00775754],\n",
       "       [0.00765834],\n",
       "       [0.00755718],\n",
       "       [0.00746136],\n",
       "       [0.00737637],\n",
       "       [0.00730548],\n",
       "       [0.00724964],\n",
       "       [0.00720782],\n",
       "       [0.00717723],\n",
       "       [0.00715369],\n",
       "       [0.00713221],\n",
       "       [0.00710765],\n",
       "       [0.00707524],\n",
       "       [0.00703147],\n",
       "       [0.00697428],\n",
       "       [0.0069033 ],\n",
       "       [0.00681978]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epistemic = samples_25.var(axis = 0)**0.5\n",
    "epistemic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.network.named_parameters():\n",
    "    print(name, param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_gaussian_loss(output, target, sigma, no_dim): # negative\n",
    "#     exponent = -0.5*(target - output)**2/(2*sigma**2) - torch.log(sigma)\n",
    "#     print(exponent.shape)\n",
    "#     return - (exponent).sum()\n",
    "\n",
    "# u_pred, KL_loss_para = net.net_U(X, t)\n",
    "           \n",
    "\n",
    "# fit_loss_U_total = log_gaussian_loss(u_pred, U, net.network.log_noise_u.exp(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0150],\n",
       "        [0.0035],\n",
       "        [0.0198],\n",
       "        ...,\n",
       "        [0.0062],\n",
       "        [0.0032],\n",
       "        [0.0058]], device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.log_noise_u.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca69f467ffdc3dc00e55b12e085102ec88652c053799da0c2cca2d561c3b19a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
