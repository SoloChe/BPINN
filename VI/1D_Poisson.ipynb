{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "\n",
    "x = sp.symbols('x')\n",
    "u = sp.sin(6*x)**3\n",
    "u_x = sp.diff(u, x)\n",
    "u_xx = sp.diff(u_x, x)\n",
    "u_xx = sp.lambdify(x, u_xx, 'numpy')\n",
    "\n",
    "lam = 0.01\n",
    "k = 0.7\n",
    "\n",
    "x = np.linspace(-0.7, 0.7, 70)\n",
    "u = (np.sin(6*x))**3\n",
    "f = lam * u_xx(x) # + k*np.tanh(u)\n",
    "\n",
    "n_train = 20\n",
    "X_f_train = np.linspace(-0.7, 0.7, n_train)\n",
    "u_f = (np.sin(6*X_f_train))**3\n",
    "f_train = lam * u_xx(X_f_train) # + k*np.tanh(u_f)\n",
    "\n",
    "X_u_train = np.linspace(-0.7, 0.7, n_train)\n",
    "# X_u_train = np.array([-0.7, 0.7])\n",
    "u_train = (np.sin(6*X_u_train))**3\n",
    "\n",
    "noise = 0.01\n",
    "f_train += noise*np.random.randn(n_train)\n",
    "u_train += noise*np.random.randn(n_train)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (15,4))\n",
    "axs[0].plot(x, u)\n",
    "axs[0].plot(X_u_train, u_train, 'o')\n",
    "axs[1].plot(x, f)\n",
    "axs[1].plot(X_f_train, f_train, 'o')\n",
    "\n",
    "x = x[:, None]; X_f_train = X_f_train[:, None]\n",
    "f = f[:, None]; f_train = f_train[:, None]\n",
    "X_u_train = X_u_train[:, None]\n",
    "u_train = u_train[:, None]\n",
    "u = u[:, None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "import scipy.io\n",
    "from utils import log_gaussian_loss, gaussian, get_kl_Gaussian_divergence\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print('device: {}'.format(device))\n",
    "\n",
    "from model import BBP_Model_PINN\n",
    "\n",
    "class BBP_Model_PINN_Poisson(BBP_Model_PINN):\n",
    "    def __init__(self, xt_lb, xt_ub, u_lb, u_ub, normal,\n",
    "                    layers, loss_func, opt, local, res, activation,\n",
    "                    learn_rate, batch_size, n_batches, \n",
    "                    prior, numerical, identification, device):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        super().__init__(xt_lb, xt_ub, u_lb, u_ub, normal,\n",
    "                            layers, loss_func, opt, local, res, activation,\n",
    "                            learn_rate, batch_size, n_batches, \n",
    "                            prior, numerical, identification, device)\n",
    "\n",
    "    def initial_para(self):\n",
    "       \n",
    "        self.lambda1_mus = nn.Parameter(torch.Tensor(1).uniform_(0, 0.1))\n",
    "        self.lambda1_rhos = nn.Parameter(torch.Tensor(1).uniform_(-3, 2))\n",
    "    \n",
    "        self.alpha = nn.Parameter(torch.Tensor(1).uniform_(0, 2))\n",
    "    \n",
    "        self.network.register_parameter('lambda1_mu', self.lambda1_mus)\n",
    "        self.network.register_parameter('lambda1_rho', self.lambda1_rhos)\n",
    "        self.network.register_parameter('alpha', self.alpha)\n",
    "        # self.network.register_parameter('beta', self.beta)\n",
    "\n",
    "        self.prior_lambda1 = self.prior\n",
    "        self.prior_lambda2 = self.prior\n",
    "\n",
    "    def net_U(self, xt):\n",
    "\n",
    "        xt = 2*(xt-self.xt_lb)/(self.xt_ub-self.xt_lb) - 1\n",
    "        out, KL_loss = self.network(xt)\n",
    "\n",
    "        u = out[:, 0:1]\n",
    "        log_noise_u = out[:, 1:2]\n",
    "        # log_noise_f = out[:, 2:3]\n",
    "        return u, log_noise_u, KL_loss\n",
    "\n",
    "    def net_F(self, X_f, lambda1_sample):\n",
    "        \n",
    "        lambda_1 = lambda1_sample       \n",
    "        u, _, _ = self.net_U(X_f)\n",
    "\n",
    "        if self.normal:\n",
    "            u = u*(self.u_ub-self.u_lb) + self.u_lb # reverse scaling\n",
    "\n",
    "        u_x = torch.autograd.grad(u, X_f, torch.ones_like(u),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, X_f, torch.ones_like(u_x),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "    \n",
    "        f_pred = lambda_1*u_xx\n",
    "        return f_pred\n",
    "    \n",
    "    def net_F_forward(self, X_f):\n",
    "\n",
    "        u, _, _ = self.net_U(X_f)\n",
    "        if self.normal:\n",
    "            u = u*(self.u_ub-self.u_lb) + self.u_lb # reverse scaling\n",
    "\n",
    "        u_x = torch.autograd.grad(u, X_f, torch.ones_like(u),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, X_f, torch.ones_like(u_x),\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True)[0]\n",
    "        f_pred = 0.01*u_xx # + 0.7*torch.tanh(u)\n",
    "        return f_pred\n",
    "\n",
    "    def fit(self, X_u, X_f, U, F, n_samples):\n",
    "        self.network.train()\n",
    "\n",
    "        # X = torch.tensor(self.X, requires_grad=True).float().to(device)\n",
    "        # t = torch.tensor(self.t, requires_grad=True).float().to(device)\n",
    "        if self.normal:\n",
    "            U = (U-self.u_lb)/(self.u_ub-self.u_lb) # scaling\n",
    "        # U = (U-self.u_mean)/self.u_std # scaling\n",
    "\n",
    "        # reset gradient and total loss\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "      \n",
    "        fit_loss_F_total = 0\n",
    "        fit_loss_U_total = 0\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "\n",
    "            u_pred, log_noise_u, KL_loss_para = self.net_U(X_u)\n",
    "\n",
    "            if self.identification:\n",
    "                lambda1_epsilons = self.lambda1_mus.data.new(self.lambda1_mus.size()).normal_()\n",
    "                lambda1_stds = torch.log(1 + torch.exp(self.lambda1_rhos))\n",
    "                lambda1_sample = self.lambda1_mus + lambda1_epsilons * lambda1_stds\n",
    "                \n",
    "                KL_loss_lambda1 = get_kl_Gaussian_divergence(self.prior_lambda1.mu, self.prior_lambda1.sigma**2, self.lambda1_mus, lambda1_stds**2)\n",
    "\n",
    "                f_pred = self.net_F(X_f, lambda1_sample)\n",
    "          \n",
    "            else:\n",
    "                f_pred = self.net_F_forward(X_f)\n",
    "                KL_loss_lambda1 = 0\n",
    "            \n",
    "\n",
    "            # calculate fit loss based on mean and standard deviation of output\n",
    "            fit_loss_U_total += self.loss_func(u_pred, U, log_noise_u.exp(), self.network.output_dim)\n",
    "            fit_loss_F_total += self.loss_func(f_pred, F, (self.alpha.exp()+1)*torch.ones_like(f_pred), self.network.output_dim)\n",
    "\n",
    "        \n",
    "        KL_loss_total = KL_loss_para + KL_loss_lambda1 \n",
    "        KL_loss_total = KL_loss_total/self.n_batches # minibatches and KL reweighting\n",
    "     \n",
    "        self.coef = self.alpha.exp() + 1\n",
    "        total_loss = KL_loss_total/U.shape[0] + fit_loss_U_total/U.shape[0] + fit_loss_F_total/F.shape[0]\n",
    "        total_loss /= n_samples\n",
    "        \n",
    "        \n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "\n",
    "        return fit_loss_U_total/n_samples, fit_loss_F_total/n_samples, KL_loss_total, total_loss\n",
    "\n",
    "    def predict(self, xt, n_sample):\n",
    "        xt = torch.tensor(xt, requires_grad = True).float().to(self.device)\n",
    "\n",
    "        self.network.eval()\n",
    "        u_samples = []\n",
    "        noises = []\n",
    "        f_samples = []\n",
    "\n",
    "        for _ in range(n_sample):\n",
    "            u_pred, noise_u, _ = self.net_U(xt)\n",
    "            noise_u = noise_u.exp()\n",
    "\n",
    "            if self.identification:\n",
    "                f_sample = self.net_F(xt, self.lambda1_mus)\n",
    "            else:\n",
    "                f_sample = self.net_F_forward(xt)\n",
    "            \n",
    "            if self.normal:\n",
    "                u_pred = u_pred*(self.u_ub-self.u_lb) + self.u_lb # reverse scaling\n",
    "                noise_u = noise_u*(self.u_ub-self.u_lb)\n",
    "\n",
    "            f_samples.append(f_sample.detach().cpu().numpy())\n",
    "            u_samples.append(u_pred.detach().cpu().numpy())\n",
    "            noises.append(noise_u.detach().cpu().numpy())\n",
    "        return np.array(u_samples), np.array(noises), np.array(f_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lb = x.min(0)\n",
    "x_ub = x.max(0)\n",
    "\n",
    "u_min = u_train.min(0)\n",
    "u_max = u_train.max(0)\n",
    "\n",
    "X_u = torch.tensor(X_u_train, device = device).float()\n",
    "U = torch.tensor(u_train, device = device).float()\n",
    "\n",
    "X_f = torch.tensor(X_f_train, requires_grad = True, device = device).float()\n",
    "F = torch.tensor(f_train, device = device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain bounds of x\n",
    "\n",
    "\n",
    "#%% model \n",
    "local = True\n",
    "identification = False\n",
    "numerical = False\n",
    "\n",
    "learn_rate = 2e-3\n",
    "n_hidden = 100\n",
    "opt = torch.optim.AdamW\n",
    "loss_func = log_gaussian_loss\n",
    "layers = [1, n_hidden, n_hidden, n_hidden, 2]\n",
    "\n",
    "# layers = [1, n_hidden, n_hidden, n_hidden, 2] # res\n",
    "\n",
    "\n",
    "prior = gaussian(0, 1)\n",
    "\n",
    "num_epochs = 40000\n",
    "\n",
    "n_batches = 1\n",
    "\n",
    "batch_size = len(X_u_train)\n",
    "\n",
    "res = True\n",
    "activation = nn.Tanh()\n",
    "\n",
    "normal = False\n",
    "pinn_model = BBP_Model_PINN_Poisson(x_lb, x_ub, u_min, u_max, normal,\n",
    "                                    layers, loss_func, opt, local, res, activation,\n",
    "                                    learn_rate, batch_size, n_batches,\n",
    "                                    prior, numerical, identification, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2710],\n",
       "        [ 0.6418],\n",
       "        [ 0.3611],\n",
       "        [-0.5032],\n",
       "        [-0.4931],\n",
       "        [ 0.4949],\n",
       "        [ 1.0840],\n",
       "        [ 0.3769],\n",
       "        [-0.5800],\n",
       "        [-0.4571],\n",
       "        [ 0.4322],\n",
       "        [ 0.5692],\n",
       "        [-0.3815],\n",
       "        [-1.0870],\n",
       "        [-0.5116],\n",
       "        [ 0.5004],\n",
       "        [ 0.5166],\n",
       "        [-0.3445],\n",
       "        [-0.6405],\n",
       "        [ 0.2671]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1/40000, total loss = 419.133, Fit loss U = 4.190, Fit loss F = 34.781, KL loss = 83436.844\n",
      "Epoch:     1/40000, error_test = 0.99047, error_train = 1.00618\n",
      "Epoch:     1/40000, error_f = 1.00004\n",
      "Epoch:     1/40000, alpha = 5.66337\n",
      "\n",
      "Epoch:    11/40000, total loss = 418.672, Fit loss U = 3.066, Fit loss F = 34.748, KL loss = 83356.227\n",
      "Epoch:    11/40000, alpha = 5.65391\n",
      "\n",
      "Epoch:    21/40000, total loss = 418.235, Fit loss U = 2.408, Fit loss F = 34.715, KL loss = 83275.719\n",
      "Epoch:    21/40000, alpha = 5.64447\n",
      "\n",
      "Epoch:    31/40000, total loss = 417.805, Fit loss U = 1.881, Fit loss F = 34.681, KL loss = 83195.320\n",
      "Epoch:    31/40000, alpha = 5.63504\n",
      "\n",
      "Epoch:    41/40000, total loss = 417.384, Fit loss U = 1.517, Fit loss F = 34.648, KL loss = 83115.062\n",
      "Epoch:    41/40000, alpha = 5.62564\n",
      "\n",
      "Epoch:    51/40000, total loss = 416.957, Fit loss U = 1.023, Fit loss F = 34.615, KL loss = 83034.938\n",
      "Epoch:    51/40000, alpha = 5.61625\n",
      "\n",
      "Epoch:    61/40000, total loss = 416.510, Fit loss U = 0.127, Fit loss F = 34.582, KL loss = 82954.938\n",
      "Epoch:    61/40000, alpha = 5.60688\n",
      "\n",
      "Epoch:    71/40000, total loss = 416.155, Fit loss U = 1.061, Fit loss F = 34.549, KL loss = 82874.953\n",
      "Epoch:    71/40000, alpha = 5.59753\n",
      "\n",
      "Epoch:    81/40000, total loss = 415.668, Fit loss U = -0.651, Fit loss F = 34.516, KL loss = 82794.867\n",
      "Epoch:    81/40000, alpha = 5.58820\n",
      "\n",
      "Epoch:    91/40000, total loss = 415.311, Fit loss U = 0.267, Fit loss F = 34.483, KL loss = 82714.641\n",
      "Epoch:    91/40000, alpha = 5.57889\n",
      "\n",
      "Epoch:   101/40000, total loss = 414.907, Fit loss U = 0.248, Fit loss F = 34.450, KL loss = 82634.383\n",
      "Epoch:   101/40000, error_test = 0.99790, error_train = 0.98869\n",
      "Epoch:   101/40000, error_f = 1.00002\n",
      "Epoch:   101/40000, alpha = 5.56960\n",
      "\n",
      "Epoch:   111/40000, total loss = 414.520, Fit loss U = 0.567, Fit loss F = 34.417, KL loss = 82554.156\n",
      "Epoch:   111/40000, alpha = 5.56033\n",
      "\n",
      "Epoch:   121/40000, total loss = 414.132, Fit loss U = 0.855, Fit loss F = 34.384, KL loss = 82473.984\n",
      "Epoch:   121/40000, alpha = 5.55107\n",
      "\n",
      "Epoch:   131/40000, total loss = 413.735, Fit loss U = 0.971, Fit loss F = 34.351, KL loss = 82393.844\n",
      "Epoch:   131/40000, alpha = 5.54183\n",
      "\n",
      "Epoch:   141/40000, total loss = 413.278, Fit loss U = -0.138, Fit loss F = 34.318, KL loss = 82313.719\n",
      "Epoch:   141/40000, alpha = 5.53261\n",
      "\n",
      "Epoch:   151/40000, total loss = 412.918, Fit loss U = 0.712, Fit loss F = 34.285, KL loss = 82233.633\n",
      "Epoch:   151/40000, alpha = 5.52340\n",
      "\n",
      "Epoch:   161/40000, total loss = 412.407, Fit loss U = -1.470, Fit loss F = 34.252, KL loss = 82153.523\n",
      "Epoch:   161/40000, alpha = 5.51421\n",
      "\n",
      "Epoch:   171/40000, total loss = 412.065, Fit loss U = -0.249, Fit loss F = 34.219, KL loss = 82073.359\n",
      "Epoch:   171/40000, alpha = 5.50503\n",
      "\n",
      "Epoch:   181/40000, total loss = 411.645, Fit loss U = -0.608, Fit loss F = 34.187, KL loss = 81993.211\n",
      "Epoch:   181/40000, alpha = 5.49587\n",
      "\n",
      "Epoch:   191/40000, total loss = 411.281, Fit loss U = 0.155, Fit loss F = 34.154, KL loss = 81913.039\n",
      "Epoch:   191/40000, alpha = 5.48673\n",
      "\n",
      "Epoch:   201/40000, total loss = 410.841, Fit loss U = -0.589, Fit loss F = 34.121, KL loss = 81832.852\n",
      "Epoch:   201/40000, error_test = 1.00079, error_train = 0.98529\n",
      "Epoch:   201/40000, error_f = 0.99993\n",
      "Epoch:   201/40000, alpha = 5.47760\n",
      "\n",
      "Epoch:   211/40000, total loss = 410.450, Fit loss U = -0.351, Fit loss F = 34.088, KL loss = 81752.625\n",
      "Epoch:   211/40000, alpha = 5.46850\n",
      "\n",
      "Epoch:   221/40000, total loss = 410.056, Fit loss U = -0.174, Fit loss F = 34.055, KL loss = 81672.398\n",
      "Epoch:   221/40000, alpha = 5.45940\n",
      "\n",
      "Epoch:   231/40000, total loss = 409.681, Fit loss U = 0.386, Fit loss F = 34.022, KL loss = 81592.117\n",
      "Epoch:   231/40000, alpha = 5.45032\n",
      "\n",
      "Epoch:   241/40000, total loss = 409.263, Fit loss U = 0.095, Fit loss F = 33.989, KL loss = 81511.836\n",
      "Epoch:   241/40000, alpha = 5.44126\n",
      "\n",
      "Epoch:   251/40000, total loss = 408.825, Fit loss U = -0.615, Fit loss F = 33.956, KL loss = 81431.523\n",
      "Epoch:   251/40000, alpha = 5.43221\n",
      "\n",
      "Epoch:   261/40000, total loss = 408.445, Fit loss U = -0.144, Fit loss F = 33.923, KL loss = 81351.188\n",
      "Epoch:   261/40000, alpha = 5.42317\n",
      "\n",
      "Epoch:   271/40000, total loss = 407.998, Fit loss U = -1.012, Fit loss F = 33.890, KL loss = 81270.773\n",
      "Epoch:   271/40000, alpha = 5.41414\n",
      "\n",
      "Epoch:   281/40000, total loss = 407.648, Fit loss U = 0.073, Fit loss F = 33.857, KL loss = 81190.352\n",
      "Epoch:   281/40000, alpha = 5.40513\n",
      "\n",
      "Epoch:   291/40000, total loss = 407.205, Fit loss U = -0.704, Fit loss F = 33.824, KL loss = 81109.883\n",
      "Epoch:   291/40000, alpha = 5.39613\n",
      "\n",
      "Epoch:   301/40000, total loss = 406.834, Fit loss U = -0.055, Fit loss F = 33.791, KL loss = 81029.367\n",
      "Epoch:   301/40000, error_test = 0.99405, error_train = 0.95014\n",
      "Epoch:   301/40000, error_f = 0.99996\n",
      "Epoch:   301/40000, alpha = 5.38714\n",
      "\n",
      "Epoch:   311/40000, total loss = 406.439, Fit loss U = 0.151, Fit loss F = 33.758, KL loss = 80948.781\n",
      "Epoch:   311/40000, alpha = 5.37817\n",
      "\n",
      "Epoch:   321/40000, total loss = 406.040, Fit loss U = 0.252, Fit loss F = 33.725, KL loss = 80868.164\n",
      "Epoch:   321/40000, alpha = 5.36920\n",
      "\n",
      "Epoch:   331/40000, total loss = 405.586, Fit loss U = -0.722, Fit loss F = 33.692, KL loss = 80787.492\n",
      "Epoch:   331/40000, alpha = 5.36025\n",
      "\n",
      "Epoch:   341/40000, total loss = 405.183, Fit loss U = -0.685, Fit loss F = 33.659, KL loss = 80706.766\n",
      "Epoch:   341/40000, alpha = 5.35131\n",
      "\n",
      "Epoch:   351/40000, total loss = 404.847, Fit loss U = 0.717, Fit loss F = 33.626, KL loss = 80625.984\n",
      "Epoch:   351/40000, alpha = 5.34238\n",
      "\n",
      "Epoch:   361/40000, total loss = 404.440, Fit loss U = 0.701, Fit loss F = 33.593, KL loss = 80545.125\n",
      "Epoch:   361/40000, alpha = 5.33346\n",
      "\n",
      "Epoch:   371/40000, total loss = 404.001, Fit loss U = 0.032, Fit loss F = 33.560, KL loss = 80464.211\n",
      "Epoch:   371/40000, alpha = 5.32455\n",
      "\n",
      "Epoch:   381/40000, total loss = 403.620, Fit loss U = 0.556, Fit loss F = 33.527, KL loss = 80383.250\n",
      "Epoch:   381/40000, alpha = 5.31565\n",
      "\n",
      "Epoch:   391/40000, total loss = 403.171, Fit loss U = -0.297, Fit loss F = 33.494, KL loss = 80302.203\n",
      "Epoch:   391/40000, alpha = 5.30676\n",
      "\n",
      "Epoch:   401/40000, total loss = 402.786, Fit loss U = 0.145, Fit loss F = 33.461, KL loss = 80221.086\n",
      "Epoch:   401/40000, error_test = 1.00406, error_train = 1.01113\n",
      "Epoch:   401/40000, error_f = 0.99992\n",
      "Epoch:   401/40000, alpha = 5.29788\n",
      "\n",
      "Epoch:   411/40000, total loss = 402.305, Fit loss U = -1.310, Fit loss F = 33.428, KL loss = 80139.898\n",
      "Epoch:   411/40000, alpha = 5.28901\n",
      "\n",
      "Epoch:   421/40000, total loss = 401.954, Fit loss U = -0.175, Fit loss F = 33.395, KL loss = 80058.617\n",
      "Epoch:   421/40000, alpha = 5.28015\n",
      "\n",
      "Epoch:   431/40000, total loss = 401.544, Fit loss U = -0.202, Fit loss F = 33.361, KL loss = 79977.258\n",
      "Epoch:   431/40000, alpha = 5.27130\n",
      "\n",
      "Epoch:   441/40000, total loss = 401.159, Fit loss U = 0.269, Fit loss F = 33.328, KL loss = 79895.773\n",
      "Epoch:   441/40000, alpha = 5.26246\n",
      "\n",
      "Epoch:   451/40000, total loss = 400.717, Fit loss U = -0.373, Fit loss F = 33.295, KL loss = 79814.188\n",
      "Epoch:   451/40000, alpha = 5.25363\n",
      "\n",
      "Epoch:   461/40000, total loss = 400.354, Fit loss U = 0.557, Fit loss F = 33.262, KL loss = 79732.531\n",
      "Epoch:   461/40000, alpha = 5.24480\n",
      "\n",
      "Epoch:   471/40000, total loss = 399.944, Fit loss U = 0.571, Fit loss F = 33.228, KL loss = 79650.789\n",
      "Epoch:   471/40000, alpha = 5.23598\n",
      "\n",
      "Epoch:   481/40000, total loss = 399.575, Fit loss U = 1.407, Fit loss F = 33.195, KL loss = 79568.945\n",
      "Epoch:   481/40000, alpha = 5.22717\n",
      "\n",
      "Epoch:   491/40000, total loss = 399.099, Fit loss U = 0.126, Fit loss F = 33.162, KL loss = 79487.008\n",
      "Epoch:   491/40000, alpha = 5.21837\n",
      "\n",
      "Epoch:   501/40000, total loss = 398.664, Fit loss U = -0.345, Fit loss F = 33.129, KL loss = 79404.984\n",
      "Epoch:   501/40000, error_test = 0.99442, error_train = 1.03337\n",
      "Epoch:   501/40000, error_f = 0.99994\n",
      "Epoch:   501/40000, alpha = 5.20958\n",
      "\n",
      "Epoch:   511/40000, total loss = 398.301, Fit loss U = 0.649, Fit loss F = 33.095, KL loss = 79322.852\n",
      "Epoch:   511/40000, alpha = 5.20079\n",
      "\n",
      "Epoch:   521/40000, total loss = 397.775, Fit loss U = -1.627, Fit loss F = 33.062, KL loss = 79240.633\n",
      "Epoch:   521/40000, alpha = 5.19201\n",
      "\n",
      "Epoch:   531/40000, total loss = 397.393, Fit loss U = -1.004, Fit loss F = 33.028, KL loss = 79158.305\n",
      "Epoch:   531/40000, alpha = 5.18324\n",
      "\n",
      "Epoch:   541/40000, total loss = 396.993, Fit loss U = -0.715, Fit loss F = 32.995, KL loss = 79075.867\n",
      "Epoch:   541/40000, alpha = 5.17447\n",
      "\n",
      "Epoch:   551/40000, total loss = 396.618, Fit loss U = 0.060, Fit loss F = 32.961, KL loss = 78993.320\n",
      "Epoch:   551/40000, alpha = 5.16571\n",
      "\n",
      "Epoch:   561/40000, total loss = 396.185, Fit loss U = -0.292, Fit loss F = 32.928, KL loss = 78910.664\n",
      "Epoch:   561/40000, alpha = 5.15696\n",
      "\n",
      "Epoch:   571/40000, total loss = 395.772, Fit loss U = -0.235, Fit loss F = 32.894, KL loss = 78827.898\n",
      "Epoch:   571/40000, alpha = 5.14821\n",
      "\n",
      "Epoch:   581/40000, total loss = 395.478, Fit loss U = 2.206, Fit loss F = 32.861, KL loss = 78745.031\n",
      "Epoch:   581/40000, alpha = 5.13946\n",
      "\n",
      "Epoch:   591/40000, total loss = 394.941, Fit loss U = -0.201, Fit loss F = 32.827, KL loss = 78662.031\n",
      "Epoch:   591/40000, alpha = 5.13073\n",
      "\n",
      "Epoch:   601/40000, total loss = 394.498, Fit loss U = -0.728, Fit loss F = 32.794, KL loss = 78578.922\n",
      "Epoch:   601/40000, error_test = 0.99019, error_train = 0.97697\n",
      "Epoch:   601/40000, error_f = 0.99995\n",
      "Epoch:   601/40000, alpha = 5.12200\n",
      "\n",
      "Epoch:   611/40000, total loss = 394.125, Fit loss U = 0.175, Fit loss F = 32.760, KL loss = 78495.688\n",
      "Epoch:   611/40000, alpha = 5.11327\n",
      "\n",
      "Epoch:   621/40000, total loss = 393.734, Fit loss U = 0.726, Fit loss F = 32.726, KL loss = 78412.312\n",
      "Epoch:   621/40000, alpha = 5.10455\n",
      "\n",
      "Epoch:   631/40000, total loss = 393.285, Fit loss U = 0.139, Fit loss F = 32.692, KL loss = 78328.789\n",
      "Epoch:   631/40000, alpha = 5.09583\n",
      "\n",
      "Epoch:   641/40000, total loss = 392.888, Fit loss U = 0.585, Fit loss F = 32.659, KL loss = 78245.141\n",
      "Epoch:   641/40000, alpha = 5.08712\n",
      "\n",
      "Epoch:   651/40000, total loss = 392.432, Fit loss U = -0.115, Fit loss F = 32.625, KL loss = 78161.367\n",
      "Epoch:   651/40000, alpha = 5.07841\n",
      "\n",
      "Epoch:   661/40000, total loss = 392.005, Fit loss U = -0.245, Fit loss F = 32.591, KL loss = 78077.453\n",
      "Epoch:   661/40000, alpha = 5.06971\n",
      "\n",
      "Epoch:   671/40000, total loss = 391.734, Fit loss U = 2.780, Fit loss F = 32.557, KL loss = 77993.391\n",
      "Epoch:   671/40000, alpha = 5.06101\n",
      "\n",
      "Epoch:   681/40000, total loss = 391.201, Fit loss U = 0.574, Fit loss F = 32.523, KL loss = 77909.195\n",
      "Epoch:   681/40000, alpha = 5.05231\n",
      "\n",
      "Epoch:   691/40000, total loss = 390.770, Fit loss U = 0.428, Fit loss F = 32.489, KL loss = 77824.875\n",
      "Epoch:   691/40000, alpha = 5.04362\n",
      "\n",
      "Epoch:   701/40000, total loss = 390.342, Fit loss U = 0.348, Fit loss F = 32.455, KL loss = 77740.414\n",
      "Epoch:   701/40000, error_test = 0.98928, error_train = 1.03113\n",
      "Epoch:   701/40000, error_f = 0.99994\n",
      "Epoch:   701/40000, alpha = 5.03493\n",
      "\n",
      "Epoch:   711/40000, total loss = 389.934, Fit loss U = 0.679, Fit loss F = 32.421, KL loss = 77655.820\n",
      "Epoch:   711/40000, alpha = 5.02625\n",
      "\n",
      "Epoch:   721/40000, total loss = 389.498, Fit loss U = 0.471, Fit loss F = 32.387, KL loss = 77571.070\n",
      "Epoch:   721/40000, alpha = 5.01756\n",
      "\n",
      "Epoch:   731/40000, total loss = 389.078, Fit loss U = 0.600, Fit loss F = 32.353, KL loss = 77486.148\n",
      "Epoch:   731/40000, alpha = 5.00888\n",
      "\n",
      "Epoch:   741/40000, total loss = 388.617, Fit loss U = -0.090, Fit loss F = 32.318, KL loss = 77401.070\n",
      "Epoch:   741/40000, alpha = 5.00021\n",
      "\n",
      "Epoch:   751/40000, total loss = 388.345, Fit loss U = 3.033, Fit loss F = 32.284, KL loss = 77315.859\n",
      "Epoch:   751/40000, alpha = 4.99154\n",
      "\n",
      "Epoch:   761/40000, total loss = 387.864, Fit loss U = 1.975, Fit loss F = 32.250, KL loss = 77230.477\n",
      "Epoch:   761/40000, alpha = 4.98286\n",
      "\n",
      "Epoch:   771/40000, total loss = 387.384, Fit loss U = 0.969, Fit loss F = 32.215, KL loss = 77144.883\n",
      "Epoch:   771/40000, alpha = 4.97419\n",
      "\n",
      "Epoch:   781/40000, total loss = 386.947, Fit loss U = 0.848, Fit loss F = 32.181, KL loss = 77059.141\n",
      "Epoch:   781/40000, alpha = 4.96552\n",
      "\n",
      "Epoch:   791/40000, total loss = 386.547, Fit loss U = 1.476, Fit loss F = 32.146, KL loss = 76973.242\n",
      "Epoch:   791/40000, alpha = 4.95685\n",
      "\n",
      "Epoch:   801/40000, total loss = 386.148, Fit loss U = 2.125, Fit loss F = 32.112, KL loss = 76887.195\n",
      "Epoch:   801/40000, error_test = 0.97639, error_train = 0.98532\n",
      "Epoch:   801/40000, error_f = 0.99996\n",
      "Epoch:   801/40000, alpha = 4.94819\n",
      "\n",
      "Epoch:   811/40000, total loss = 385.717, Fit loss U = 2.172, Fit loss F = 32.077, KL loss = 76800.992\n",
      "Epoch:   811/40000, alpha = 4.93953\n",
      "\n",
      "Epoch:   821/40000, total loss = 385.160, Fit loss U = -0.305, Fit loss F = 32.043, KL loss = 76714.594\n",
      "Epoch:   821/40000, alpha = 4.93087\n",
      "\n",
      "Epoch:   831/40000, total loss = 384.780, Fit loss U = 0.782, Fit loss F = 32.008, KL loss = 76628.008\n",
      "Epoch:   831/40000, alpha = 4.92221\n",
      "\n",
      "Epoch:   841/40000, total loss = 384.368, Fit loss U = 1.262, Fit loss F = 31.973, KL loss = 76541.266\n",
      "Epoch:   841/40000, alpha = 4.91356\n",
      "\n",
      "Epoch:   851/40000, total loss = 384.010, Fit loss U = 2.833, Fit loss F = 31.938, KL loss = 76454.336\n",
      "Epoch:   851/40000, alpha = 4.90490\n",
      "\n",
      "Epoch:   861/40000, total loss = 383.448, Fit loss U = 0.336, Fit loss F = 31.904, KL loss = 76367.258\n",
      "Epoch:   861/40000, alpha = 4.89625\n",
      "\n",
      "Epoch:   871/40000, total loss = 383.076, Fit loss U = 1.652, Fit loss F = 31.869, KL loss = 76279.977\n",
      "Epoch:   871/40000, alpha = 4.88759\n",
      "\n",
      "Epoch:   881/40000, total loss = 382.612, Fit loss U = 1.152, Fit loss F = 31.834, KL loss = 76192.492\n",
      "Epoch:   881/40000, alpha = 4.87894\n",
      "\n",
      "Epoch:   891/40000, total loss = 382.232, Fit loss U = 2.361, Fit loss F = 31.799, KL loss = 76104.820\n",
      "Epoch:   891/40000, alpha = 4.87028\n",
      "\n",
      "Epoch:   901/40000, total loss = 381.729, Fit loss U = 1.122, Fit loss F = 31.764, KL loss = 76016.969\n",
      "Epoch:   901/40000, error_test = 0.98449, error_train = 1.02439\n",
      "Epoch:   901/40000, error_f = 0.99998\n",
      "Epoch:   901/40000, alpha = 4.86162\n",
      "\n",
      "Epoch:   911/40000, total loss = 381.287, Fit loss U = 1.124, Fit loss F = 31.728, KL loss = 75928.945\n",
      "Epoch:   911/40000, alpha = 4.85297\n",
      "\n",
      "Epoch:   921/40000, total loss = 380.797, Fit loss U = 0.186, Fit loss F = 31.693, KL loss = 75840.680\n",
      "Epoch:   921/40000, alpha = 4.84431\n",
      "\n",
      "Epoch:   931/40000, total loss = 380.419, Fit loss U = 1.500, Fit loss F = 31.658, KL loss = 75752.227\n",
      "Epoch:   931/40000, alpha = 4.83565\n",
      "\n",
      "Epoch:   941/40000, total loss = 380.028, Fit loss U = 2.584, Fit loss F = 31.623, KL loss = 75663.594\n",
      "Epoch:   941/40000, alpha = 4.82700\n",
      "\n",
      "Epoch:   951/40000, total loss = 379.573, Fit loss U = 2.395, Fit loss F = 31.587, KL loss = 75574.797\n",
      "Epoch:   951/40000, alpha = 4.81835\n",
      "\n",
      "Epoch:   961/40000, total loss = 379.146, Fit loss U = 2.784, Fit loss F = 31.552, KL loss = 75485.789\n",
      "Epoch:   961/40000, alpha = 4.80969\n",
      "\n",
      "Epoch:   971/40000, total loss = 378.701, Fit loss U = 2.842, Fit loss F = 31.516, KL loss = 75396.594\n",
      "Epoch:   971/40000, alpha = 4.80104\n",
      "\n",
      "Epoch:   981/40000, total loss = 378.239, Fit loss U = 2.577, Fit loss F = 31.481, KL loss = 75307.211\n",
      "Epoch:   981/40000, alpha = 4.79239\n",
      "\n",
      "Epoch:   991/40000, total loss = 377.698, Fit loss U = 0.760, Fit loss F = 31.445, KL loss = 75217.539\n",
      "Epoch:   991/40000, alpha = 4.78373\n",
      "\n",
      "Epoch:  1001/40000, total loss = 377.318, Fit loss U = 2.182, Fit loss F = 31.409, KL loss = 75127.648\n",
      "Epoch:  1001/40000, error_test = 0.98649, error_train = 0.96794\n",
      "Epoch:  1001/40000, error_f = 1.00002\n",
      "Epoch:  1001/40000, alpha = 4.77507\n",
      "\n",
      "Epoch:  1011/40000, total loss = 376.996, Fit loss U = 4.792, Fit loss F = 31.374, KL loss = 75037.539\n",
      "Epoch:  1011/40000, alpha = 4.76641\n",
      "\n",
      "Epoch:  1021/40000, total loss = 376.282, Fit loss U = -0.424, Fit loss F = 31.338, KL loss = 74947.227\n",
      "Epoch:  1021/40000, alpha = 4.75775\n",
      "\n",
      "Epoch:  1031/40000, total loss = 375.996, Fit loss U = 2.952, Fit loss F = 31.302, KL loss = 74856.703\n",
      "Epoch:  1031/40000, alpha = 4.74909\n",
      "\n",
      "Epoch:  1041/40000, total loss = 375.511, Fit loss U = 2.351, Fit loss F = 31.266, KL loss = 74765.961\n",
      "Epoch:  1041/40000, alpha = 4.74043\n",
      "\n",
      "Epoch:  1051/40000, total loss = 375.036, Fit loss U = 1.996, Fit loss F = 31.230, KL loss = 74675.008\n",
      "Epoch:  1051/40000, alpha = 4.73176\n",
      "\n",
      "Epoch:  1061/40000, total loss = 374.621, Fit loss U = 2.842, Fit loss F = 31.194, KL loss = 74583.836\n",
      "Epoch:  1061/40000, alpha = 4.72310\n",
      "\n",
      "Epoch:  1071/40000, total loss = 374.164, Fit loss U = 2.868, Fit loss F = 31.157, KL loss = 74492.477\n",
      "Epoch:  1071/40000, alpha = 4.71443\n",
      "\n",
      "Epoch:  1081/40000, total loss = 373.636, Fit loss U = 1.520, Fit loss F = 31.121, KL loss = 74400.820\n",
      "Epoch:  1081/40000, alpha = 4.70576\n",
      "\n",
      "Epoch:  1091/40000, total loss = 373.178, Fit loss U = 1.590, Fit loss F = 31.085, KL loss = 74308.914\n",
      "Epoch:  1091/40000, alpha = 4.69709\n",
      "\n",
      "Epoch:  1101/40000, total loss = 372.812, Fit loss U = 3.521, Fit loss F = 31.048, KL loss = 74216.781\n",
      "Epoch:  1101/40000, error_test = 1.00162, error_train = 0.99892\n",
      "Epoch:  1101/40000, error_f = 0.99996\n",
      "Epoch:  1101/40000, alpha = 4.68842\n",
      "\n",
      "Epoch:  1111/40000, total loss = 372.214, Fit loss U = 0.820, Fit loss F = 31.012, KL loss = 74124.453\n",
      "Epoch:  1111/40000, alpha = 4.67975\n",
      "\n",
      "Epoch:  1121/40000, total loss = 371.820, Fit loss U = 2.232, Fit loss F = 30.975, KL loss = 74031.883\n",
      "Epoch:  1121/40000, alpha = 4.67107\n",
      "\n",
      "Epoch:  1131/40000, total loss = 371.332, Fit loss U = 1.796, Fit loss F = 30.939, KL loss = 73939.102\n",
      "Epoch:  1131/40000, alpha = 4.66239\n",
      "\n",
      "Epoch:  1141/40000, total loss = 371.002, Fit loss U = 4.531, Fit loss F = 30.902, KL loss = 73846.070\n",
      "Epoch:  1141/40000, alpha = 4.65371\n",
      "\n",
      "Epoch:  1151/40000, total loss = 370.477, Fit loss U = 3.379, Fit loss F = 30.865, KL loss = 73752.852\n",
      "Epoch:  1151/40000, alpha = 4.64503\n",
      "\n",
      "Epoch:  1161/40000, total loss = 370.112, Fit loss U = 5.472, Fit loss F = 30.828, KL loss = 73659.383\n",
      "Epoch:  1161/40000, alpha = 4.63635\n",
      "\n",
      "Epoch:  1171/40000, total loss = 369.369, Fit loss U = 0.032, Fit loss F = 30.791, KL loss = 73565.617\n",
      "Epoch:  1171/40000, alpha = 4.62766\n",
      "\n",
      "Epoch:  1181/40000, total loss = 369.031, Fit loss U = 2.709, Fit loss F = 30.754, KL loss = 73471.586\n",
      "Epoch:  1181/40000, alpha = 4.61897\n",
      "\n",
      "Epoch:  1191/40000, total loss = 368.552, Fit loss U = 2.603, Fit loss F = 30.717, KL loss = 73377.289\n",
      "Epoch:  1191/40000, alpha = 4.61028\n",
      "\n",
      "Epoch:  1201/40000, total loss = 368.172, Fit loss U = 4.492, Fit loss F = 30.680, KL loss = 73282.773\n",
      "Epoch:  1201/40000, error_test = 1.00587, error_train = 1.00813\n",
      "Epoch:  1201/40000, error_f = 0.99994\n",
      "Epoch:  1201/40000, alpha = 4.60158\n",
      "\n",
      "Epoch:  1211/40000, total loss = 367.629, Fit loss U = 3.139, Fit loss F = 30.643, KL loss = 73188.016\n",
      "Epoch:  1211/40000, alpha = 4.59289\n",
      "\n",
      "Epoch:  1221/40000, total loss = 367.070, Fit loss U = 1.505, Fit loss F = 30.605, KL loss = 73092.984\n",
      "Epoch:  1221/40000, alpha = 4.58419\n",
      "\n",
      "Epoch:  1231/40000, total loss = 366.691, Fit loss U = 3.495, Fit loss F = 30.568, KL loss = 72997.664\n",
      "Epoch:  1231/40000, alpha = 4.57549\n",
      "\n",
      "Epoch:  1241/40000, total loss = 366.156, Fit loss U = 2.380, Fit loss F = 30.530, KL loss = 72902.156\n",
      "Epoch:  1241/40000, alpha = 4.56678\n",
      "\n",
      "Epoch:  1251/40000, total loss = 365.652, Fit loss U = 1.917, Fit loss F = 30.493, KL loss = 72806.367\n",
      "Epoch:  1251/40000, alpha = 4.55807\n",
      "\n",
      "Epoch:  1261/40000, total loss = 365.188, Fit loss U = 2.269, Fit loss F = 30.455, KL loss = 72710.305\n",
      "Epoch:  1261/40000, alpha = 4.54936\n",
      "\n",
      "Epoch:  1271/40000, total loss = 364.778, Fit loss U = 3.746, Fit loss F = 30.417, KL loss = 72614.000\n",
      "Epoch:  1271/40000, alpha = 4.54064\n",
      "\n",
      "Epoch:  1281/40000, total loss = 364.276, Fit loss U = 3.404, Fit loss F = 30.380, KL loss = 72517.438\n",
      "Epoch:  1281/40000, alpha = 4.53192\n",
      "\n",
      "Epoch:  1291/40000, total loss = 363.741, Fit loss U = 2.415, Fit loss F = 30.342, KL loss = 72420.594\n",
      "Epoch:  1291/40000, alpha = 4.52320\n",
      "\n",
      "Epoch:  1301/40000, total loss = 363.288, Fit loss U = 3.109, Fit loss F = 30.304, KL loss = 72323.477\n",
      "Epoch:  1301/40000, error_test = 1.02339, error_train = 1.00913\n",
      "Epoch:  1301/40000, error_f = 0.99994\n",
      "Epoch:  1301/40000, alpha = 4.51448\n",
      "\n",
      "Epoch:  1311/40000, total loss = 362.721, Fit loss U = 1.549, Fit loss F = 30.266, KL loss = 72226.109\n",
      "Epoch:  1311/40000, alpha = 4.50575\n",
      "\n",
      "Epoch:  1321/40000, total loss = 362.286, Fit loss U = 2.659, Fit loss F = 30.227, KL loss = 72128.438\n",
      "Epoch:  1321/40000, alpha = 4.49702\n",
      "\n",
      "Epoch:  1331/40000, total loss = 361.747, Fit loss U = 1.710, Fit loss F = 30.189, KL loss = 72030.445\n",
      "Epoch:  1331/40000, alpha = 4.48829\n",
      "\n",
      "Epoch:  1341/40000, total loss = 361.426, Fit loss U = 5.158, Fit loss F = 30.151, KL loss = 71932.164\n",
      "Epoch:  1341/40000, alpha = 4.47955\n",
      "\n",
      "Epoch:  1351/40000, total loss = 361.013, Fit loss U = 6.796, Fit loss F = 30.112, KL loss = 71833.609\n",
      "Epoch:  1351/40000, alpha = 4.47080\n",
      "\n",
      "Epoch:  1361/40000, total loss = 360.331, Fit loss U = 3.062, Fit loss F = 30.074, KL loss = 71734.812\n",
      "Epoch:  1361/40000, alpha = 4.46206\n",
      "\n",
      "Epoch:  1371/40000, total loss = 359.792, Fit loss U = 2.229, Fit loss F = 30.035, KL loss = 71635.766\n",
      "Epoch:  1371/40000, alpha = 4.45331\n",
      "\n",
      "Epoch:  1381/40000, total loss = 359.417, Fit loss U = 4.703, Fit loss F = 29.997, KL loss = 71536.422\n",
      "Epoch:  1381/40000, alpha = 4.44455\n",
      "\n",
      "Epoch:  1391/40000, total loss = 358.959, Fit loss U = 5.536, Fit loss F = 29.958, KL loss = 71436.828\n",
      "Epoch:  1391/40000, alpha = 4.43580\n",
      "\n",
      "Epoch:  1401/40000, total loss = 358.389, Fit loss U = 4.163, Fit loss F = 29.919, KL loss = 71336.906\n",
      "Epoch:  1401/40000, error_test = 1.00174, error_train = 1.02322\n",
      "Epoch:  1401/40000, error_f = 0.99997\n",
      "Epoch:  1401/40000, alpha = 4.42704\n",
      "\n",
      "Epoch:  1411/40000, total loss = 357.856, Fit loss U = 3.572, Fit loss F = 29.880, KL loss = 71236.688\n",
      "Epoch:  1411/40000, alpha = 4.41827\n",
      "\n",
      "Epoch:  1421/40000, total loss = 357.333, Fit loss U = 3.195, Fit loss F = 29.841, KL loss = 71136.148\n",
      "Epoch:  1421/40000, alpha = 4.40951\n",
      "\n",
      "Epoch:  1431/40000, total loss = 356.899, Fit loss U = 4.645, Fit loss F = 29.802, KL loss = 71035.320\n",
      "Epoch:  1431/40000, alpha = 4.40073\n",
      "\n",
      "Epoch:  1441/40000, total loss = 356.271, Fit loss U = 2.226, Fit loss F = 29.762, KL loss = 70934.242\n",
      "Epoch:  1441/40000, alpha = 4.39196\n",
      "\n",
      "Epoch:  1451/40000, total loss = 355.835, Fit loss U = 3.684, Fit loss F = 29.723, KL loss = 70832.859\n",
      "Epoch:  1451/40000, alpha = 4.38318\n",
      "\n",
      "Epoch:  1461/40000, total loss = 355.249, Fit loss U = 2.166, Fit loss F = 29.684, KL loss = 70731.203\n",
      "Epoch:  1461/40000, alpha = 4.37440\n",
      "\n",
      "Epoch:  1471/40000, total loss = 354.897, Fit loss U = 5.370, Fit loss F = 29.644, KL loss = 70629.203\n",
      "Epoch:  1471/40000, alpha = 4.36562\n",
      "\n",
      "Epoch:  1481/40000, total loss = 354.218, Fit loss U = 2.076, Fit loss F = 29.604, KL loss = 70526.867\n",
      "Epoch:  1481/40000, alpha = 4.35683\n",
      "\n",
      "Epoch:  1491/40000, total loss = 353.758, Fit loss U = 3.169, Fit loss F = 29.565, KL loss = 70424.188\n",
      "Epoch:  1491/40000, alpha = 4.34804\n",
      "\n",
      "Epoch:  1501/40000, total loss = 353.274, Fit loss U = 3.838, Fit loss F = 29.525, KL loss = 70321.227\n",
      "Epoch:  1501/40000, error_test = 0.98786, error_train = 1.03700\n",
      "Epoch:  1501/40000, error_f = 0.99993\n",
      "Epoch:  1501/40000, alpha = 4.33924\n",
      "\n",
      "Epoch:  1511/40000, total loss = 352.803, Fit loss U = 4.779, Fit loss F = 29.485, KL loss = 70217.930\n",
      "Epoch:  1511/40000, alpha = 4.33044\n",
      "\n",
      "Epoch:  1521/40000, total loss = 352.231, Fit loss U = 3.745, Fit loss F = 29.445, KL loss = 70114.328\n",
      "Epoch:  1521/40000, alpha = 4.32164\n",
      "\n",
      "Epoch:  1531/40000, total loss = 351.798, Fit loss U = 5.511, Fit loss F = 29.405, KL loss = 70010.422\n",
      "Epoch:  1531/40000, alpha = 4.31283\n",
      "\n",
      "Epoch:  1541/40000, total loss = 351.174, Fit loss U = 3.485, Fit loss F = 29.365, KL loss = 69906.211\n",
      "Epoch:  1541/40000, alpha = 4.30402\n",
      "\n",
      "Epoch:  1551/40000, total loss = 350.775, Fit loss U = 6.001, Fit loss F = 29.324, KL loss = 69801.711\n",
      "Epoch:  1551/40000, alpha = 4.29520\n",
      "\n",
      "Epoch:  1561/40000, total loss = 350.138, Fit loss U = 3.788, Fit loss F = 29.284, KL loss = 69696.922\n",
      "Epoch:  1561/40000, alpha = 4.28638\n",
      "\n",
      "Epoch:  1571/40000, total loss = 349.666, Fit loss U = 4.895, Fit loss F = 29.244, KL loss = 69591.797\n",
      "Epoch:  1571/40000, alpha = 4.27756\n",
      "\n",
      "Epoch:  1581/40000, total loss = 349.065, Fit loss U = 3.461, Fit loss F = 29.203, KL loss = 69486.352\n",
      "Epoch:  1581/40000, alpha = 4.26874\n",
      "\n",
      "Epoch:  1591/40000, total loss = 348.557, Fit loss U = 3.916, Fit loss F = 29.162, KL loss = 69380.562\n",
      "Epoch:  1591/40000, alpha = 4.25991\n",
      "\n",
      "Epoch:  1601/40000, total loss = 348.003, Fit loss U = 3.491, Fit loss F = 29.122, KL loss = 69274.398\n",
      "Epoch:  1601/40000, error_test = 1.00857, error_train = 1.03750\n",
      "Epoch:  1601/40000, error_f = 1.00003\n",
      "Epoch:  1601/40000, alpha = 4.25107\n",
      "\n",
      "Epoch:  1611/40000, total loss = 347.497, Fit loss U = 4.072, Fit loss F = 29.081, KL loss = 69167.906\n",
      "Epoch:  1611/40000, alpha = 4.24223\n",
      "\n",
      "Epoch:  1621/40000, total loss = 346.956, Fit loss U = 3.977, Fit loss F = 29.040, KL loss = 69061.125\n",
      "Epoch:  1621/40000, alpha = 4.23339\n",
      "\n",
      "Epoch:  1631/40000, total loss = 346.639, Fit loss U = 8.373, Fit loss F = 28.999, KL loss = 68954.016\n",
      "Epoch:  1631/40000, alpha = 4.22454\n",
      "\n",
      "Epoch:  1641/40000, total loss = 345.943, Fit loss U = 5.240, Fit loss F = 28.957, KL loss = 68846.664\n",
      "Epoch:  1641/40000, alpha = 4.21569\n",
      "\n",
      "Epoch:  1651/40000, total loss = 345.408, Fit loss U = 5.334, Fit loss F = 28.916, KL loss = 68739.094\n",
      "Epoch:  1651/40000, alpha = 4.20684\n",
      "\n",
      "Epoch:  1661/40000, total loss = 344.868, Fit loss U = 5.380, Fit loss F = 28.875, KL loss = 68631.133\n",
      "Epoch:  1661/40000, alpha = 4.19799\n",
      "\n",
      "Epoch:  1671/40000, total loss = 344.324, Fit loss U = 5.372, Fit loss F = 28.833, KL loss = 68522.844\n",
      "Epoch:  1671/40000, alpha = 4.18913\n",
      "\n",
      "Epoch:  1681/40000, total loss = 343.771, Fit loss U = 5.207, Fit loss F = 28.792, KL loss = 68414.203\n",
      "Epoch:  1681/40000, alpha = 4.18026\n",
      "\n",
      "Epoch:  1691/40000, total loss = 343.334, Fit loss U = 7.417, Fit loss F = 28.750, KL loss = 68305.188\n",
      "Epoch:  1691/40000, alpha = 4.17139\n",
      "\n",
      "Epoch:  1701/40000, total loss = 342.569, Fit loss U = 3.098, Fit loss F = 28.708, KL loss = 68195.773\n",
      "Epoch:  1701/40000, error_test = 1.01735, error_train = 0.98900\n",
      "Epoch:  1701/40000, error_f = 0.99991\n",
      "Epoch:  1701/40000, alpha = 4.16252\n",
      "\n",
      "Epoch:  1711/40000, total loss = 342.036, Fit loss U = 3.460, Fit loss F = 28.666, KL loss = 68085.977\n",
      "Epoch:  1711/40000, alpha = 4.15364\n",
      "\n",
      "Epoch:  1721/40000, total loss = 341.646, Fit loss U = 6.723, Fit loss F = 28.624, KL loss = 67975.781\n",
      "Epoch:  1721/40000, alpha = 4.14477\n",
      "\n",
      "Epoch:  1731/40000, total loss = 340.927, Fit loss U = 3.443, Fit loss F = 28.582, KL loss = 67865.242\n",
      "Epoch:  1731/40000, alpha = 4.13588\n",
      "\n",
      "Epoch:  1741/40000, total loss = 340.389, Fit loss U = 3.798, Fit loss F = 28.540, KL loss = 67754.383\n",
      "Epoch:  1741/40000, alpha = 4.12700\n",
      "\n",
      "Epoch:  1751/40000, total loss = 339.953, Fit loss U = 6.245, Fit loss F = 28.498, KL loss = 67643.133\n",
      "Epoch:  1751/40000, alpha = 4.11811\n",
      "\n",
      "Epoch:  1761/40000, total loss = 339.358, Fit loss U = 5.555, Fit loss F = 28.455, KL loss = 67531.555\n",
      "Epoch:  1761/40000, alpha = 4.10922\n",
      "\n",
      "Epoch:  1771/40000, total loss = 338.737, Fit loss U = 4.365, Fit loss F = 28.413, KL loss = 67419.680\n",
      "Epoch:  1771/40000, alpha = 4.10032\n",
      "\n",
      "Epoch:  1781/40000, total loss = 338.371, Fit loss U = 8.303, Fit loss F = 28.370, KL loss = 67307.492\n",
      "Epoch:  1781/40000, alpha = 4.09143\n",
      "\n",
      "Epoch:  1791/40000, total loss = 337.698, Fit loss U = 6.136, Fit loss F = 28.327, KL loss = 67194.953\n",
      "Epoch:  1791/40000, alpha = 4.08253\n",
      "\n",
      "Epoch:  1801/40000, total loss = 336.997, Fit loss U = 3.446, Fit loss F = 28.285, KL loss = 67082.008\n",
      "Epoch:  1801/40000, error_test = 1.00260, error_train = 0.98143\n",
      "Epoch:  1801/40000, error_f = 0.99995\n",
      "Epoch:  1801/40000, alpha = 4.07362\n",
      "\n",
      "Epoch:  1811/40000, total loss = 336.536, Fit loss U = 5.602, Fit loss F = 28.242, KL loss = 66968.703\n",
      "Epoch:  1811/40000, alpha = 4.06471\n",
      "\n",
      "Epoch:  1821/40000, total loss = 335.985, Fit loss U = 5.989, Fit loss F = 28.199, KL loss = 66855.078\n",
      "Epoch:  1821/40000, alpha = 4.05580\n",
      "\n",
      "Epoch:  1831/40000, total loss = 335.508, Fit loss U = 7.903, Fit loss F = 28.155, KL loss = 66741.102\n",
      "Epoch:  1831/40000, alpha = 4.04689\n",
      "\n",
      "Epoch:  1841/40000, total loss = 334.824, Fit loss U = 5.682, Fit loss F = 28.112, KL loss = 66626.773\n",
      "Epoch:  1841/40000, alpha = 4.03798\n",
      "\n",
      "Epoch:  1851/40000, total loss = 334.208, Fit loss U = 4.892, Fit loss F = 28.069, KL loss = 66512.062\n",
      "Epoch:  1851/40000, alpha = 4.02906\n",
      "\n",
      "Epoch:  1861/40000, total loss = 333.665, Fit loss U = 5.588, Fit loss F = 28.025, KL loss = 66396.961\n",
      "Epoch:  1861/40000, alpha = 4.02014\n",
      "\n",
      "Epoch:  1871/40000, total loss = 333.145, Fit loss U = 6.772, Fit loss F = 27.982, KL loss = 66281.492\n",
      "Epoch:  1871/40000, alpha = 4.01121\n",
      "\n",
      "Epoch:  1881/40000, total loss = 332.552, Fit loss U = 6.526, Fit loss F = 27.938, KL loss = 66165.773\n",
      "Epoch:  1881/40000, alpha = 4.00229\n",
      "\n",
      "Epoch:  1891/40000, total loss = 331.926, Fit loss U = 5.655, Fit loss F = 27.894, KL loss = 66049.719\n",
      "Epoch:  1891/40000, alpha = 3.99335\n",
      "\n",
      "Epoch:  1901/40000, total loss = 331.438, Fit loss U = 7.585, Fit loss F = 27.851, KL loss = 65933.219\n",
      "Epoch:  1901/40000, error_test = 1.01663, error_train = 1.03832\n",
      "Epoch:  1901/40000, error_f = 0.99994\n",
      "Epoch:  1901/40000, alpha = 3.98442\n",
      "\n",
      "Epoch:  1911/40000, total loss = 330.804, Fit loss U = 6.633, Fit loss F = 27.807, KL loss = 65816.367\n",
      "Epoch:  1911/40000, alpha = 3.97549\n",
      "\n",
      "Epoch:  1921/40000, total loss = 330.263, Fit loss U = 7.584, Fit loss F = 27.763, KL loss = 65699.117\n",
      "Epoch:  1921/40000, alpha = 3.96655\n",
      "\n",
      "Epoch:  1931/40000, total loss = 329.663, Fit loss U = 7.387, Fit loss F = 27.718, KL loss = 65581.492\n",
      "Epoch:  1931/40000, alpha = 3.95761\n",
      "\n",
      "Epoch:  1941/40000, total loss = 328.990, Fit loss U = 5.781, Fit loss F = 27.674, KL loss = 65463.402\n",
      "Epoch:  1941/40000, alpha = 3.94867\n",
      "\n",
      "Epoch:  1951/40000, total loss = 328.378, Fit loss U = 5.446, Fit loss F = 27.630, KL loss = 65344.934\n",
      "Epoch:  1951/40000, alpha = 3.93972\n",
      "\n",
      "Epoch:  1961/40000, total loss = 327.866, Fit loss U = 7.126, Fit loss F = 27.585, KL loss = 65226.141\n",
      "Epoch:  1961/40000, alpha = 3.93077\n",
      "\n",
      "Epoch:  1971/40000, total loss = 327.443, Fit loss U = 10.607, Fit loss F = 27.540, KL loss = 65107.070\n",
      "Epoch:  1971/40000, alpha = 3.92183\n",
      "\n",
      "Epoch:  1981/40000, total loss = 326.594, Fit loss U = 5.620, Fit loss F = 27.496, KL loss = 64987.605\n",
      "Epoch:  1981/40000, alpha = 3.91288\n",
      "\n",
      "Epoch:  1991/40000, total loss = 325.961, Fit loss U = 5.005, Fit loss F = 27.451, KL loss = 64867.695\n",
      "Epoch:  1991/40000, alpha = 3.90393\n",
      "\n",
      "Epoch:  2001/40000, total loss = 325.525, Fit loss U = 8.361, Fit loss F = 27.406, KL loss = 64747.414\n",
      "Epoch:  2001/40000, error_test = 1.03274, error_train = 0.98474\n",
      "Epoch:  2001/40000, error_f = 1.00000\n",
      "Epoch:  2001/40000, alpha = 3.89497\n",
      "\n",
      "Epoch:  2011/40000, total loss = 324.951, Fit loss U = 8.982, Fit loss F = 27.361, KL loss = 64626.770\n",
      "Epoch:  2011/40000, alpha = 3.88601\n",
      "\n",
      "Epoch:  2021/40000, total loss = 324.156, Fit loss U = 5.227, Fit loss F = 27.316, KL loss = 64505.789\n",
      "Epoch:  2021/40000, alpha = 3.87705\n",
      "\n",
      "Epoch:  2031/40000, total loss = 323.603, Fit loss U = 6.357, Fit loss F = 27.270, KL loss = 64384.371\n",
      "Epoch:  2031/40000, alpha = 3.86809\n",
      "\n",
      "Epoch:  2041/40000, total loss = 323.406, Fit loss U = 14.639, Fit loss F = 27.225, KL loss = 64262.562\n",
      "Epoch:  2041/40000, alpha = 3.85913\n",
      "\n",
      "Epoch:  2051/40000, total loss = 322.559, Fit loss U = 9.961, Fit loss F = 27.180, KL loss = 64140.418\n",
      "Epoch:  2051/40000, alpha = 3.85017\n",
      "\n",
      "Epoch:  2061/40000, total loss = 321.803, Fit loss U = 7.139, Fit loss F = 27.134, KL loss = 64017.965\n",
      "Epoch:  2061/40000, alpha = 3.84120\n",
      "\n",
      "Epoch:  2071/40000, total loss = 321.175, Fit loss U = 6.909, Fit loss F = 27.088, KL loss = 63895.117\n",
      "Epoch:  2071/40000, alpha = 3.83224\n",
      "\n",
      "Epoch:  2081/40000, total loss = 320.612, Fit loss U = 8.025, Fit loss F = 27.042, KL loss = 63771.777\n",
      "Epoch:  2081/40000, alpha = 3.82327\n",
      "\n",
      "Epoch:  2091/40000, total loss = 320.098, Fit loss U = 10.149, Fit loss F = 26.996, KL loss = 63648.074\n",
      "Epoch:  2091/40000, alpha = 3.81430\n",
      "\n",
      "Epoch:  2101/40000, total loss = 319.273, Fit loss U = 6.102, Fit loss F = 26.950, KL loss = 63524.078\n",
      "Epoch:  2101/40000, error_test = 1.02327, error_train = 0.99354\n",
      "Epoch:  2101/40000, error_f = 0.99994\n",
      "Epoch:  2101/40000, alpha = 3.80533\n",
      "\n",
      "Epoch:  2111/40000, total loss = 318.627, Fit loss U = 5.665, Fit loss F = 26.904, KL loss = 63399.707\n",
      "Epoch:  2111/40000, alpha = 3.79636\n",
      "\n",
      "Epoch:  2121/40000, total loss = 318.100, Fit loss U = 7.656, Fit loss F = 26.858, KL loss = 63274.949\n",
      "Epoch:  2121/40000, alpha = 3.78739\n",
      "\n",
      "Epoch:  2131/40000, total loss = 317.440, Fit loss U = 7.005, Fit loss F = 26.812, KL loss = 63149.840\n",
      "Epoch:  2131/40000, alpha = 3.77842\n",
      "\n",
      "Epoch:  2141/40000, total loss = 316.893, Fit loss U = 8.679, Fit loss F = 26.765, KL loss = 63024.223\n",
      "Epoch:  2141/40000, alpha = 3.76945\n",
      "\n",
      "Epoch:  2151/40000, total loss = 316.158, Fit loss U = 6.629, Fit loss F = 26.719, KL loss = 62898.137\n",
      "Epoch:  2151/40000, alpha = 3.76048\n",
      "\n",
      "Epoch:  2161/40000, total loss = 315.722, Fit loss U = 10.603, Fit loss F = 26.672, KL loss = 62771.602\n",
      "Epoch:  2161/40000, alpha = 3.75151\n",
      "\n",
      "Epoch:  2171/40000, total loss = 314.879, Fit loss U = 6.482, Fit loss F = 26.625, KL loss = 62644.680\n",
      "Epoch:  2171/40000, alpha = 3.74253\n",
      "\n",
      "Epoch:  2181/40000, total loss = 314.276, Fit loss U = 7.208, Fit loss F = 26.578, KL loss = 62517.266\n",
      "Epoch:  2181/40000, alpha = 3.73356\n",
      "\n",
      "Epoch:  2191/40000, total loss = 313.687, Fit loss U = 8.269, Fit loss F = 26.531, KL loss = 62389.422\n",
      "Epoch:  2191/40000, alpha = 3.72459\n",
      "\n",
      "Epoch:  2201/40000, total loss = 312.980, Fit loss U = 6.988, Fit loss F = 26.484, KL loss = 62261.207\n",
      "Epoch:  2201/40000, error_test = 0.99074, error_train = 1.03140\n",
      "Epoch:  2201/40000, error_f = 0.99998\n",
      "Epoch:  2201/40000, alpha = 3.71561\n",
      "\n",
      "Epoch:  2211/40000, total loss = 312.333, Fit loss U = 6.947, Fit loss F = 26.437, KL loss = 62132.684\n",
      "Epoch:  2211/40000, alpha = 3.70664\n",
      "\n",
      "Epoch:  2221/40000, total loss = 311.661, Fit loss U = 6.440, Fit loss F = 26.389, KL loss = 62003.867\n",
      "Epoch:  2221/40000, alpha = 3.69767\n",
      "\n",
      "Epoch:  2231/40000, total loss = 310.994, Fit loss U = 6.077, Fit loss F = 26.342, KL loss = 61874.539\n",
      "Epoch:  2231/40000, alpha = 3.68870\n",
      "\n",
      "Epoch:  2241/40000, total loss = 310.367, Fit loss U = 6.576, Fit loss F = 26.294, KL loss = 61744.707\n",
      "Epoch:  2241/40000, alpha = 3.67973\n",
      "\n",
      "Epoch:  2251/40000, total loss = 309.841, Fit loss U = 9.130, Fit loss F = 26.247, KL loss = 61614.531\n",
      "Epoch:  2251/40000, alpha = 3.67076\n",
      "\n",
      "Epoch:  2261/40000, total loss = 309.121, Fit loss U = 7.830, Fit loss F = 26.199, KL loss = 61483.879\n",
      "Epoch:  2261/40000, alpha = 3.66179\n",
      "\n",
      "Epoch:  2271/40000, total loss = 308.430, Fit loss U = 7.166, Fit loss F = 26.151, KL loss = 61352.832\n",
      "Epoch:  2271/40000, alpha = 3.65282\n",
      "\n",
      "Epoch:  2281/40000, total loss = 307.792, Fit loss U = 7.592, Fit loss F = 26.103, KL loss = 61221.406\n",
      "Epoch:  2281/40000, alpha = 3.64385\n",
      "\n",
      "Epoch:  2291/40000, total loss = 307.099, Fit loss U = 6.977, Fit loss F = 26.055, KL loss = 61089.516\n",
      "Epoch:  2291/40000, alpha = 3.63488\n",
      "\n",
      "Epoch:  2301/40000, total loss = 306.460, Fit loss U = 7.489, Fit loss F = 26.007, KL loss = 60957.062\n",
      "Epoch:  2301/40000, error_test = 1.03712, error_train = 1.02475\n",
      "Epoch:  2301/40000, error_f = 0.99997\n",
      "Epoch:  2301/40000, alpha = 3.62592\n",
      "\n",
      "Epoch:  2311/40000, total loss = 305.764, Fit loss U = 6.909, Fit loss F = 25.959, KL loss = 60824.145\n",
      "Epoch:  2311/40000, alpha = 3.61695\n",
      "\n",
      "Epoch:  2321/40000, total loss = 305.039, Fit loss U = 5.803, Fit loss F = 25.910, KL loss = 60690.762\n",
      "Epoch:  2321/40000, alpha = 3.60799\n",
      "\n",
      "Epoch:  2331/40000, total loss = 304.632, Fit loss U = 11.080, Fit loss F = 25.862, KL loss = 60556.992\n",
      "Epoch:  2331/40000, alpha = 3.59903\n",
      "\n",
      "Epoch:  2341/40000, total loss = 303.814, Fit loss U = 8.177, Fit loss F = 25.813, KL loss = 60422.957\n",
      "Epoch:  2341/40000, alpha = 3.59007\n",
      "\n",
      "Epoch:  2351/40000, total loss = 303.107, Fit loss U = 7.484, Fit loss F = 25.764, KL loss = 60288.824\n",
      "Epoch:  2351/40000, alpha = 3.58111\n",
      "\n",
      "Epoch:  2361/40000, total loss = 302.571, Fit loss U = 10.272, Fit loss F = 25.715, KL loss = 60154.324\n",
      "Epoch:  2361/40000, alpha = 3.57215\n",
      "\n",
      "Epoch:  2371/40000, total loss = 301.859, Fit loss U = 9.568, Fit loss F = 25.667, KL loss = 60019.359\n",
      "Epoch:  2371/40000, alpha = 3.56320\n",
      "\n",
      "Epoch:  2381/40000, total loss = 301.136, Fit loss U = 8.712, Fit loss F = 25.618, KL loss = 59883.949\n",
      "Epoch:  2381/40000, alpha = 3.55425\n",
      "\n",
      "Epoch:  2391/40000, total loss = 300.465, Fit loss U = 8.908, Fit loss F = 25.569, KL loss = 59748.137\n",
      "Epoch:  2391/40000, alpha = 3.54530\n",
      "\n",
      "Epoch:  2401/40000, total loss = 299.862, Fit loss U = 10.558, Fit loss F = 25.519, KL loss = 59611.703\n",
      "Epoch:  2401/40000, error_test = 1.02260, error_train = 1.01276\n",
      "Epoch:  2401/40000, error_f = 0.99998\n",
      "Epoch:  2401/40000, alpha = 3.53635\n",
      "\n",
      "Epoch:  2411/40000, total loss = 299.118, Fit loss U = 9.418, Fit loss F = 25.470, KL loss = 59474.770\n",
      "Epoch:  2411/40000, alpha = 3.52741\n",
      "\n",
      "Epoch:  2421/40000, total loss = 298.357, Fit loss U = 7.989, Fit loss F = 25.420, KL loss = 59337.289\n",
      "Epoch:  2421/40000, alpha = 3.51847\n",
      "\n",
      "Epoch:  2431/40000, total loss = 297.621, Fit loss U = 7.109, Fit loss F = 25.371, KL loss = 59199.453\n",
      "Epoch:  2431/40000, alpha = 3.50953\n",
      "\n",
      "Epoch:  2441/40000, total loss = 296.997, Fit loss U = 8.485, Fit loss F = 25.321, KL loss = 59061.309\n",
      "Epoch:  2441/40000, alpha = 3.50059\n",
      "\n",
      "Epoch:  2451/40000, total loss = 296.298, Fit loss U = 8.412, Fit loss F = 25.272, KL loss = 58922.848\n",
      "Epoch:  2451/40000, alpha = 3.49166\n",
      "\n",
      "Epoch:  2461/40000, total loss = 295.631, Fit loss U = 9.005, Fit loss F = 25.222, KL loss = 58783.840\n",
      "Epoch:  2461/40000, alpha = 3.48273\n",
      "\n",
      "Epoch:  2471/40000, total loss = 294.893, Fit loss U = 8.254, Fit loss F = 25.172, KL loss = 58644.387\n",
      "Epoch:  2471/40000, alpha = 3.47381\n",
      "\n",
      "Epoch:  2481/40000, total loss = 294.296, Fit loss U = 10.348, Fit loss F = 25.122, KL loss = 58504.492\n",
      "Epoch:  2481/40000, alpha = 3.46489\n",
      "\n",
      "Epoch:  2491/40000, total loss = 293.515, Fit loss U = 8.818, Fit loss F = 25.072, KL loss = 58364.180\n",
      "Epoch:  2491/40000, alpha = 3.45597\n",
      "\n",
      "Epoch:  2501/40000, total loss = 292.995, Fit loss U = 12.544, Fit loss F = 25.021, KL loss = 58223.332\n",
      "Epoch:  2501/40000, error_test = 1.03154, error_train = 1.04000\n",
      "Epoch:  2501/40000, error_f = 1.00000\n",
      "Epoch:  2501/40000, alpha = 3.44705\n",
      "\n",
      "Epoch:  2511/40000, total loss = 292.050, Fit loss U = 7.809, Fit loss F = 24.971, KL loss = 58082.109\n",
      "Epoch:  2511/40000, alpha = 3.43814\n",
      "\n",
      "Epoch:  2521/40000, total loss = 291.306, Fit loss U = 7.156, Fit loss F = 24.920, KL loss = 57940.453\n",
      "Epoch:  2521/40000, alpha = 3.42923\n",
      "\n",
      "Epoch:  2531/40000, total loss = 290.738, Fit loss U = 10.053, Fit loss F = 24.870, KL loss = 57798.352\n",
      "Epoch:  2531/40000, alpha = 3.42033\n",
      "\n",
      "Epoch:  2541/40000, total loss = 289.972, Fit loss U = 9.040, Fit loss F = 24.819, KL loss = 57655.777\n",
      "Epoch:  2541/40000, alpha = 3.41143\n",
      "\n",
      "Epoch:  2551/40000, total loss = 289.244, Fit loss U = 8.822, Fit loss F = 24.768, KL loss = 57512.828\n",
      "Epoch:  2551/40000, alpha = 3.40254\n",
      "\n",
      "Epoch:  2561/40000, total loss = 288.853, Fit loss U = 15.392, Fit loss F = 24.718, KL loss = 57369.492\n",
      "Epoch:  2561/40000, alpha = 3.39365\n",
      "\n",
      "Epoch:  2571/40000, total loss = 287.824, Fit loss U = 9.223, Fit loss F = 24.667, KL loss = 57225.914\n",
      "Epoch:  2571/40000, alpha = 3.38477\n",
      "\n",
      "Epoch:  2581/40000, total loss = 287.081, Fit loss U = 8.824, Fit loss F = 24.616, KL loss = 57081.875\n",
      "Epoch:  2581/40000, alpha = 3.37589\n",
      "\n",
      "Epoch:  2591/40000, total loss = 286.441, Fit loss U = 10.535, Fit loss F = 24.564, KL loss = 56937.164\n",
      "Epoch:  2591/40000, alpha = 3.36702\n",
      "\n",
      "Epoch:  2601/40000, total loss = 285.704, Fit loss U = 10.371, Fit loss F = 24.513, KL loss = 56792.055\n",
      "Epoch:  2601/40000, error_test = 1.00956, error_train = 1.01098\n",
      "Epoch:  2601/40000, error_f = 0.99999\n",
      "Epoch:  2601/40000, alpha = 3.35815\n",
      "\n",
      "Epoch:  2611/40000, total loss = 284.852, Fit loss U = 7.932, Fit loss F = 24.462, KL loss = 56646.371\n",
      "Epoch:  2611/40000, alpha = 3.34929\n",
      "\n",
      "Epoch:  2621/40000, total loss = 284.259, Fit loss U = 10.764, Fit loss F = 24.410, KL loss = 56500.117\n",
      "Epoch:  2621/40000, alpha = 3.34043\n",
      "\n",
      "Epoch:  2631/40000, total loss = 283.550, Fit loss U = 11.288, Fit loss F = 24.359, KL loss = 56353.633\n",
      "Epoch:  2631/40000, alpha = 3.33157\n",
      "\n",
      "Epoch:  2641/40000, total loss = 282.629, Fit loss U = 7.593, Fit loss F = 24.307, KL loss = 56206.785\n",
      "Epoch:  2641/40000, alpha = 3.32273\n",
      "\n",
      "Epoch:  2651/40000, total loss = 281.925, Fit loss U = 8.289, Fit loss F = 24.256, KL loss = 56059.598\n",
      "Epoch:  2651/40000, alpha = 3.31389\n",
      "\n",
      "Epoch:  2661/40000, total loss = 281.191, Fit loss U = 8.424, Fit loss F = 24.204, KL loss = 55911.824\n",
      "Epoch:  2661/40000, alpha = 3.30505\n",
      "\n",
      "Epoch:  2671/40000, total loss = 280.517, Fit loss U = 9.826, Fit loss F = 24.152, KL loss = 55763.586\n",
      "Epoch:  2671/40000, alpha = 3.29623\n",
      "\n",
      "Epoch:  2681/40000, total loss = 280.007, Fit loss U = 14.556, Fit loss F = 24.100, KL loss = 55614.863\n",
      "Epoch:  2681/40000, alpha = 3.28741\n",
      "\n",
      "Epoch:  2691/40000, total loss = 279.261, Fit loss U = 14.594, Fit loss F = 24.048, KL loss = 55465.789\n",
      "Epoch:  2691/40000, alpha = 3.27859\n",
      "\n",
      "Epoch:  2701/40000, total loss = 278.534, Fit loss U = 15.062, Fit loss F = 23.995, KL loss = 55316.297\n",
      "Epoch:  2701/40000, error_test = 0.99911, error_train = 0.96821\n",
      "Epoch:  2701/40000, error_f = 1.00003\n",
      "Epoch:  2701/40000, alpha = 3.26979\n",
      "\n",
      "Epoch:  2711/40000, total loss = 277.585, Fit loss U = 11.114, Fit loss F = 23.943, KL loss = 55166.348\n",
      "Epoch:  2711/40000, alpha = 3.26098\n",
      "\n",
      "Epoch:  2721/40000, total loss = 276.801, Fit loss U = 10.541, Fit loss F = 23.891, KL loss = 55015.949\n",
      "Epoch:  2721/40000, alpha = 3.25219\n",
      "\n",
      "Epoch:  2731/40000, total loss = 275.976, Fit loss U = 9.177, Fit loss F = 23.838, KL loss = 54865.039\n",
      "Epoch:  2731/40000, alpha = 3.24340\n",
      "\n",
      "Epoch:  2741/40000, total loss = 275.377, Fit loss U = 12.371, Fit loss F = 23.786, KL loss = 54713.793\n",
      "Epoch:  2741/40000, alpha = 3.23463\n",
      "\n",
      "Epoch:  2751/40000, total loss = 274.586, Fit loss U = 11.775, Fit loss F = 23.733, KL loss = 54562.102\n",
      "Epoch:  2751/40000, alpha = 3.22585\n",
      "\n",
      "Epoch:  2761/40000, total loss = 273.715, Fit loss U = 9.619, Fit loss F = 23.680, KL loss = 54409.918\n",
      "Epoch:  2761/40000, alpha = 3.21709\n",
      "\n",
      "Epoch:  2771/40000, total loss = 272.995, Fit loss U = 10.547, Fit loss F = 23.628, KL loss = 54257.332\n",
      "Epoch:  2771/40000, alpha = 3.20833\n",
      "\n",
      "Epoch:  2781/40000, total loss = 272.205, Fit loss U = 10.101, Fit loss F = 23.575, KL loss = 54104.324\n",
      "Epoch:  2781/40000, alpha = 3.19959\n",
      "\n",
      "Epoch:  2791/40000, total loss = 271.458, Fit loss U = 10.522, Fit loss F = 23.522, KL loss = 53951.070\n",
      "Epoch:  2791/40000, alpha = 3.19085\n",
      "\n",
      "Epoch:  2801/40000, total loss = 270.585, Fit loss U = 8.494, Fit loss F = 23.469, KL loss = 53797.359\n",
      "Epoch:  2801/40000, error_test = 1.00795, error_train = 1.03866\n",
      "Epoch:  2801/40000, error_f = 1.00001\n",
      "Epoch:  2801/40000, alpha = 3.18211\n",
      "\n",
      "Epoch:  2811/40000, total loss = 269.874, Fit loss U = 9.759, Fit loss F = 23.416, KL loss = 53643.035\n",
      "Epoch:  2811/40000, alpha = 3.17339\n",
      "\n",
      "Epoch:  2821/40000, total loss = 269.089, Fit loss U = 9.593, Fit loss F = 23.362, KL loss = 53488.188\n",
      "Epoch:  2821/40000, alpha = 3.16468\n",
      "\n",
      "Epoch:  2831/40000, total loss = 268.332, Fit loss U = 10.041, Fit loss F = 23.309, KL loss = 53332.918\n",
      "Epoch:  2831/40000, alpha = 3.15597\n",
      "\n",
      "Epoch:  2841/40000, total loss = 267.658, Fit loss U = 12.186, Fit loss F = 23.256, KL loss = 53177.258\n",
      "Epoch:  2841/40000, alpha = 3.14727\n",
      "\n",
      "Epoch:  2851/40000, total loss = 266.887, Fit loss U = 12.409, Fit loss F = 23.202, KL loss = 53021.340\n",
      "Epoch:  2851/40000, alpha = 3.13859\n",
      "\n",
      "Epoch:  2861/40000, total loss = 265.970, Fit loss U = 9.746, Fit loss F = 23.149, KL loss = 52865.035\n",
      "Epoch:  2861/40000, alpha = 3.12991\n",
      "\n",
      "Epoch:  2871/40000, total loss = 265.348, Fit loss U = 13.044, Fit loss F = 23.095, KL loss = 52708.238\n",
      "Epoch:  2871/40000, alpha = 3.12124\n",
      "\n",
      "Epoch:  2881/40000, total loss = 264.541, Fit loss U = 12.689, Fit loss F = 23.041, KL loss = 52550.883\n",
      "Epoch:  2881/40000, alpha = 3.11258\n",
      "\n",
      "Epoch:  2891/40000, total loss = 263.727, Fit loss U = 12.236, Fit loss F = 22.987, KL loss = 52393.133\n",
      "Epoch:  2891/40000, alpha = 3.10393\n",
      "\n",
      "Epoch:  2901/40000, total loss = 262.868, Fit loss U = 10.944, Fit loss F = 22.934, KL loss = 52234.906\n",
      "Epoch:  2901/40000, error_test = 1.02605, error_train = 1.02144\n",
      "Epoch:  2901/40000, error_f = 1.00001\n",
      "Epoch:  2901/40000, alpha = 3.09529\n",
      "\n",
      "Epoch:  2911/40000, total loss = 262.221, Fit loss U = 13.909, Fit loss F = 22.880, KL loss = 52076.242\n",
      "Epoch:  2911/40000, alpha = 3.08666\n",
      "\n",
      "Epoch:  2921/40000, total loss = 261.253, Fit loss U = 10.514, Fit loss F = 22.826, KL loss = 51917.105\n",
      "Epoch:  2921/40000, alpha = 3.07804\n",
      "\n",
      "Epoch:  2931/40000, total loss = 260.470, Fit loss U = 10.872, Fit loss F = 22.771, KL loss = 51757.551\n",
      "Epoch:  2931/40000, alpha = 3.06943\n",
      "\n",
      "Epoch:  2941/40000, total loss = 259.709, Fit loss U = 11.697, Fit loss F = 22.717, KL loss = 51597.578\n",
      "Epoch:  2941/40000, alpha = 3.06083\n",
      "\n",
      "Epoch:  2951/40000, total loss = 258.858, Fit loss U = 10.779, Fit loss F = 22.663, KL loss = 51437.176\n",
      "Epoch:  2951/40000, alpha = 3.05224\n",
      "\n",
      "Epoch:  2961/40000, total loss = 258.327, Fit loss U = 16.304, Fit loss F = 22.609, KL loss = 51276.320\n",
      "Epoch:  2961/40000, alpha = 3.04366\n",
      "\n",
      "Epoch:  2971/40000, total loss = 257.242, Fit loss U = 10.766, Fit loss F = 22.554, KL loss = 51115.215\n",
      "Epoch:  2971/40000, alpha = 3.03510\n",
      "\n",
      "Epoch:  2981/40000, total loss = 256.646, Fit loss U = 15.048, Fit loss F = 22.500, KL loss = 50953.715\n",
      "Epoch:  2981/40000, alpha = 3.02654\n",
      "\n",
      "Epoch:  2991/40000, total loss = 255.496, Fit loss U = 8.284, Fit loss F = 22.445, KL loss = 50791.953\n",
      "Epoch:  2991/40000, alpha = 3.01800\n",
      "\n",
      "Epoch:  3001/40000, total loss = 254.662, Fit loss U = 7.891, Fit loss F = 22.391, KL loss = 50629.594\n",
      "Epoch:  3001/40000, error_test = 1.05276, error_train = 0.97629\n",
      "Epoch:  3001/40000, error_f = 1.00001\n",
      "Epoch:  3001/40000, alpha = 3.00947\n",
      "\n",
      "Epoch:  3011/40000, total loss = 253.996, Fit loss U = 10.890, Fit loss F = 22.336, KL loss = 50466.855\n",
      "Epoch:  3011/40000, alpha = 3.00094\n",
      "\n",
      "Epoch:  3021/40000, total loss = 253.172, Fit loss U = 10.777, Fit loss F = 22.281, KL loss = 50303.820\n",
      "Epoch:  3021/40000, alpha = 2.99243\n",
      "\n",
      "Epoch:  3031/40000, total loss = 252.372, Fit loss U = 11.192, Fit loss F = 22.226, KL loss = 50140.203\n",
      "Epoch:  3031/40000, alpha = 2.98394\n",
      "\n",
      "Epoch:  3041/40000, total loss = 251.481, Fit loss U = 9.836, Fit loss F = 22.171, KL loss = 49976.082\n",
      "Epoch:  3041/40000, alpha = 2.97545\n",
      "\n",
      "Epoch:  3051/40000, total loss = 250.683, Fit loss U = 10.390, Fit loss F = 22.116, KL loss = 49811.449\n",
      "Epoch:  3051/40000, alpha = 2.96698\n",
      "\n",
      "Epoch:  3061/40000, total loss = 249.876, Fit loss U = 10.827, Fit loss F = 22.061, KL loss = 49646.375\n",
      "Epoch:  3061/40000, alpha = 2.95852\n",
      "\n",
      "Epoch:  3071/40000, total loss = 249.159, Fit loss U = 13.104, Fit loss F = 22.006, KL loss = 49480.762\n",
      "Epoch:  3071/40000, alpha = 2.95007\n",
      "\n",
      "Epoch:  3081/40000, total loss = 248.238, Fit loss U = 11.321, Fit loss F = 21.951, KL loss = 49314.805\n",
      "Epoch:  3081/40000, alpha = 2.94163\n",
      "\n",
      "Epoch:  3091/40000, total loss = 247.314, Fit loss U = 9.544, Fit loss F = 21.896, KL loss = 49148.500\n",
      "Epoch:  3091/40000, alpha = 2.93321\n",
      "\n",
      "Epoch:  3101/40000, total loss = 246.555, Fit loss U = 11.070, Fit loss F = 21.841, KL loss = 48981.895\n",
      "Epoch:  3101/40000, error_test = 1.00175, error_train = 0.99790\n",
      "Epoch:  3101/40000, error_f = 0.99999\n",
      "Epoch:  3101/40000, alpha = 2.92480\n",
      "\n",
      "Epoch:  3111/40000, total loss = 245.790, Fit loss U = 12.530, Fit loss F = 21.785, KL loss = 48814.777\n",
      "Epoch:  3111/40000, alpha = 2.91640\n",
      "\n",
      "Epoch:  3121/40000, total loss = 244.891, Fit loss U = 11.355, Fit loss F = 21.730, KL loss = 48647.301\n",
      "Epoch:  3121/40000, alpha = 2.90802\n",
      "\n",
      "Epoch:  3131/40000, total loss = 244.019, Fit loss U = 10.765, Fit loss F = 21.675, KL loss = 48479.418\n",
      "Epoch:  3131/40000, alpha = 2.89965\n",
      "\n",
      "Epoch:  3141/40000, total loss = 243.187, Fit loss U = 11.016, Fit loss F = 21.619, KL loss = 48311.137\n",
      "Epoch:  3141/40000, alpha = 2.89129\n",
      "\n",
      "Epoch:  3151/40000, total loss = 242.323, Fit loss U = 10.642, Fit loss F = 21.564, KL loss = 48142.559\n",
      "Epoch:  3151/40000, alpha = 2.88295\n",
      "\n",
      "Epoch:  3161/40000, total loss = 241.666, Fit loss U = 14.441, Fit loss F = 21.508, KL loss = 47973.656\n",
      "Epoch:  3161/40000, alpha = 2.87462\n",
      "\n",
      "Epoch:  3171/40000, total loss = 240.644, Fit loss U = 10.985, Fit loss F = 21.452, KL loss = 47804.438\n",
      "Epoch:  3171/40000, alpha = 2.86630\n",
      "\n",
      "Epoch:  3181/40000, total loss = 239.734, Fit loss U = 9.819, Fit loss F = 21.396, KL loss = 47634.691\n",
      "Epoch:  3181/40000, alpha = 2.85800\n",
      "\n",
      "Epoch:  3191/40000, total loss = 238.945, Fit loss U = 11.110, Fit loss F = 21.341, KL loss = 47464.445\n",
      "Epoch:  3191/40000, alpha = 2.84972\n",
      "\n",
      "Epoch:  3201/40000, total loss = 238.159, Fit loss U = 12.519, Fit loss F = 21.285, KL loss = 47293.719\n",
      "Epoch:  3201/40000, error_test = 1.03449, error_train = 1.02820\n",
      "Epoch:  3201/40000, error_f = 1.00000\n",
      "Epoch:  3201/40000, alpha = 2.84145\n",
      "\n",
      "Epoch:  3211/40000, total loss = 237.228, Fit loss U = 11.083, Fit loss F = 21.229, KL loss = 47122.504\n",
      "Epoch:  3211/40000, alpha = 2.83319\n",
      "\n",
      "Epoch:  3221/40000, total loss = 236.347, Fit loss U = 10.689, Fit loss F = 21.173, KL loss = 46950.816\n",
      "Epoch:  3221/40000, alpha = 2.82494\n",
      "\n",
      "Epoch:  3231/40000, total loss = 235.465, Fit loss U = 10.313, Fit loss F = 21.117, KL loss = 46778.633\n",
      "Epoch:  3231/40000, alpha = 2.81672\n",
      "\n",
      "Epoch:  3241/40000, total loss = 234.757, Fit loss U = 13.477, Fit loss F = 21.061, KL loss = 46606.066\n",
      "Epoch:  3241/40000, alpha = 2.80851\n",
      "\n",
      "Epoch:  3251/40000, total loss = 233.846, Fit loss U = 12.594, Fit loss F = 21.005, KL loss = 46433.199\n",
      "Epoch:  3251/40000, alpha = 2.80031\n",
      "\n",
      "Epoch:  3261/40000, total loss = 232.840, Fit loss U = 9.866, Fit loss F = 20.949, KL loss = 46259.914\n",
      "Epoch:  3261/40000, alpha = 2.79213\n",
      "\n",
      "Epoch:  3271/40000, total loss = 232.079, Fit loss U = 12.066, Fit loss F = 20.893, KL loss = 46086.156\n",
      "Epoch:  3271/40000, alpha = 2.78396\n",
      "\n",
      "Epoch:  3281/40000, total loss = 231.167, Fit loss U = 11.280, Fit loss F = 20.837, KL loss = 45912.277\n",
      "Epoch:  3281/40000, alpha = 2.77581\n",
      "\n",
      "Epoch:  3291/40000, total loss = 230.177, Fit loss U = 8.959, Fit loss F = 20.780, KL loss = 45738.059\n",
      "Epoch:  3291/40000, alpha = 2.76767\n",
      "\n",
      "Epoch:  3301/40000, total loss = 229.458, Fit loss U = 12.112, Fit loss F = 20.724, KL loss = 45563.312\n",
      "Epoch:  3301/40000, error_test = 1.04536, error_train = 0.96931\n",
      "Epoch:  3301/40000, error_f = 1.00000\n",
      "Epoch:  3301/40000, alpha = 2.75955\n",
      "\n",
      "Epoch:  3311/40000, total loss = 228.504, Fit loss U = 10.586, Fit loss F = 20.668, KL loss = 45388.297\n",
      "Epoch:  3311/40000, alpha = 2.75145\n",
      "\n",
      "Epoch:  3321/40000, total loss = 227.644, Fit loss U = 10.958, Fit loss F = 20.611, KL loss = 45213.062\n",
      "Epoch:  3321/40000, alpha = 2.74336\n",
      "\n",
      "Epoch:  3331/40000, total loss = 226.705, Fit loss U = 9.787, Fit loss F = 20.555, KL loss = 45037.520\n",
      "Epoch:  3331/40000, alpha = 2.73529\n",
      "\n",
      "Epoch:  3341/40000, total loss = 225.890, Fit loss U = 11.143, Fit loss F = 20.499, KL loss = 44861.559\n",
      "Epoch:  3341/40000, alpha = 2.72724\n",
      "\n",
      "Epoch:  3351/40000, total loss = 224.939, Fit loss U = 9.840, Fit loss F = 20.442, KL loss = 44685.062\n",
      "Epoch:  3351/40000, alpha = 2.71920\n",
      "\n",
      "Epoch:  3361/40000, total loss = 224.231, Fit loss U = 13.436, Fit loss F = 20.386, KL loss = 44508.043\n",
      "Epoch:  3361/40000, alpha = 2.71118\n",
      "\n",
      "Epoch:  3371/40000, total loss = 223.218, Fit loss U = 10.927, Fit loss F = 20.329, KL loss = 44331.074\n",
      "Epoch:  3371/40000, alpha = 2.70318\n",
      "\n",
      "Epoch:  3381/40000, total loss = 222.438, Fit loss U = 13.096, Fit loss F = 20.272, KL loss = 44153.914\n",
      "Epoch:  3381/40000, alpha = 2.69519\n",
      "\n",
      "Epoch:  3391/40000, total loss = 221.557, Fit loss U = 13.272, Fit loss F = 20.216, KL loss = 43976.551\n",
      "Epoch:  3391/40000, alpha = 2.68722\n",
      "\n",
      "Epoch:  3401/40000, total loss = 220.434, Fit loss U = 8.665, Fit loss F = 20.159, KL loss = 43798.652\n",
      "Epoch:  3401/40000, error_test = 1.00588, error_train = 0.99050\n",
      "Epoch:  3401/40000, error_f = 0.99999\n",
      "Epoch:  3401/40000, alpha = 2.67927\n",
      "\n",
      "Epoch:  3411/40000, total loss = 219.679, Fit loss U = 11.469, Fit loss F = 20.103, KL loss = 43620.180\n",
      "Epoch:  3411/40000, alpha = 2.67134\n",
      "\n",
      "Epoch:  3421/40000, total loss = 218.654, Fit loss U = 8.917, Fit loss F = 20.046, KL loss = 43441.250\n",
      "Epoch:  3421/40000, alpha = 2.66342\n",
      "\n",
      "Epoch:  3431/40000, total loss = 218.035, Fit loss U = 14.534, Fit loss F = 19.989, KL loss = 43261.832\n",
      "Epoch:  3431/40000, alpha = 2.65552\n",
      "\n",
      "Epoch:  3441/40000, total loss = 217.022, Fit loss U = 12.314, Fit loss F = 19.932, KL loss = 43082.012\n",
      "Epoch:  3441/40000, alpha = 2.64764\n",
      "\n",
      "Epoch:  3451/40000, total loss = 216.081, Fit loss U = 11.546, Fit loss F = 19.876, KL loss = 42901.898\n",
      "Epoch:  3451/40000, alpha = 2.63978\n",
      "\n",
      "Epoch:  3461/40000, total loss = 215.397, Fit loss U = 15.971, Fit loss F = 19.819, KL loss = 42721.520\n",
      "Epoch:  3461/40000, alpha = 2.63193\n",
      "\n",
      "Epoch:  3471/40000, total loss = 214.239, Fit loss U = 10.901, Fit loss F = 19.762, KL loss = 42541.172\n",
      "Epoch:  3471/40000, alpha = 2.62411\n",
      "\n",
      "Epoch:  3481/40000, total loss = 213.242, Fit loss U = 9.102, Fit loss F = 19.705, KL loss = 42360.398\n",
      "Epoch:  3481/40000, alpha = 2.61630\n",
      "\n",
      "Epoch:  3491/40000, total loss = 212.562, Fit loss U = 13.671, Fit loss F = 19.649, KL loss = 42179.137\n",
      "Epoch:  3491/40000, alpha = 2.60851\n",
      "\n",
      "Epoch:  3501/40000, total loss = 211.444, Fit loss U = 9.523, Fit loss F = 19.592, KL loss = 41997.684\n",
      "Epoch:  3501/40000, error_test = 1.02107, error_train = 1.05998\n",
      "Epoch:  3501/40000, error_f = 1.00000\n",
      "Epoch:  3501/40000, alpha = 2.60074\n",
      "\n",
      "Epoch:  3511/40000, total loss = 210.707, Fit loss U = 13.016, Fit loss F = 19.535, KL loss = 41815.828\n",
      "Epoch:  3511/40000, alpha = 2.59298\n",
      "\n",
      "Epoch:  3521/40000, total loss = 209.785, Fit loss U = 12.875, Fit loss F = 19.478, KL loss = 41633.547\n",
      "Epoch:  3521/40000, alpha = 2.58525\n",
      "\n",
      "Epoch:  3531/40000, total loss = 208.768, Fit loss U = 10.859, Fit loss F = 19.421, KL loss = 41450.734\n",
      "Epoch:  3531/40000, alpha = 2.57754\n",
      "\n",
      "Epoch:  3541/40000, total loss = 207.724, Fit loss U = 8.365, Fit loss F = 19.364, KL loss = 41267.574\n",
      "Epoch:  3541/40000, alpha = 2.56984\n",
      "\n",
      "Epoch:  3551/40000, total loss = 206.920, Fit loss U = 10.694, Fit loss F = 19.307, KL loss = 41084.020\n",
      "Epoch:  3551/40000, alpha = 2.56216\n",
      "\n",
      "Epoch:  3561/40000, total loss = 205.899, Fit loss U = 8.706, Fit loss F = 19.250, KL loss = 40900.336\n",
      "Epoch:  3561/40000, alpha = 2.55451\n",
      "\n",
      "Epoch:  3571/40000, total loss = 205.034, Fit loss U = 9.844, Fit loss F = 19.193, KL loss = 40716.332\n",
      "Epoch:  3571/40000, alpha = 2.54687\n",
      "\n",
      "Epoch:  3581/40000, total loss = 204.201, Fit loss U = 11.665, Fit loss F = 19.137, KL loss = 40532.129\n",
      "Epoch:  3581/40000, alpha = 2.53925\n",
      "\n",
      "Epoch:  3591/40000, total loss = 203.257, Fit loss U = 11.296, Fit loss F = 19.080, KL loss = 40347.660\n",
      "Epoch:  3591/40000, alpha = 2.53166\n",
      "\n",
      "Epoch:  3601/40000, total loss = 202.413, Fit loss U = 12.951, Fit loss F = 19.023, KL loss = 40162.914\n",
      "Epoch:  3601/40000, error_test = 1.01106, error_train = 0.99655\n",
      "Epoch:  3601/40000, error_f = 1.00000\n",
      "Epoch:  3601/40000, alpha = 2.52408\n",
      "\n",
      "Epoch:  3611/40000, total loss = 201.474, Fit loss U = 12.748, Fit loss F = 18.966, KL loss = 39977.742\n",
      "Epoch:  3611/40000, alpha = 2.51652\n",
      "\n",
      "Epoch:  3621/40000, total loss = 200.431, Fit loss U = 10.467, Fit loss F = 18.909, KL loss = 39792.367\n",
      "Epoch:  3621/40000, alpha = 2.50898\n",
      "\n",
      "Epoch:  3631/40000, total loss = 199.575, Fit loss U = 11.976, Fit loss F = 18.852, KL loss = 39606.809\n",
      "Epoch:  3631/40000, alpha = 2.50146\n",
      "\n",
      "Epoch:  3641/40000, total loss = 198.582, Fit loss U = 10.735, Fit loss F = 18.795, KL loss = 39421.059\n",
      "Epoch:  3641/40000, alpha = 2.49397\n",
      "\n",
      "Epoch:  3651/40000, total loss = 197.592, Fit loss U = 9.616, Fit loss F = 18.738, KL loss = 39234.922\n",
      "Epoch:  3651/40000, alpha = 2.48649\n",
      "\n",
      "Epoch:  3661/40000, total loss = 196.670, Fit loss U = 9.881, Fit loss F = 18.681, KL loss = 39048.430\n",
      "Epoch:  3661/40000, alpha = 2.47903\n",
      "\n",
      "Epoch:  3671/40000, total loss = 196.015, Fit loss U = 15.502, Fit loss F = 18.624, KL loss = 38861.793\n",
      "Epoch:  3671/40000, alpha = 2.47160\n",
      "\n",
      "Epoch:  3681/40000, total loss = 195.023, Fit loss U = 14.393, Fit loss F = 18.567, KL loss = 38674.922\n",
      "Epoch:  3681/40000, alpha = 2.46418\n",
      "\n",
      "Epoch:  3691/40000, total loss = 193.980, Fit loss U = 12.305, Fit loss F = 18.510, KL loss = 38487.762\n",
      "Epoch:  3691/40000, alpha = 2.45679\n",
      "\n",
      "Epoch:  3701/40000, total loss = 192.888, Fit loss U = 9.259, Fit loss F = 18.453, KL loss = 38300.469\n",
      "Epoch:  3701/40000, error_test = 1.00624, error_train = 1.01886\n",
      "Epoch:  3701/40000, error_f = 1.00000\n",
      "Epoch:  3701/40000, alpha = 2.44941\n",
      "\n",
      "Epoch:  3711/40000, total loss = 192.124, Fit loss U = 12.807, Fit loss F = 18.397, KL loss = 38112.742\n",
      "Epoch:  3711/40000, alpha = 2.44206\n",
      "\n",
      "Epoch:  3721/40000, total loss = 191.085, Fit loss U = 10.886, Fit loss F = 18.340, KL loss = 37924.668\n",
      "Epoch:  3721/40000, alpha = 2.43473\n",
      "\n",
      "Epoch:  3731/40000, total loss = 190.101, Fit loss U = 10.095, Fit loss F = 18.283, KL loss = 37736.340\n",
      "Epoch:  3731/40000, alpha = 2.42742\n",
      "\n",
      "Epoch:  3741/40000, total loss = 189.087, Fit loss U = 8.740, Fit loss F = 18.226, KL loss = 37547.746\n",
      "Epoch:  3741/40000, alpha = 2.42013\n",
      "\n",
      "Epoch:  3751/40000, total loss = 188.343, Fit loss U = 12.785, Fit loss F = 18.169, KL loss = 37359.133\n",
      "Epoch:  3751/40000, alpha = 2.41287\n",
      "\n",
      "Epoch:  3761/40000, total loss = 187.248, Fit loss U = 9.824, Fit loss F = 18.112, KL loss = 37170.203\n",
      "Epoch:  3761/40000, alpha = 2.40562\n",
      "\n",
      "Epoch:  3771/40000, total loss = 186.367, Fit loss U = 11.194, Fit loss F = 18.055, KL loss = 36980.867\n",
      "Epoch:  3771/40000, alpha = 2.39840\n",
      "\n",
      "Epoch:  3781/40000, total loss = 185.394, Fit loss U = 10.728, Fit loss F = 17.999, KL loss = 36791.453\n",
      "Epoch:  3781/40000, alpha = 2.39119\n",
      "\n",
      "Epoch:  3791/40000, total loss = 184.594, Fit loss U = 13.751, Fit loss F = 17.942, KL loss = 36601.781\n",
      "Epoch:  3791/40000, alpha = 2.38401\n",
      "\n",
      "Epoch:  3801/40000, total loss = 183.493, Fit loss U = 10.788, Fit loss F = 17.885, KL loss = 36411.926\n",
      "Epoch:  3801/40000, error_test = 1.01353, error_train = 1.01799\n",
      "Epoch:  3801/40000, error_f = 0.99999\n",
      "Epoch:  3801/40000, alpha = 2.37686\n",
      "\n",
      "Epoch:  3811/40000, total loss = 182.526, Fit loss U = 10.510, Fit loss F = 17.829, KL loss = 36221.844\n",
      "Epoch:  3811/40000, alpha = 2.36972\n",
      "\n",
      "Epoch:  3821/40000, total loss = 181.646, Fit loss U = 12.011, Fit loss F = 17.772, KL loss = 36031.434\n",
      "Epoch:  3821/40000, alpha = 2.36261\n",
      "\n",
      "Epoch:  3831/40000, total loss = 180.697, Fit loss U = 12.148, Fit loss F = 17.715, KL loss = 35840.867\n",
      "Epoch:  3831/40000, alpha = 2.35551\n",
      "\n",
      "Epoch:  3841/40000, total loss = 179.613, Fit loss U = 9.592, Fit loss F = 17.659, KL loss = 35650.121\n",
      "Epoch:  3841/40000, alpha = 2.34844\n",
      "\n",
      "Epoch:  3851/40000, total loss = 178.808, Fit loss U = 12.631, Fit loss F = 17.602, KL loss = 35459.258\n",
      "Epoch:  3851/40000, alpha = 2.34140\n",
      "\n",
      "Epoch:  3861/40000, total loss = 177.758, Fit loss U = 10.766, Fit loss F = 17.545, KL loss = 35268.422\n",
      "Epoch:  3861/40000, alpha = 2.33437\n",
      "\n",
      "Epoch:  3871/40000, total loss = 176.867, Fit loss U = 12.117, Fit loss F = 17.489, KL loss = 35077.430\n",
      "Epoch:  3871/40000, alpha = 2.32737\n",
      "\n",
      "Epoch:  3881/40000, total loss = 175.806, Fit loss U = 10.076, Fit loss F = 17.432, KL loss = 34886.102\n",
      "Epoch:  3881/40000, alpha = 2.32039\n",
      "\n",
      "Epoch:  3891/40000, total loss = 175.051, Fit loss U = 14.189, Fit loss F = 17.376, KL loss = 34694.523\n",
      "Epoch:  3891/40000, alpha = 2.31343\n",
      "\n",
      "Epoch:  3901/40000, total loss = 173.977, Fit loss U = 11.919, Fit loss F = 17.320, KL loss = 34502.965\n",
      "Epoch:  3901/40000, error_test = 1.02248, error_train = 1.03619\n",
      "Epoch:  3901/40000, error_f = 1.00000\n",
      "Epoch:  3901/40000, alpha = 2.30650\n",
      "\n",
      "Epoch:  3911/40000, total loss = 172.972, Fit loss U = 11.048, Fit loss F = 17.263, KL loss = 34311.227\n",
      "Epoch:  3911/40000, alpha = 2.29959\n",
      "\n",
      "Epoch:  3921/40000, total loss = 172.005, Fit loss U = 10.965, Fit loss F = 17.207, KL loss = 34119.207\n",
      "Epoch:  3921/40000, alpha = 2.29270\n",
      "\n",
      "Epoch:  3931/40000, total loss = 170.975, Fit loss U = 9.638, Fit loss F = 17.151, KL loss = 33927.121\n",
      "Epoch:  3931/40000, alpha = 2.28583\n",
      "\n",
      "Epoch:  3941/40000, total loss = 169.953, Fit loss U = 8.474, Fit loss F = 17.094, KL loss = 33734.875\n",
      "Epoch:  3941/40000, alpha = 2.27899\n",
      "\n",
      "Epoch:  3951/40000, total loss = 169.146, Fit loss U = 11.643, Fit loss F = 17.038, KL loss = 33542.445\n",
      "Epoch:  3951/40000, alpha = 2.27217\n",
      "\n",
      "Epoch:  3961/40000, total loss = 168.192, Fit loss U = 11.860, Fit loss F = 16.982, KL loss = 33349.930\n",
      "Epoch:  3961/40000, alpha = 2.26537\n",
      "\n",
      "Epoch:  3971/40000, total loss = 167.146, Fit loss U = 10.250, Fit loss F = 16.926, KL loss = 33157.398\n",
      "Epoch:  3971/40000, alpha = 2.25860\n",
      "\n",
      "Epoch:  3981/40000, total loss = 166.293, Fit loss U = 12.506, Fit loss F = 16.870, KL loss = 32964.855\n",
      "Epoch:  3981/40000, alpha = 2.25185\n",
      "\n",
      "Epoch:  3991/40000, total loss = 165.227, Fit loss U = 10.503, Fit loss F = 16.814, KL loss = 32772.145\n",
      "Epoch:  3991/40000, alpha = 2.24513\n",
      "\n",
      "Epoch:  4001/40000, total loss = 164.317, Fit loss U = 11.679, Fit loss F = 16.758, KL loss = 32579.129\n",
      "Epoch:  4001/40000, error_test = 0.95831, error_train = 0.96461\n",
      "Epoch:  4001/40000, error_f = 1.00000\n",
      "Epoch:  4001/40000, alpha = 2.23842\n",
      "\n",
      "Epoch:  4011/40000, total loss = 163.369, Fit loss U = 12.077, Fit loss F = 16.702, KL loss = 32385.969\n",
      "Epoch:  4011/40000, alpha = 2.23174\n",
      "\n",
      "Epoch:  4021/40000, total loss = 162.321, Fit loss U = 10.516, Fit loss F = 16.646, KL loss = 32192.654\n",
      "Epoch:  4021/40000, alpha = 2.22509\n",
      "\n",
      "Epoch:  4031/40000, total loss = 161.272, Fit loss U = 8.911, Fit loss F = 16.590, KL loss = 31999.350\n",
      "Epoch:  4031/40000, alpha = 2.21846\n",
      "\n",
      "Epoch:  4041/40000, total loss = 160.552, Fit loss U = 13.894, Fit loss F = 16.534, KL loss = 31806.150\n",
      "Epoch:  4041/40000, alpha = 2.21185\n",
      "\n",
      "Epoch:  4051/40000, total loss = 159.539, Fit loss U = 13.036, Fit loss F = 16.479, KL loss = 31612.730\n",
      "Epoch:  4051/40000, alpha = 2.20527\n",
      "\n",
      "Epoch:  4061/40000, total loss = 158.513, Fit loss U = 11.897, Fit loss F = 16.423, KL loss = 31419.408\n",
      "Epoch:  4061/40000, alpha = 2.19870\n",
      "\n",
      "Epoch:  4071/40000, total loss = 157.431, Fit loss U = 9.662, Fit loss F = 16.368, KL loss = 31225.875\n",
      "Epoch:  4071/40000, alpha = 2.19217\n",
      "\n",
      "Epoch:  4081/40000, total loss = 156.503, Fit loss U = 10.527, Fit loss F = 16.312, KL loss = 31032.180\n",
      "Epoch:  4081/40000, alpha = 2.18566\n",
      "\n",
      "Epoch:  4091/40000, total loss = 155.639, Fit loss U = 12.697, Fit loss F = 16.257, KL loss = 30838.348\n",
      "Epoch:  4091/40000, alpha = 2.17917\n",
      "\n",
      "Epoch:  4101/40000, total loss = 154.485, Fit loss U = 9.004, Fit loss F = 16.201, KL loss = 30644.949\n",
      "Epoch:  4101/40000, error_test = 1.00986, error_train = 1.00175\n",
      "Epoch:  4101/40000, error_f = 1.00000\n",
      "Epoch:  4101/40000, alpha = 2.17270\n",
      "\n",
      "Epoch:  4111/40000, total loss = 153.657, Fit loss U = 11.817, Fit loss F = 16.146, KL loss = 30451.812\n",
      "Epoch:  4111/40000, alpha = 2.16626\n",
      "\n",
      "Epoch:  4121/40000, total loss = 152.579, Fit loss U = 9.626, Fit loss F = 16.091, KL loss = 30258.547\n",
      "Epoch:  4121/40000, alpha = 2.15985\n",
      "\n",
      "Epoch:  4131/40000, total loss = 151.690, Fit loss U = 11.272, Fit loss F = 16.035, KL loss = 30064.912\n",
      "Epoch:  4131/40000, alpha = 2.15345\n",
      "\n",
      "Epoch:  4141/40000, total loss = 150.926, Fit loss U = 15.413, Fit loss F = 15.980, KL loss = 29871.260\n",
      "Epoch:  4141/40000, alpha = 2.14709\n",
      "\n",
      "Epoch:  4151/40000, total loss = 149.693, Fit loss U = 10.162, Fit loss F = 15.925, KL loss = 29677.721\n",
      "Epoch:  4151/40000, alpha = 2.14074\n",
      "\n",
      "Epoch:  4161/40000, total loss = 148.823, Fit loss U = 12.157, Fit loss F = 15.870, KL loss = 29484.230\n",
      "Epoch:  4161/40000, alpha = 2.13442\n",
      "\n",
      "Epoch:  4171/40000, total loss = 147.958, Fit loss U = 14.298, Fit loss F = 15.816, KL loss = 29290.508\n",
      "Epoch:  4171/40000, alpha = 2.12813\n",
      "\n",
      "Epoch:  4181/40000, total loss = 146.817, Fit loss U = 10.894, Fit loss F = 15.761, KL loss = 29096.768\n",
      "Epoch:  4181/40000, alpha = 2.12186\n",
      "\n",
      "Epoch:  4191/40000, total loss = 146.047, Fit loss U = 14.918, Fit loss F = 15.706, KL loss = 28903.107\n",
      "Epoch:  4191/40000, alpha = 2.11561\n",
      "\n",
      "Epoch:  4201/40000, total loss = 144.942, Fit loss U = 12.223, Fit loss F = 15.651, KL loss = 28709.562\n",
      "Epoch:  4201/40000, error_test = 1.06128, error_train = 1.00546\n",
      "Epoch:  4201/40000, error_f = 1.00000\n",
      "Epoch:  4201/40000, alpha = 2.10939\n",
      "\n",
      "Epoch:  4211/40000, total loss = 143.755, Fit loss U = 7.911, Fit loss F = 15.597, KL loss = 28515.986\n",
      "Epoch:  4211/40000, alpha = 2.10319\n",
      "\n",
      "Epoch:  4221/40000, total loss = 142.879, Fit loss U = 9.824, Fit loss F = 15.542, KL loss = 28322.180\n",
      "Epoch:  4221/40000, alpha = 2.09702\n",
      "\n",
      "Epoch:  4231/40000, total loss = 141.864, Fit loss U = 8.942, Fit loss F = 15.488, KL loss = 28128.418\n",
      "Epoch:  4231/40000, alpha = 2.09087\n",
      "\n",
      "Epoch:  4241/40000, total loss = 141.071, Fit loss U = 12.512, Fit loss F = 15.433, KL loss = 27934.791\n",
      "Epoch:  4241/40000, alpha = 2.08475\n",
      "\n",
      "Epoch:  4251/40000, total loss = 140.151, Fit loss U = 13.493, Fit loss F = 15.379, KL loss = 27741.445\n",
      "Epoch:  4251/40000, alpha = 2.07865\n",
      "\n",
      "Epoch:  4261/40000, total loss = 138.993, Fit loss U = 9.705, Fit loss F = 15.325, KL loss = 27548.342\n",
      "Epoch:  4261/40000, alpha = 2.07257\n",
      "\n",
      "Epoch:  4271/40000, total loss = 137.967, Fit loss U = 8.563, Fit loss F = 15.271, KL loss = 27355.162\n",
      "Epoch:  4271/40000, alpha = 2.06652\n",
      "\n",
      "Epoch:  4281/40000, total loss = 137.240, Fit loss U = 13.405, Fit loss F = 15.217, KL loss = 27161.873\n",
      "Epoch:  4281/40000, alpha = 2.06050\n",
      "\n",
      "Epoch:  4291/40000, total loss = 136.033, Fit loss U = 8.634, Fit loss F = 15.163, KL loss = 26968.631\n",
      "Epoch:  4291/40000, alpha = 2.05450\n",
      "\n",
      "Epoch:  4301/40000, total loss = 135.145, Fit loss U = 10.254, Fit loss F = 15.109, KL loss = 26775.264\n",
      "Epoch:  4301/40000, error_test = 1.02032, error_train = 1.00202\n",
      "Epoch:  4301/40000, error_f = 1.00000\n",
      "Epoch:  4301/40000, alpha = 2.04852\n",
      "\n",
      "Epoch:  4311/40000, total loss = 134.151, Fit loss U = 9.749, Fit loss F = 15.056, KL loss = 26582.164\n",
      "Epoch:  4311/40000, alpha = 2.04257\n",
      "\n",
      "Epoch:  4321/40000, total loss = 133.120, Fit loss U = 8.415, Fit loss F = 15.002, KL loss = 26389.885\n",
      "Epoch:  4321/40000, alpha = 2.03665\n",
      "\n",
      "Epoch:  4331/40000, total loss = 132.267, Fit loss U = 10.623, Fit loss F = 14.948, KL loss = 26197.641\n",
      "Epoch:  4331/40000, alpha = 2.03075\n",
      "\n",
      "Epoch:  4341/40000, total loss = 131.260, Fit loss U = 9.746, Fit loss F = 14.895, KL loss = 26005.520\n",
      "Epoch:  4341/40000, alpha = 2.02487\n",
      "\n",
      "Epoch:  4351/40000, total loss = 130.371, Fit loss U = 11.254, Fit loss F = 14.842, KL loss = 25813.324\n",
      "Epoch:  4351/40000, alpha = 2.01902\n",
      "\n",
      "Epoch:  4361/40000, total loss = 129.619, Fit loss U = 15.463, Fit loss F = 14.789, KL loss = 25621.305\n",
      "Epoch:  4361/40000, alpha = 2.01319\n",
      "\n",
      "Epoch:  4371/40000, total loss = 128.385, Fit loss U = 10.018, Fit loss F = 14.735, KL loss = 25429.480\n",
      "Epoch:  4371/40000, alpha = 2.00739\n",
      "\n",
      "Epoch:  4381/40000, total loss = 127.429, Fit loss U = 10.148, Fit loss F = 14.682, KL loss = 25237.506\n",
      "Epoch:  4381/40000, alpha = 2.00161\n",
      "\n",
      "Epoch:  4391/40000, total loss = 126.355, Fit loss U = 7.907, Fit loss F = 14.629, KL loss = 25045.633\n",
      "Epoch:  4391/40000, alpha = 1.99586\n",
      "\n",
      "Epoch:  4401/40000, total loss = 125.477, Fit loss U = 9.558, Fit loss F = 14.577, KL loss = 24854.041\n",
      "Epoch:  4401/40000, error_test = 1.01377, error_train = 1.00038\n",
      "Epoch:  4401/40000, error_f = 1.00000\n",
      "Epoch:  4401/40000, alpha = 1.99013\n",
      "\n",
      "Epoch:  4411/40000, total loss = 124.572, Fit loss U = 10.667, Fit loss F = 14.524, KL loss = 24662.514\n",
      "Epoch:  4411/40000, alpha = 1.98443\n",
      "\n",
      "Epoch:  4421/40000, total loss = 123.601, Fit loss U = 10.429, Fit loss F = 14.471, KL loss = 24471.178\n",
      "Epoch:  4421/40000, alpha = 1.97875\n",
      "\n",
      "Epoch:  4431/40000, total loss = 122.603, Fit loss U = 9.626, Fit loss F = 14.419, KL loss = 24280.225\n",
      "Epoch:  4431/40000, alpha = 1.97310\n",
      "\n",
      "Epoch:  4441/40000, total loss = 121.742, Fit loss U = 11.515, Fit loss F = 14.366, KL loss = 24089.543\n",
      "Epoch:  4441/40000, alpha = 1.96747\n",
      "\n",
      "Epoch:  4451/40000, total loss = 120.740, Fit loss U = 10.586, Fit loss F = 14.314, KL loss = 23899.051\n",
      "Epoch:  4451/40000, alpha = 1.96187\n",
      "\n",
      "Epoch:  4461/40000, total loss = 119.771, Fit loss U = 10.275, Fit loss F = 14.262, KL loss = 23708.799\n",
      "Epoch:  4461/40000, alpha = 1.95629\n",
      "\n",
      "Epoch:  4471/40000, total loss = 118.892, Fit loss U = 11.752, Fit loss F = 14.210, KL loss = 23518.719\n",
      "Epoch:  4471/40000, alpha = 1.95074\n",
      "\n",
      "Epoch:  4481/40000, total loss = 117.916, Fit loss U = 11.248, Fit loss F = 14.158, KL loss = 23329.092\n",
      "Epoch:  4481/40000, alpha = 1.94521\n",
      "\n",
      "Epoch:  4491/40000, total loss = 117.019, Fit loss U = 12.257, Fit loss F = 14.106, KL loss = 23140.098\n",
      "Epoch:  4491/40000, alpha = 1.93971\n",
      "\n",
      "Epoch:  4501/40000, total loss = 116.076, Fit loss U = 12.301, Fit loss F = 14.054, KL loss = 22951.703\n",
      "Epoch:  4501/40000, error_test = 1.00698, error_train = 0.97529\n",
      "Epoch:  4501/40000, error_f = 1.00000\n",
      "Epoch:  4501/40000, alpha = 1.93423\n",
      "\n",
      "Epoch:  4511/40000, total loss = 115.368, Fit loss U = 17.012, Fit loss F = 14.003, KL loss = 22763.402\n",
      "Epoch:  4511/40000, alpha = 1.92877\n",
      "\n",
      "Epoch:  4521/40000, total loss = 114.122, Fit loss U = 10.944, Fit loss F = 13.951, KL loss = 22575.355\n",
      "Epoch:  4521/40000, alpha = 1.92334\n",
      "\n",
      "Epoch:  4531/40000, total loss = 113.159, Fit loss U = 10.534, Fit loss F = 13.900, KL loss = 22387.398\n",
      "Epoch:  4531/40000, alpha = 1.91794\n",
      "\n",
      "Epoch:  4541/40000, total loss = 112.248, Fit loss U = 11.153, Fit loss F = 13.849, KL loss = 22199.520\n",
      "Epoch:  4541/40000, alpha = 1.91256\n",
      "\n",
      "Epoch:  4551/40000, total loss = 111.309, Fit loss U = 11.172, Fit loss F = 13.798, KL loss = 22012.113\n",
      "Epoch:  4551/40000, alpha = 1.90721\n",
      "\n",
      "Epoch:  4561/40000, total loss = 110.247, Fit loss U = 8.687, Fit loss F = 13.747, KL loss = 21825.061\n",
      "Epoch:  4561/40000, alpha = 1.90188\n",
      "\n",
      "Epoch:  4571/40000, total loss = 109.356, Fit loss U = 9.601, Fit loss F = 13.696, KL loss = 21638.184\n",
      "Epoch:  4571/40000, alpha = 1.89657\n",
      "\n",
      "Epoch:  4581/40000, total loss = 108.480, Fit loss U = 10.792, Fit loss F = 13.645, KL loss = 21451.568\n",
      "Epoch:  4581/40000, alpha = 1.89129\n",
      "\n",
      "Epoch:  4591/40000, total loss = 107.390, Fit loss U = 7.660, Fit loss F = 13.594, KL loss = 21265.553\n",
      "Epoch:  4591/40000, alpha = 1.88604\n",
      "\n",
      "Epoch:  4601/40000, total loss = 106.743, Fit loss U = 13.308, Fit loss F = 13.544, KL loss = 21080.072\n",
      "Epoch:  4601/40000, error_test = 1.00464, error_train = 1.08328\n",
      "Epoch:  4601/40000, error_f = 1.00000\n",
      "Epoch:  4601/40000, alpha = 1.88081\n",
      "\n",
      "Epoch:  4611/40000, total loss = 105.727, Fit loss U = 11.579, Fit loss F = 13.493, KL loss = 20894.695\n",
      "Epoch:  4611/40000, alpha = 1.87560\n",
      "\n",
      "Epoch:  4621/40000, total loss = 104.738, Fit loss U = 10.375, Fit loss F = 13.443, KL loss = 20709.469\n",
      "Epoch:  4621/40000, alpha = 1.87042\n",
      "\n",
      "Epoch:  4631/40000, total loss = 103.715, Fit loss U = 8.441, Fit loss F = 13.393, KL loss = 20524.711\n",
      "Epoch:  4631/40000, alpha = 1.86526\n",
      "\n",
      "Epoch:  4641/40000, total loss = 102.847, Fit loss U = 9.578, Fit loss F = 13.343, KL loss = 20340.188\n",
      "Epoch:  4641/40000, alpha = 1.86013\n",
      "\n",
      "Epoch:  4651/40000, total loss = 101.965, Fit loss U = 10.399, Fit loss F = 13.293, KL loss = 20156.109\n",
      "Epoch:  4651/40000, alpha = 1.85502\n",
      "\n",
      "Epoch:  4661/40000, total loss = 101.053, Fit loss U = 10.567, Fit loss F = 13.243, KL loss = 19972.494\n",
      "Epoch:  4661/40000, alpha = 1.84994\n",
      "\n",
      "Epoch:  4671/40000, total loss = 100.083, Fit loss U = 9.535, Fit loss F = 13.194, KL loss = 19789.404\n",
      "Epoch:  4671/40000, alpha = 1.84488\n",
      "\n",
      "Epoch:  4681/40000, total loss = 99.138, Fit loss U = 8.943, Fit loss F = 13.144, KL loss = 19606.799\n",
      "Epoch:  4681/40000, alpha = 1.83985\n",
      "\n",
      "Epoch:  4691/40000, total loss = 98.258, Fit loss U = 9.588, Fit loss F = 13.095, KL loss = 19424.703\n",
      "Epoch:  4691/40000, alpha = 1.83484\n",
      "\n",
      "Epoch:  4701/40000, total loss = 97.557, Fit loss U = 13.799, Fit loss F = 13.046, KL loss = 19242.996\n",
      "Epoch:  4701/40000, error_test = 1.02485, error_train = 0.99024\n",
      "Epoch:  4701/40000, error_f = 1.00000\n",
      "Epoch:  4701/40000, alpha = 1.82985\n",
      "\n",
      "Epoch:  4711/40000, total loss = 96.335, Fit loss U = 7.497, Fit loss F = 12.997, KL loss = 19061.996\n",
      "Epoch:  4711/40000, alpha = 1.82489\n",
      "\n",
      "Epoch:  4721/40000, total loss = 95.594, Fit loss U = 10.785, Fit loss F = 12.948, KL loss = 18881.377\n",
      "Epoch:  4721/40000, alpha = 1.81996\n",
      "\n",
      "Epoch:  4731/40000, total loss = 94.663, Fit loss U = 10.232, Fit loss F = 12.899, KL loss = 18701.189\n",
      "Epoch:  4731/40000, alpha = 1.81505\n",
      "\n",
      "Epoch:  4741/40000, total loss = 93.745, Fit loss U = 9.935, Fit loss F = 12.851, KL loss = 18521.195\n",
      "Epoch:  4741/40000, alpha = 1.81016\n",
      "\n",
      "Epoch:  4751/40000, total loss = 92.793, Fit loss U = 8.865, Fit loss F = 12.802, KL loss = 18341.838\n",
      "Epoch:  4751/40000, alpha = 1.80530\n",
      "\n",
      "Epoch:  4761/40000, total loss = 91.995, Fit loss U = 10.828, Fit loss F = 12.754, KL loss = 18163.182\n",
      "Epoch:  4761/40000, alpha = 1.80046\n",
      "\n",
      "Epoch:  4771/40000, total loss = 91.233, Fit loss U = 13.432, Fit loss F = 12.705, KL loss = 17985.289\n",
      "Epoch:  4771/40000, alpha = 1.79565\n",
      "\n",
      "Epoch:  4781/40000, total loss = 90.152, Fit loss U = 9.572, Fit loss F = 12.657, KL loss = 17808.150\n",
      "Epoch:  4781/40000, alpha = 1.79086\n",
      "\n",
      "Epoch:  4791/40000, total loss = 89.212, Fit loss U = 8.486, Fit loss F = 12.609, KL loss = 17631.387\n",
      "Epoch:  4791/40000, alpha = 1.78609\n",
      "\n",
      "Epoch:  4801/40000, total loss = 88.642, Fit loss U = 14.773, Fit loss F = 12.562, KL loss = 17455.143\n",
      "Epoch:  4801/40000, error_test = 0.99590, error_train = 0.99874\n",
      "Epoch:  4801/40000, error_f = 1.00000\n",
      "Epoch:  4801/40000, alpha = 1.78135\n",
      "\n",
      "Epoch:  4811/40000, total loss = 87.478, Fit loss U = 9.067, Fit loss F = 12.514, KL loss = 17279.795\n",
      "Epoch:  4811/40000, alpha = 1.77663\n",
      "\n",
      "Epoch:  4821/40000, total loss = 86.602, Fit loss U = 9.110, Fit loss F = 12.466, KL loss = 17104.703\n",
      "Epoch:  4821/40000, alpha = 1.77194\n",
      "\n",
      "Epoch:  4831/40000, total loss = 85.845, Fit loss U = 11.467, Fit loss F = 12.419, KL loss = 16930.053\n",
      "Epoch:  4831/40000, alpha = 1.76727\n",
      "\n",
      "Epoch:  4841/40000, total loss = 84.890, Fit loss U = 9.842, Fit loss F = 12.372, KL loss = 16755.801\n",
      "Epoch:  4841/40000, alpha = 1.76262\n",
      "\n",
      "Epoch:  4851/40000, total loss = 84.069, Fit loss U = 10.835, Fit loss F = 12.325, KL loss = 16582.162\n",
      "Epoch:  4851/40000, alpha = 1.75800\n",
      "\n",
      "Epoch:  4861/40000, total loss = 83.057, Fit loss U = 7.936, Fit loss F = 12.278, KL loss = 16409.340\n",
      "Epoch:  4861/40000, alpha = 1.75340\n",
      "\n",
      "Epoch:  4871/40000, total loss = 82.376, Fit loss U = 11.574, Fit loss F = 12.231, KL loss = 16237.104\n",
      "Epoch:  4871/40000, alpha = 1.74883\n",
      "\n",
      "Epoch:  4881/40000, total loss = 81.347, Fit loss U = 8.211, Fit loss F = 12.185, KL loss = 16065.520\n",
      "Epoch:  4881/40000, alpha = 1.74428\n",
      "\n",
      "Epoch:  4891/40000, total loss = 80.614, Fit loss U = 10.715, Fit loss F = 12.138, KL loss = 15894.338\n",
      "Epoch:  4891/40000, alpha = 1.73975\n",
      "\n",
      "Epoch:  4901/40000, total loss = 79.697, Fit loss U = 9.471, Fit loss F = 12.092, KL loss = 15723.823\n",
      "Epoch:  4901/40000, error_test = 1.01934, error_train = 0.99625\n",
      "Epoch:  4901/40000, error_f = 1.00000\n",
      "Epoch:  4901/40000, alpha = 1.73525\n",
      "\n",
      "Epoch:  4911/40000, total loss = 79.009, Fit loss U = 12.682, Fit loss F = 12.046, KL loss = 15554.502\n",
      "Epoch:  4911/40000, alpha = 1.73077\n",
      "\n",
      "Epoch:  4921/40000, total loss = 78.205, Fit loss U = 13.500, Fit loss F = 12.000, KL loss = 15385.996\n",
      "Epoch:  4921/40000, alpha = 1.72631\n",
      "\n",
      "Epoch:  4931/40000, total loss = 77.238, Fit loss U = 10.995, Fit loss F = 11.954, KL loss = 15218.161\n",
      "Epoch:  4931/40000, alpha = 1.72188\n",
      "\n",
      "Epoch:  4941/40000, total loss = 76.313, Fit loss U = 9.259, Fit loss F = 11.908, KL loss = 15050.949\n",
      "Epoch:  4941/40000, alpha = 1.71747\n",
      "\n",
      "Epoch:  4951/40000, total loss = 75.661, Fit loss U = 12.908, Fit loss F = 11.863, KL loss = 14884.457\n",
      "Epoch:  4951/40000, alpha = 1.71308\n",
      "\n",
      "Epoch:  4961/40000, total loss = 74.624, Fit loss U = 8.795, Fit loss F = 11.817, KL loss = 14718.640\n",
      "Epoch:  4961/40000, alpha = 1.70872\n",
      "\n",
      "Epoch:  4971/40000, total loss = 73.736, Fit loss U = 7.618, Fit loss F = 11.772, KL loss = 14553.314\n",
      "Epoch:  4971/40000, alpha = 1.70438\n",
      "\n",
      "Epoch:  4981/40000, total loss = 73.048, Fit loss U = 10.353, Fit loss F = 11.727, KL loss = 14388.861\n",
      "Epoch:  4981/40000, alpha = 1.70007\n",
      "\n",
      "Epoch:  4991/40000, total loss = 72.327, Fit loss U = 12.332, Fit loss F = 11.682, KL loss = 14225.323\n",
      "Epoch:  4991/40000, alpha = 1.69577\n",
      "\n",
      "Epoch:  5001/40000, total loss = 71.379, Fit loss U = 9.683, Fit loss F = 11.637, KL loss = 14062.524\n",
      "Epoch:  5001/40000, error_test = 1.03620, error_train = 1.01652\n",
      "Epoch:  5001/40000, error_f = 1.00000\n",
      "Epoch:  5001/40000, alpha = 1.69150\n",
      "\n",
      "Epoch:  5011/40000, total loss = 70.555, Fit loss U = 9.441, Fit loss F = 11.593, KL loss = 13900.562\n",
      "Epoch:  5011/40000, alpha = 1.68726\n",
      "\n",
      "Epoch:  5021/40000, total loss = 69.881, Fit loss U = 12.154, Fit loss F = 11.548, KL loss = 13739.251\n",
      "Epoch:  5021/40000, alpha = 1.68303\n",
      "\n",
      "Epoch:  5031/40000, total loss = 68.948, Fit loss U = 9.566, Fit loss F = 11.504, KL loss = 13578.811\n",
      "Epoch:  5031/40000, alpha = 1.67883\n",
      "\n",
      "Epoch:  5041/40000, total loss = 68.034, Fit loss U = 7.312, Fit loss F = 11.460, KL loss = 13419.090\n",
      "Epoch:  5041/40000, alpha = 1.67465\n",
      "\n",
      "Epoch:  5051/40000, total loss = 67.436, Fit loss U = 11.327, Fit loss F = 11.416, KL loss = 13259.873\n",
      "Epoch:  5051/40000, alpha = 1.67050\n",
      "\n",
      "Epoch:  5061/40000, total loss = 66.557, Fit loss U = 9.633, Fit loss F = 11.372, KL loss = 13101.400\n",
      "Epoch:  5061/40000, alpha = 1.66636\n",
      "\n",
      "Epoch:  5071/40000, total loss = 65.730, Fit loss U = 8.867, Fit loss F = 11.328, KL loss = 12943.952\n",
      "Epoch:  5071/40000, alpha = 1.66226\n",
      "\n",
      "Epoch:  5081/40000, total loss = 64.961, Fit loss U = 9.213, Fit loss F = 11.285, KL loss = 12787.192\n",
      "Epoch:  5081/40000, alpha = 1.65817\n",
      "\n",
      "Epoch:  5091/40000, total loss = 64.326, Fit loss U = 12.152, Fit loss F = 11.241, KL loss = 12631.310\n",
      "Epoch:  5091/40000, alpha = 1.65410\n",
      "\n",
      "Epoch:  5101/40000, total loss = 63.435, Fit loss U = 9.862, Fit loss F = 11.198, KL loss = 12476.366\n",
      "Epoch:  5101/40000, error_test = 1.00821, error_train = 1.03919\n",
      "Epoch:  5101/40000, error_f = 1.00000\n",
      "Epoch:  5101/40000, alpha = 1.65006\n",
      "\n",
      "Epoch:  5111/40000, total loss = 62.703, Fit loss U = 10.677, Fit loss F = 11.155, KL loss = 12322.326\n",
      "Epoch:  5111/40000, alpha = 1.64604\n",
      "\n",
      "Epoch:  5121/40000, total loss = 61.815, Fit loss U = 8.248, Fit loss F = 11.112, KL loss = 12169.344\n",
      "Epoch:  5121/40000, alpha = 1.64204\n",
      "\n",
      "Epoch:  5131/40000, total loss = 61.350, Fit loss U = 14.218, Fit loss F = 11.070, KL loss = 12017.173\n",
      "Epoch:  5131/40000, alpha = 1.63807\n",
      "\n",
      "Epoch:  5141/40000, total loss = 60.495, Fit loss U = 12.253, Fit loss F = 11.027, KL loss = 11866.105\n",
      "Epoch:  5141/40000, alpha = 1.63411\n",
      "\n",
      "Epoch:  5151/40000, total loss = 59.744, Fit loss U = 12.336, Fit loss F = 10.985, KL loss = 11715.615\n",
      "Epoch:  5151/40000, alpha = 1.63018\n",
      "\n",
      "Epoch:  5161/40000, total loss = 58.942, Fit loss U = 11.289, Fit loss F = 10.943, KL loss = 11566.019\n",
      "Epoch:  5161/40000, alpha = 1.62627\n",
      "\n",
      "Epoch:  5171/40000, total loss = 58.059, Fit loss U = 8.545, Fit loss F = 10.901, KL loss = 11417.380\n",
      "Epoch:  5171/40000, alpha = 1.62239\n",
      "\n",
      "Epoch:  5181/40000, total loss = 57.431, Fit loss U = 10.810, Fit loss F = 10.859, KL loss = 11269.515\n",
      "Epoch:  5181/40000, alpha = 1.61852\n",
      "\n",
      "Epoch:  5191/40000, total loss = 56.545, Fit loss U = 7.801, Fit loss F = 10.817, KL loss = 11122.782\n",
      "Epoch:  5191/40000, alpha = 1.61468\n",
      "\n",
      "Epoch:  5201/40000, total loss = 55.884, Fit loss U = 9.211, Fit loss F = 10.776, KL loss = 10976.872\n",
      "Epoch:  5201/40000, error_test = 1.02417, error_train = 1.03013\n",
      "Epoch:  5201/40000, error_f = 1.00000\n",
      "Epoch:  5201/40000, alpha = 1.61086\n",
      "\n",
      "Epoch:  5211/40000, total loss = 55.156, Fit loss U = 9.155, Fit loss F = 10.734, KL loss = 10832.259\n",
      "Epoch:  5211/40000, alpha = 1.60706\n",
      "\n",
      "Epoch:  5221/40000, total loss = 54.437, Fit loss U = 9.210, Fit loss F = 10.693, KL loss = 10688.379\n",
      "Epoch:  5221/40000, alpha = 1.60328\n",
      "\n",
      "Epoch:  5231/40000, total loss = 53.638, Fit loss U = 7.565, Fit loss F = 10.652, KL loss = 10545.395\n",
      "Epoch:  5231/40000, alpha = 1.59952\n",
      "\n",
      "Epoch:  5241/40000, total loss = 52.977, Fit loss U = 8.562, Fit loss F = 10.611, KL loss = 10403.638\n",
      "Epoch:  5241/40000, alpha = 1.59578\n",
      "\n",
      "Epoch:  5251/40000, total loss = 52.238, Fit loss U = 7.925, Fit loss F = 10.570, KL loss = 10262.629\n",
      "Epoch:  5251/40000, alpha = 1.59207\n",
      "\n",
      "Epoch:  5261/40000, total loss = 51.532, Fit loss U = 7.839, Fit loss F = 10.530, KL loss = 10122.617\n",
      "Epoch:  5261/40000, alpha = 1.58838\n",
      "\n",
      "Epoch:  5271/40000, total loss = 50.875, Fit loss U = 8.649, Fit loss F = 10.489, KL loss = 9983.592\n",
      "Epoch:  5271/40000, alpha = 1.58471\n",
      "\n",
      "Epoch:  5281/40000, total loss = 50.176, Fit loss U = 8.535, Fit loss F = 10.449, KL loss = 9845.427\n",
      "Epoch:  5281/40000, alpha = 1.58105\n",
      "\n",
      "Epoch:  5291/40000, total loss = 49.554, Fit loss U = 9.880, Fit loss F = 10.409, KL loss = 9707.969\n",
      "Epoch:  5291/40000, alpha = 1.57743\n",
      "\n",
      "Epoch:  5301/40000, total loss = 48.810, Fit loss U = 8.661, Fit loss F = 10.369, KL loss = 9571.721\n",
      "Epoch:  5301/40000, error_test = 1.01600, error_train = 1.04986\n",
      "Epoch:  5301/40000, error_f = 1.00000\n",
      "Epoch:  5301/40000, alpha = 1.57382\n",
      "\n",
      "Epoch:  5311/40000, total loss = 48.351, Fit loss U = 13.004, Fit loss F = 10.330, KL loss = 9436.785\n",
      "Epoch:  5311/40000, alpha = 1.57023\n",
      "\n",
      "Epoch:  5321/40000, total loss = 47.445, Fit loss U = 8.325, Fit loss F = 10.290, KL loss = 9302.876\n",
      "Epoch:  5321/40000, alpha = 1.56666\n",
      "\n",
      "Epoch:  5331/40000, total loss = 46.832, Fit loss U = 9.394, Fit loss F = 10.251, KL loss = 9169.932\n",
      "Epoch:  5331/40000, alpha = 1.56312\n",
      "\n",
      "Epoch:  5341/40000, total loss = 46.159, Fit loss U = 9.138, Fit loss F = 10.212, KL loss = 9038.239\n",
      "Epoch:  5341/40000, alpha = 1.55959\n",
      "\n",
      "Epoch:  5351/40000, total loss = 45.423, Fit loss U = 7.560, Fit loss F = 10.173, KL loss = 8907.204\n",
      "Epoch:  5351/40000, alpha = 1.55609\n",
      "\n",
      "Epoch:  5361/40000, total loss = 44.860, Fit loss U = 9.372, Fit loss F = 10.134, KL loss = 8776.941\n",
      "Epoch:  5361/40000, alpha = 1.55260\n",
      "\n",
      "Epoch:  5371/40000, total loss = 44.305, Fit loss U = 11.188, Fit loss F = 10.095, KL loss = 8648.127\n",
      "Epoch:  5371/40000, alpha = 1.54914\n",
      "\n",
      "Epoch:  5381/40000, total loss = 43.502, Fit loss U = 7.948, Fit loss F = 10.057, KL loss = 8520.424\n",
      "Epoch:  5381/40000, alpha = 1.54569\n",
      "\n",
      "Epoch:  5391/40000, total loss = 42.860, Fit loss U = 7.817, Fit loss F = 10.018, KL loss = 8393.747\n",
      "Epoch:  5391/40000, alpha = 1.54227\n",
      "\n",
      "Epoch:  5401/40000, total loss = 42.414, Fit loss U = 11.457, Fit loss F = 9.980, KL loss = 8268.414\n",
      "Epoch:  5401/40000, error_test = 1.00866, error_train = 0.98160\n",
      "Epoch:  5401/40000, error_f = 1.00000\n",
      "Epoch:  5401/40000, alpha = 1.53887\n",
      "\n",
      "Epoch:  5411/40000, total loss = 41.678, Fit loss U = 9.173, Fit loss F = 9.942, KL loss = 8144.416\n",
      "Epoch:  5411/40000, alpha = 1.53548\n",
      "\n",
      "Epoch:  5421/40000, total loss = 40.924, Fit loss U = 6.452, Fit loss F = 9.904, KL loss = 8021.258\n",
      "Epoch:  5421/40000, alpha = 1.53212\n",
      "\n",
      "Epoch:  5431/40000, total loss = 40.405, Fit loss U = 8.339, Fit loss F = 9.866, KL loss = 7898.987\n",
      "Epoch:  5431/40000, alpha = 1.52878\n",
      "\n",
      "Epoch:  5441/40000, total loss = 39.932, Fit loss U = 11.058, Fit loss F = 9.829, KL loss = 7777.576\n",
      "Epoch:  5441/40000, alpha = 1.52546\n",
      "\n",
      "Epoch:  5451/40000, total loss = 39.428, Fit loss U = 13.075, Fit loss F = 9.792, KL loss = 7657.013\n",
      "Epoch:  5451/40000, alpha = 1.52215\n",
      "\n",
      "Epoch:  5461/40000, total loss = 38.644, Fit loss U = 9.308, Fit loss F = 9.754, KL loss = 7538.160\n",
      "Epoch:  5461/40000, alpha = 1.51887\n",
      "\n",
      "Epoch:  5471/40000, total loss = 38.063, Fit loss U = 9.387, Fit loss F = 9.717, KL loss = 7421.653\n",
      "Epoch:  5471/40000, alpha = 1.51560\n",
      "\n",
      "Epoch:  5481/40000, total loss = 37.503, Fit loss U = 9.843, Fit loss F = 9.681, KL loss = 7305.265\n",
      "Epoch:  5481/40000, alpha = 1.51236\n",
      "\n",
      "Epoch:  5491/40000, total loss = 36.849, Fit loss U = 8.379, Fit loss F = 9.644, KL loss = 7189.664\n",
      "Epoch:  5491/40000, alpha = 1.50913\n",
      "\n",
      "Epoch:  5501/40000, total loss = 36.263, Fit loss U = 8.157, Fit loss F = 9.607, KL loss = 7074.902\n",
      "Epoch:  5501/40000, error_test = 1.01660, error_train = 1.02191\n",
      "Epoch:  5501/40000, error_f = 1.00000\n",
      "Epoch:  5501/40000, alpha = 1.50593\n",
      "\n",
      "Epoch:  5511/40000, total loss = 35.681, Fit loss U = 7.913, Fit loss F = 9.571, KL loss = 6961.334\n",
      "Epoch:  5511/40000, alpha = 1.50274\n",
      "\n",
      "Epoch:  5521/40000, total loss = 35.159, Fit loss U = 8.723, Fit loss F = 9.535, KL loss = 6849.223\n",
      "Epoch:  5521/40000, alpha = 1.49958\n",
      "\n",
      "Epoch:  5531/40000, total loss = 34.541, Fit loss U = 7.528, Fit loss F = 9.499, KL loss = 6737.914\n",
      "Epoch:  5531/40000, alpha = 1.49643\n",
      "\n",
      "Epoch:  5541/40000, total loss = 34.088, Fit loss U = 9.528, Fit loss F = 9.463, KL loss = 6627.640\n",
      "Epoch:  5541/40000, alpha = 1.49330\n",
      "\n",
      "Epoch:  5551/40000, total loss = 33.704, Fit loss U = 12.810, Fit loss F = 9.427, KL loss = 6518.513\n",
      "Epoch:  5551/40000, alpha = 1.49019\n",
      "\n",
      "Epoch:  5561/40000, total loss = 33.038, Fit loss U = 10.294, Fit loss F = 9.392, KL loss = 6410.766\n",
      "Epoch:  5561/40000, alpha = 1.48710\n",
      "\n",
      "Epoch:  5571/40000, total loss = 32.643, Fit loss U = 13.087, Fit loss F = 9.356, KL loss = 6304.105\n",
      "Epoch:  5571/40000, alpha = 1.48402\n",
      "\n",
      "Epoch:  5581/40000, total loss = 31.874, Fit loss U = 8.310, Fit loss F = 9.321, KL loss = 6198.533\n",
      "Epoch:  5581/40000, alpha = 1.48097\n",
      "\n",
      "Epoch:  5591/40000, total loss = 31.502, Fit loss U = 11.357, Fit loss F = 9.286, KL loss = 6093.945\n",
      "Epoch:  5591/40000, alpha = 1.47793\n",
      "\n",
      "Epoch:  5601/40000, total loss = 30.916, Fit loss U = 9.974, Fit loss F = 9.251, KL loss = 5990.894\n",
      "Epoch:  5601/40000, error_test = 1.02550, error_train = 1.05198\n",
      "Epoch:  5601/40000, error_f = 1.00000\n",
      "Epoch:  5601/40000, alpha = 1.47492\n",
      "\n",
      "Epoch:  5611/40000, total loss = 30.375, Fit loss U = 9.414, Fit loss F = 9.217, KL loss = 5888.629\n",
      "Epoch:  5611/40000, alpha = 1.47192\n",
      "\n",
      "Epoch:  5621/40000, total loss = 29.976, Fit loss U = 11.585, Fit loss F = 9.182, KL loss = 5787.527\n",
      "Epoch:  5621/40000, alpha = 1.46894\n",
      "\n",
      "Epoch:  5631/40000, total loss = 29.433, Fit loss U = 10.741, Fit loss F = 9.148, KL loss = 5687.680\n",
      "Epoch:  5631/40000, alpha = 1.46598\n",
      "\n",
      "Epoch:  5641/40000, total loss = 28.808, Fit loss U = 8.118, Fit loss F = 9.114, KL loss = 5589.257\n",
      "Epoch:  5641/40000, alpha = 1.46303\n",
      "\n",
      "Epoch:  5651/40000, total loss = 28.625, Fit loss U = 14.247, Fit loss F = 9.080, KL loss = 5491.643\n",
      "Epoch:  5651/40000, alpha = 1.46011\n",
      "\n",
      "Epoch:  5661/40000, total loss = 27.832, Fit loss U = 8.041, Fit loss F = 9.046, KL loss = 5395.579\n",
      "Epoch:  5661/40000, alpha = 1.45720\n",
      "\n",
      "Epoch:  5671/40000, total loss = 27.466, Fit loss U = 10.257, Fit loss F = 9.012, KL loss = 5300.538\n",
      "Epoch:  5671/40000, alpha = 1.45431\n",
      "\n",
      "Epoch:  5681/40000, total loss = 27.003, Fit loss U = 10.443, Fit loss F = 8.979, KL loss = 5206.322\n",
      "Epoch:  5681/40000, alpha = 1.45144\n",
      "\n",
      "Epoch:  5691/40000, total loss = 26.631, Fit loss U = 12.310, Fit loss F = 8.945, KL loss = 5113.577\n",
      "Epoch:  5691/40000, alpha = 1.44858\n",
      "\n",
      "Epoch:  5701/40000, total loss = 26.048, Fit loss U = 9.812, Fit loss F = 8.912, KL loss = 5022.279\n",
      "Epoch:  5701/40000, error_test = 1.01406, error_train = 0.98845\n",
      "Epoch:  5701/40000, error_f = 1.00000\n",
      "Epoch:  5701/40000, alpha = 1.44575\n",
      "\n",
      "Epoch:  5711/40000, total loss = 25.582, Fit loss U = 9.600, Fit loss F = 8.879, KL loss = 4931.653\n",
      "Epoch:  5711/40000, alpha = 1.44293\n",
      "\n",
      "Epoch:  5721/40000, total loss = 25.386, Fit loss U = 14.678, Fit loss F = 8.846, KL loss = 4841.943\n",
      "Epoch:  5721/40000, alpha = 1.44013\n",
      "\n",
      "Epoch:  5731/40000, total loss = 24.616, Fit loss U = 8.133, Fit loss F = 8.814, KL loss = 4753.803\n",
      "Epoch:  5731/40000, alpha = 1.43734\n",
      "\n",
      "Epoch:  5741/40000, total loss = 24.296, Fit loss U = 10.456, Fit loss F = 8.781, KL loss = 4666.743\n",
      "Epoch:  5741/40000, alpha = 1.43457\n",
      "\n",
      "Epoch:  5751/40000, total loss = 23.794, Fit loss U = 9.054, Fit loss F = 8.749, KL loss = 4580.820\n",
      "Epoch:  5751/40000, alpha = 1.43182\n",
      "\n",
      "Epoch:  5761/40000, total loss = 23.376, Fit loss U = 9.251, Fit loss F = 8.717, KL loss = 4495.587\n",
      "Epoch:  5761/40000, alpha = 1.42909\n",
      "\n",
      "Epoch:  5771/40000, total loss = 23.067, Fit loss U = 11.504, Fit loss F = 8.685, KL loss = 4411.581\n",
      "Epoch:  5771/40000, alpha = 1.42638\n",
      "\n",
      "Epoch:  5781/40000, total loss = 22.457, Fit loss U = 7.486, Fit loss F = 8.653, KL loss = 4329.966\n",
      "Epoch:  5781/40000, alpha = 1.42368\n",
      "\n",
      "Epoch:  5791/40000, total loss = 22.068, Fit loss U = 7.810, Fit loss F = 8.621, KL loss = 4249.256\n",
      "Epoch:  5791/40000, alpha = 1.42100\n",
      "\n",
      "Epoch:  5801/40000, total loss = 21.777, Fit loss U = 10.088, Fit loss F = 8.589, KL loss = 4168.633\n",
      "Epoch:  5801/40000, error_test = 1.00327, error_train = 1.02128\n",
      "Epoch:  5801/40000, error_f = 1.00001\n",
      "Epoch:  5801/40000, alpha = 1.41833\n",
      "\n",
      "Epoch:  5811/40000, total loss = 21.401, Fit loss U = 10.563, Fit loss F = 8.558, KL loss = 4089.056\n",
      "Epoch:  5811/40000, alpha = 1.41568\n",
      "\n",
      "Epoch:  5821/40000, total loss = 20.796, Fit loss U = 6.364, Fit loss F = 8.527, KL loss = 4010.268\n",
      "Epoch:  5821/40000, alpha = 1.41305\n",
      "\n",
      "Epoch:  5831/40000, total loss = 20.521, Fit loss U = 8.685, Fit loss F = 8.496, KL loss = 3932.488\n",
      "Epoch:  5831/40000, alpha = 1.41044\n",
      "\n",
      "Epoch:  5841/40000, total loss = 20.081, Fit loss U = 7.517, Fit loss F = 8.465, KL loss = 3856.400\n",
      "Epoch:  5841/40000, alpha = 1.40784\n",
      "\n",
      "Epoch:  5851/40000, total loss = 19.724, Fit loss U = 7.910, Fit loss F = 8.434, KL loss = 3781.405\n",
      "Epoch:  5851/40000, alpha = 1.40525\n",
      "\n",
      "Epoch:  5861/40000, total loss = 19.417, Fit loss U = 9.169, Fit loss F = 8.404, KL loss = 3707.605\n",
      "Epoch:  5861/40000, alpha = 1.40269\n",
      "\n",
      "Epoch:  5871/40000, total loss = 18.975, Fit loss U = 7.640, Fit loss F = 8.373, KL loss = 3634.825\n",
      "Epoch:  5871/40000, alpha = 1.40014\n",
      "\n",
      "Epoch:  5881/40000, total loss = 18.688, Fit loss U = 9.084, Fit loss F = 8.343, KL loss = 3563.370\n",
      "Epoch:  5881/40000, alpha = 1.39760\n",
      "\n",
      "Epoch:  5891/40000, total loss = 18.408, Fit loss U = 10.496, Fit loss F = 8.313, KL loss = 3493.417\n",
      "Epoch:  5891/40000, alpha = 1.39509\n",
      "\n",
      "Epoch:  5901/40000, total loss = 17.961, Fit loss U = 8.489, Fit loss F = 8.283, KL loss = 3424.433\n",
      "Epoch:  5901/40000, error_test = 0.99439, error_train = 1.05094\n",
      "Epoch:  5901/40000, error_f = 1.00000\n",
      "Epoch:  5901/40000, alpha = 1.39258\n",
      "\n",
      "Epoch:  5911/40000, total loss = 17.592, Fit loss U = 7.935, Fit loss F = 8.253, KL loss = 3356.463\n",
      "Epoch:  5911/40000, alpha = 1.39010\n",
      "\n",
      "Epoch:  5921/40000, total loss = 17.339, Fit loss U = 9.630, Fit loss F = 8.223, KL loss = 3289.252\n",
      "Epoch:  5921/40000, alpha = 1.38763\n",
      "\n",
      "Epoch:  5931/40000, total loss = 16.920, Fit loss U = 7.901, Fit loss F = 8.194, KL loss = 3223.107\n",
      "Epoch:  5931/40000, alpha = 1.38517\n",
      "\n",
      "Epoch:  5941/40000, total loss = 16.582, Fit loss U = 7.682, Fit loss F = 8.165, KL loss = 3157.935\n",
      "Epoch:  5941/40000, alpha = 1.38273\n",
      "\n",
      "Epoch:  5951/40000, total loss = 16.246, Fit loss U = 7.408, Fit loss F = 8.135, KL loss = 3093.849\n",
      "Epoch:  5951/40000, alpha = 1.38031\n",
      "\n",
      "Epoch:  5961/40000, total loss = 15.955, Fit loss U = 7.927, Fit loss F = 8.106, KL loss = 3030.670\n",
      "Epoch:  5961/40000, alpha = 1.37790\n",
      "\n",
      "Epoch:  5971/40000, total loss = 15.638, Fit loss U = 7.807, Fit loss F = 8.077, KL loss = 2968.680\n",
      "Epoch:  5971/40000, alpha = 1.37551\n",
      "\n",
      "Epoch:  5981/40000, total loss = 15.371, Fit loss U = 8.617, Fit loss F = 8.049, KL loss = 2907.582\n",
      "Epoch:  5981/40000, alpha = 1.37313\n",
      "\n",
      "Epoch:  5991/40000, total loss = 15.000, Fit loss U = 7.209, Fit loss F = 8.020, KL loss = 2847.682\n",
      "Epoch:  5991/40000, alpha = 1.37077\n",
      "\n",
      "Epoch:  6001/40000, total loss = 14.910, Fit loss U = 11.305, Fit loss F = 7.992, KL loss = 2789.076\n",
      "Epoch:  6001/40000, error_test = 1.00975, error_train = 0.94462\n",
      "Epoch:  6001/40000, error_f = 1.00000\n",
      "Epoch:  6001/40000, alpha = 1.36842\n",
      "\n",
      "Epoch:  6011/40000, total loss = 14.714, Fit loss U = 13.155, Fit loss F = 7.964, KL loss = 2731.525\n",
      "Epoch:  6011/40000, alpha = 1.36609\n",
      "\n",
      "Epoch:  6021/40000, total loss = 14.229, Fit loss U = 9.167, Fit loss F = 7.936, KL loss = 2674.832\n",
      "Epoch:  6021/40000, alpha = 1.36377\n",
      "\n",
      "Epoch:  6031/40000, total loss = 13.973, Fit loss U = 9.646, Fit loss F = 7.908, KL loss = 2618.990\n",
      "Epoch:  6031/40000, alpha = 1.36147\n",
      "\n",
      "Epoch:  6041/40000, total loss = 13.633, Fit loss U = 8.376, Fit loss F = 7.880, KL loss = 2564.096\n",
      "Epoch:  6041/40000, alpha = 1.35918\n",
      "\n",
      "Epoch:  6051/40000, total loss = 13.375, Fit loss U = 8.597, Fit loss F = 7.852, KL loss = 2510.415\n",
      "Epoch:  6051/40000, alpha = 1.35691\n",
      "\n",
      "Epoch:  6061/40000, total loss = 13.340, Fit loss U = 13.161, Fit loss F = 7.825, KL loss = 2458.222\n",
      "Epoch:  6061/40000, alpha = 1.35465\n",
      "\n",
      "Epoch:  6071/40000, total loss = 12.815, Fit loss U = 7.808, Fit loss F = 7.797, KL loss = 2406.910\n",
      "Epoch:  6071/40000, alpha = 1.35240\n",
      "\n",
      "Epoch:  6081/40000, total loss = 12.739, Fit loss U = 11.401, Fit loss F = 7.770, KL loss = 2356.032\n",
      "Epoch:  6081/40000, alpha = 1.35017\n",
      "\n",
      "Epoch:  6091/40000, total loss = 12.502, Fit loss U = 11.664, Fit loss F = 7.743, KL loss = 2306.253\n",
      "Epoch:  6091/40000, alpha = 1.34796\n",
      "\n",
      "Epoch:  6101/40000, total loss = 11.962, Fit loss U = 5.748, Fit loss F = 7.716, KL loss = 2257.815\n",
      "Epoch:  6101/40000, error_test = 1.02149, error_train = 1.03456\n",
      "Epoch:  6101/40000, error_f = 1.00000\n",
      "Epoch:  6101/40000, alpha = 1.34576\n",
      "\n",
      "Epoch:  6111/40000, total loss = 11.887, Fit loss U = 9.027, Fit loss F = 7.689, KL loss = 2210.249\n",
      "Epoch:  6111/40000, alpha = 1.34357\n",
      "\n",
      "Epoch:  6121/40000, total loss = 11.582, Fit loss U = 7.616, Fit loss F = 7.663, KL loss = 2163.708\n",
      "Epoch:  6121/40000, alpha = 1.34140\n",
      "\n",
      "Epoch:  6131/40000, total loss = 11.392, Fit loss U = 8.461, Fit loss F = 7.636, KL loss = 2117.429\n",
      "Epoch:  6131/40000, alpha = 1.33924\n",
      "\n",
      "Epoch:  6141/40000, total loss = 11.046, Fit loss U = 6.161, Fit loss F = 7.610, KL loss = 2071.574\n",
      "Epoch:  6141/40000, alpha = 1.33709\n",
      "\n",
      "Epoch:  6151/40000, total loss = 10.982, Fit loss U = 9.435, Fit loss F = 7.584, KL loss = 2026.280\n",
      "Epoch:  6151/40000, alpha = 1.33496\n",
      "\n",
      "Epoch:  6161/40000, total loss = 10.641, Fit loss U = 7.027, Fit loss F = 7.558, KL loss = 1982.297\n",
      "Epoch:  6161/40000, alpha = 1.33284\n",
      "\n",
      "Epoch:  6171/40000, total loss = 10.433, Fit loss U = 7.222, Fit loss F = 7.532, KL loss = 1939.122\n",
      "Epoch:  6171/40000, alpha = 1.33074\n",
      "\n",
      "Epoch:  6181/40000, total loss = 10.370, Fit loss U = 10.192, Fit loss F = 7.506, KL loss = 1896.984\n",
      "Epoch:  6181/40000, alpha = 1.32865\n",
      "\n",
      "Epoch:  6191/40000, total loss = 10.026, Fit loss U = 7.409, Fit loss F = 7.481, KL loss = 1856.378\n",
      "Epoch:  6191/40000, alpha = 1.32657\n",
      "\n",
      "Epoch:  6201/40000, total loss = 9.824, Fit loss U = 7.372, Fit loss F = 7.455, KL loss = 1816.592\n",
      "Epoch:  6201/40000, error_test = 1.00455, error_train = 1.05617\n",
      "Epoch:  6201/40000, error_f = 1.00000\n",
      "Epoch:  6201/40000, alpha = 1.32451\n",
      "\n",
      "Epoch:  6211/40000, total loss = 9.738, Fit loss U = 9.609, Fit loss F = 7.430, KL loss = 1777.306\n",
      "Epoch:  6211/40000, alpha = 1.32246\n",
      "\n",
      "Epoch:  6221/40000, total loss = 9.655, Fit loss U = 11.790, Fit loss F = 7.405, KL loss = 1739.143\n",
      "Epoch:  6221/40000, alpha = 1.32042\n",
      "\n",
      "Epoch:  6231/40000, total loss = 9.323, Fit loss U = 8.948, Fit loss F = 7.380, KL loss = 1701.409\n",
      "Epoch:  6231/40000, alpha = 1.31840\n",
      "\n",
      "Epoch:  6241/40000, total loss = 9.426, Fit loss U = 14.685, Fit loss F = 7.355, KL loss = 1664.847\n",
      "Epoch:  6241/40000, alpha = 1.31639\n",
      "\n",
      "Epoch:  6251/40000, total loss = 8.964, Fit loss U = 8.994, Fit loss F = 7.330, KL loss = 1629.545\n",
      "Epoch:  6251/40000, alpha = 1.31439\n",
      "\n",
      "Epoch:  6261/40000, total loss = 8.752, Fit loss U = 8.258, Fit loss F = 7.306, KL loss = 1594.741\n",
      "Epoch:  6261/40000, alpha = 1.31240\n",
      "\n",
      "Epoch:  6271/40000, total loss = 8.646, Fit loss U = 9.565, Fit loss F = 7.281, KL loss = 1560.670\n",
      "Epoch:  6271/40000, alpha = 1.31043\n",
      "\n",
      "Epoch:  6281/40000, total loss = 8.570, Fit loss U = 11.412, Fit loss F = 7.257, KL loss = 1527.281\n",
      "Epoch:  6281/40000, alpha = 1.30847\n",
      "\n",
      "Epoch:  6291/40000, total loss = 8.319, Fit loss U = 9.718, Fit loss F = 7.233, KL loss = 1494.318\n",
      "Epoch:  6291/40000, alpha = 1.30653\n",
      "\n",
      "Epoch:  6301/40000, total loss = 8.165, Fit loss U = 9.818, Fit loss F = 7.209, KL loss = 1462.736\n",
      "Epoch:  6301/40000, error_test = 1.00373, error_train = 0.99520\n",
      "Epoch:  6301/40000, error_f = 1.00000\n",
      "Epoch:  6301/40000, alpha = 1.30459\n",
      "\n",
      "Epoch:  6311/40000, total loss = 8.235, Fit loss U = 14.343, Fit loss F = 7.185, KL loss = 1431.685\n",
      "Epoch:  6311/40000, alpha = 1.30267\n",
      "\n",
      "Epoch:  6321/40000, total loss = 7.801, Fit loss U = 8.722, Fit loss F = 7.161, KL loss = 1401.272\n",
      "Epoch:  6321/40000, alpha = 1.30077\n",
      "\n",
      "Epoch:  6331/40000, total loss = 7.813, Fit loss U = 11.999, Fit loss F = 7.138, KL loss = 1371.236\n",
      "Epoch:  6331/40000, alpha = 1.29887\n",
      "\n",
      "Epoch:  6341/40000, total loss = 7.405, Fit loss U = 6.737, Fit loss F = 7.114, KL loss = 1342.418\n",
      "Epoch:  6341/40000, alpha = 1.29699\n",
      "\n",
      "Epoch:  6351/40000, total loss = 7.288, Fit loss U = 7.266, Fit loss F = 7.091, KL loss = 1313.990\n",
      "Epoch:  6351/40000, alpha = 1.29511\n",
      "\n",
      "Epoch:  6361/40000, total loss = 7.282, Fit loss U = 9.938, Fit loss F = 7.068, KL loss = 1286.440\n",
      "Epoch:  6361/40000, alpha = 1.29325\n",
      "\n",
      "Epoch:  6371/40000, total loss = 7.085, Fit loss U = 8.721, Fit loss F = 7.044, KL loss = 1259.437\n",
      "Epoch:  6371/40000, alpha = 1.29141\n",
      "\n",
      "Epoch:  6381/40000, total loss = 6.898, Fit loss U = 7.630, Fit loss F = 7.021, KL loss = 1233.002\n",
      "Epoch:  6381/40000, alpha = 1.28957\n",
      "\n",
      "Epoch:  6391/40000, total loss = 6.883, Fit loss U = 9.867, Fit loss F = 6.999, KL loss = 1207.930\n",
      "Epoch:  6391/40000, alpha = 1.28775\n",
      "\n",
      "Epoch:  6401/40000, total loss = 6.723, Fit loss U = 9.099, Fit loss F = 6.976, KL loss = 1183.882\n",
      "Epoch:  6401/40000, error_test = 1.02407, error_train = 0.95440\n",
      "Epoch:  6401/40000, error_f = 1.00000\n",
      "Epoch:  6401/40000, alpha = 1.28594\n",
      "\n",
      "Epoch:  6411/40000, total loss = 6.686, Fit loss U = 10.771, Fit loss F = 6.953, KL loss = 1159.934\n",
      "Epoch:  6411/40000, alpha = 1.28414\n",
      "\n",
      "Epoch:  6421/40000, total loss = 6.519, Fit loss U = 9.840, Fit loss F = 6.931, KL loss = 1136.098\n",
      "Epoch:  6421/40000, alpha = 1.28235\n",
      "\n",
      "Epoch:  6431/40000, total loss = 6.230, Fit loss U = 6.388, Fit loss F = 6.909, KL loss = 1113.068\n",
      "Epoch:  6431/40000, alpha = 1.28058\n",
      "\n",
      "Epoch:  6441/40000, total loss = 6.195, Fit loss U = 7.961, Fit loss F = 6.887, KL loss = 1090.590\n",
      "Epoch:  6441/40000, alpha = 1.27881\n",
      "\n",
      "Epoch:  6451/40000, total loss = 6.096, Fit loss U = 8.194, Fit loss F = 6.865, KL loss = 1068.599\n",
      "Epoch:  6451/40000, alpha = 1.27706\n",
      "\n",
      "Epoch:  6461/40000, total loss = 6.050, Fit loss U = 9.428, Fit loss F = 6.843, KL loss = 1047.347\n",
      "Epoch:  6461/40000, alpha = 1.27532\n",
      "\n",
      "Epoch:  6471/40000, total loss = 6.049, Fit loss U = 11.504, Fit loss F = 6.821, KL loss = 1026.566\n",
      "Epoch:  6471/40000, alpha = 1.27359\n",
      "\n",
      "Epoch:  6481/40000, total loss = 5.935, Fit loss U = 11.293, Fit loss F = 6.799, KL loss = 1006.103\n",
      "Epoch:  6481/40000, alpha = 1.27187\n",
      "\n",
      "Epoch:  6491/40000, total loss = 5.632, Fit loss U = 7.222, Fit loss F = 6.778, KL loss = 986.500\n",
      "Epoch:  6491/40000, alpha = 1.27016\n",
      "\n",
      "Epoch:  6501/40000, total loss = 5.628, Fit loss U = 9.108, Fit loss F = 6.756, KL loss = 966.948\n",
      "Epoch:  6501/40000, error_test = 0.98476, error_train = 0.98371\n",
      "Epoch:  6501/40000, error_f = 1.00000\n",
      "Epoch:  6501/40000, alpha = 1.26847\n",
      "\n",
      "Epoch:  6511/40000, total loss = 5.503, Fit loss U = 8.536, Fit loss F = 6.735, KL loss = 947.970\n",
      "Epoch:  6511/40000, alpha = 1.26678\n",
      "\n",
      "Epoch:  6521/40000, total loss = 5.358, Fit loss U = 7.518, Fit loss F = 6.714, KL loss = 929.361\n",
      "Epoch:  6521/40000, alpha = 1.26511\n",
      "\n",
      "Epoch:  6531/40000, total loss = 5.343, Fit loss U = 9.029, Fit loss F = 6.693, KL loss = 911.444\n",
      "Epoch:  6531/40000, alpha = 1.26344\n",
      "\n",
      "Epoch:  6541/40000, total loss = 5.168, Fit loss U = 7.202, Fit loss F = 6.672, KL loss = 894.794\n",
      "Epoch:  6541/40000, alpha = 1.26179\n",
      "\n",
      "Epoch:  6551/40000, total loss = 5.191, Fit loss U = 9.333, Fit loss F = 6.651, KL loss = 878.271\n",
      "Epoch:  6551/40000, alpha = 1.26015\n",
      "\n",
      "Epoch:  6561/40000, total loss = 5.133, Fit loss U = 9.779, Fit loss F = 6.631, KL loss = 862.587\n",
      "Epoch:  6561/40000, alpha = 1.25852\n",
      "\n",
      "Epoch:  6571/40000, total loss = 5.001, Fit loss U = 8.667, Fit loss F = 6.610, KL loss = 847.521\n",
      "Epoch:  6571/40000, alpha = 1.25690\n",
      "\n",
      "Epoch:  6581/40000, total loss = 4.948, Fit loss U = 9.148, Fit loss F = 6.590, KL loss = 832.238\n",
      "Epoch:  6581/40000, alpha = 1.25529\n",
      "\n",
      "Epoch:  6591/40000, total loss = 4.883, Fit loss U = 9.352, Fit loss F = 6.569, KL loss = 817.434\n",
      "Epoch:  6591/40000, alpha = 1.25369\n",
      "\n",
      "Epoch:  6601/40000, total loss = 4.728, Fit loss U = 7.641, Fit loss F = 6.549, KL loss = 803.657\n",
      "Epoch:  6601/40000, error_test = 1.00328, error_train = 0.97988\n",
      "Epoch:  6601/40000, error_f = 1.00000\n",
      "Epoch:  6601/40000, alpha = 1.25210\n",
      "\n",
      "Epoch:  6611/40000, total loss = 4.748, Fit loss U = 9.468, Fit loss F = 6.529, KL loss = 789.669\n",
      "Epoch:  6611/40000, alpha = 1.25053\n",
      "\n",
      "Epoch:  6621/40000, total loss = 4.658, Fit loss U = 8.990, Fit loss F = 6.509, KL loss = 776.589\n",
      "Epoch:  6621/40000, alpha = 1.24896\n",
      "\n",
      "Epoch:  6631/40000, total loss = 4.595, Fit loss U = 9.080, Fit loss F = 6.490, KL loss = 763.345\n",
      "Epoch:  6631/40000, alpha = 1.24740\n",
      "\n",
      "Epoch:  6641/40000, total loss = 4.544, Fit loss U = 9.342, Fit loss F = 6.470, KL loss = 750.769\n",
      "Epoch:  6641/40000, alpha = 1.24586\n",
      "\n",
      "Epoch:  6651/40000, total loss = 4.470, Fit loss U = 9.092, Fit loss F = 6.450, KL loss = 738.557\n",
      "Epoch:  6651/40000, alpha = 1.24432\n",
      "\n",
      "Epoch:  6661/40000, total loss = 4.496, Fit loss U = 10.767, Fit loss F = 6.431, KL loss = 727.190\n",
      "Epoch:  6661/40000, alpha = 1.24279\n",
      "\n",
      "Epoch:  6671/40000, total loss = 4.262, Fit loss U = 7.179, Fit loss F = 6.411, KL loss = 716.580\n",
      "Epoch:  6671/40000, alpha = 1.24128\n",
      "\n",
      "Epoch:  6681/40000, total loss = 4.335, Fit loss U = 9.726, Fit loss F = 6.392, KL loss = 705.883\n",
      "Epoch:  6681/40000, alpha = 1.23977\n",
      "\n",
      "Epoch:  6691/40000, total loss = 4.211, Fit loss U = 8.289, Fit loss F = 6.373, KL loss = 695.529\n",
      "Epoch:  6691/40000, alpha = 1.23827\n",
      "\n",
      "Epoch:  6701/40000, total loss = 4.199, Fit loss U = 9.102, Fit loss F = 6.354, KL loss = 685.154\n",
      "Epoch:  6701/40000, error_test = 1.01920, error_train = 1.05509\n",
      "Epoch:  6701/40000, error_f = 1.00000\n",
      "Epoch:  6701/40000, alpha = 1.23679\n",
      "\n",
      "Epoch:  6711/40000, total loss = 4.166, Fit loss U = 9.431, Fit loss F = 6.335, KL loss = 675.538\n",
      "Epoch:  6711/40000, alpha = 1.23531\n",
      "\n",
      "Epoch:  6721/40000, total loss = 3.956, Fit loss U = 6.148, Fit loss F = 6.317, KL loss = 666.459\n",
      "Epoch:  6721/40000, alpha = 1.23384\n",
      "\n",
      "Epoch:  6731/40000, total loss = 4.073, Fit loss U = 9.424, Fit loss F = 6.298, KL loss = 657.431\n",
      "Epoch:  6731/40000, alpha = 1.23238\n",
      "\n",
      "Epoch:  6741/40000, total loss = 3.847, Fit loss U = 5.753, Fit loss F = 6.280, KL loss = 649.106\n",
      "Epoch:  6741/40000, alpha = 1.23093\n",
      "\n",
      "Epoch:  6751/40000, total loss = 3.866, Fit loss U = 7.042, Fit loss F = 6.261, KL loss = 640.078\n",
      "Epoch:  6751/40000, alpha = 1.22950\n",
      "\n",
      "Epoch:  6761/40000, total loss = 3.895, Fit loss U = 8.577, Fit loss F = 6.243, KL loss = 630.741\n",
      "Epoch:  6761/40000, alpha = 1.22807\n",
      "\n",
      "Epoch:  6771/40000, total loss = 3.997, Fit loss U = 11.464, Fit loss F = 6.225, KL loss = 622.439\n",
      "Epoch:  6771/40000, alpha = 1.22665\n",
      "\n",
      "Epoch:  6781/40000, total loss = 3.809, Fit loss U = 8.487, Fit loss F = 6.207, KL loss = 614.784\n",
      "Epoch:  6781/40000, alpha = 1.22524\n",
      "\n",
      "Epoch:  6791/40000, total loss = 3.901, Fit loss U = 11.100, Fit loss F = 6.188, KL loss = 607.336\n",
      "Epoch:  6791/40000, alpha = 1.22383\n",
      "\n",
      "Epoch:  6801/40000, total loss = 3.785, Fit loss U = 9.476, Fit loss F = 6.171, KL loss = 600.469\n",
      "Epoch:  6801/40000, error_test = 0.99953, error_train = 0.99522\n",
      "Epoch:  6801/40000, error_f = 1.00000\n",
      "Epoch:  6801/40000, alpha = 1.22244\n",
      "\n",
      "Epoch:  6811/40000, total loss = 3.716, Fit loss U = 8.724, Fit loss F = 6.153, KL loss = 594.409\n",
      "Epoch:  6811/40000, alpha = 1.22106\n",
      "\n",
      "Epoch:  6821/40000, total loss = 3.636, Fit loss U = 7.752, Fit loss F = 6.135, KL loss = 588.254\n",
      "Epoch:  6821/40000, alpha = 1.21969\n",
      "\n",
      "Epoch:  6831/40000, total loss = 3.525, Fit loss U = 6.216, Fit loss F = 6.118, KL loss = 581.626\n",
      "Epoch:  6831/40000, alpha = 1.21832\n",
      "\n",
      "Epoch:  6841/40000, total loss = 3.560, Fit loss U = 7.606, Fit loss F = 6.100, KL loss = 574.842\n",
      "Epoch:  6841/40000, alpha = 1.21697\n",
      "\n",
      "Epoch:  6851/40000, total loss = 3.553, Fit loss U = 8.164, Fit loss F = 6.083, KL loss = 568.151\n",
      "Epoch:  6851/40000, alpha = 1.21562\n",
      "\n",
      "Epoch:  6861/40000, total loss = 3.630, Fit loss U = 10.308, Fit loss F = 6.066, KL loss = 562.299\n",
      "Epoch:  6861/40000, alpha = 1.21428\n",
      "\n",
      "Epoch:  6871/40000, total loss = 3.572, Fit loss U = 9.693, Fit loss F = 6.049, KL loss = 557.052\n",
      "Epoch:  6871/40000, alpha = 1.21295\n",
      "\n",
      "Epoch:  6881/40000, total loss = 3.537, Fit loss U = 9.552, Fit loss F = 6.032, KL loss = 551.637\n",
      "Epoch:  6881/40000, alpha = 1.21163\n",
      "\n",
      "Epoch:  6891/40000, total loss = 3.589, Fit loss U = 11.115, Fit loss F = 6.015, KL loss = 546.408\n",
      "Epoch:  6891/40000, alpha = 1.21032\n",
      "\n",
      "Epoch:  6901/40000, total loss = 3.341, Fit loss U = 6.710, Fit loss F = 5.998, KL loss = 541.083\n",
      "Epoch:  6901/40000, error_test = 1.03248, error_train = 1.00275\n",
      "Epoch:  6901/40000, error_f = 1.00000\n",
      "Epoch:  6901/40000, alpha = 1.20902\n",
      "\n",
      "Epoch:  6911/40000, total loss = 3.393, Fit loss U = 8.341, Fit loss F = 5.981, KL loss = 535.433\n",
      "Epoch:  6911/40000, alpha = 1.20772\n",
      "\n",
      "Epoch:  6921/40000, total loss = 3.468, Fit loss U = 10.349, Fit loss F = 5.965, KL loss = 530.487\n",
      "Epoch:  6921/40000, alpha = 1.20644\n",
      "\n",
      "Epoch:  6931/40000, total loss = 3.281, Fit loss U = 7.053, Fit loss F = 5.948, KL loss = 526.224\n",
      "Epoch:  6931/40000, alpha = 1.20516\n",
      "\n",
      "Epoch:  6941/40000, total loss = 3.424, Fit loss U = 10.335, Fit loss F = 5.932, KL loss = 522.209\n",
      "Epoch:  6941/40000, alpha = 1.20389\n",
      "\n",
      "Epoch:  6951/40000, total loss = 3.279, Fit loss U = 7.744, Fit loss F = 5.915, KL loss = 519.171\n",
      "Epoch:  6951/40000, alpha = 1.20263\n",
      "\n",
      "Epoch:  6961/40000, total loss = 3.428, Fit loss U = 11.077, Fit loss F = 5.899, KL loss = 515.805\n",
      "Epoch:  6961/40000, alpha = 1.20138\n",
      "\n",
      "Epoch:  6971/40000, total loss = 3.383, Fit loss U = 10.497, Fit loss F = 5.883, KL loss = 512.697\n",
      "Epoch:  6971/40000, alpha = 1.20013\n",
      "\n",
      "Epoch:  6981/40000, total loss = 3.354, Fit loss U = 10.242, Fit loss F = 5.867, KL loss = 509.628\n",
      "Epoch:  6981/40000, alpha = 1.19889\n",
      "\n",
      "Epoch:  6991/40000, total loss = 3.290, Fit loss U = 9.328, Fit loss F = 5.851, KL loss = 506.201\n",
      "Epoch:  6991/40000, alpha = 1.19767\n",
      "\n",
      "Epoch:  7001/40000, total loss = 3.288, Fit loss U = 9.687, Fit loss F = 5.835, KL loss = 502.457\n",
      "Epoch:  7001/40000, error_test = 1.02301, error_train = 0.98304\n",
      "Epoch:  7001/40000, error_f = 1.00000\n",
      "Epoch:  7001/40000, alpha = 1.19645\n",
      "\n",
      "Epoch:  7011/40000, total loss = 3.186, Fit loss U = 8.032, Fit loss F = 5.820, KL loss = 498.748\n",
      "Epoch:  7011/40000, alpha = 1.19523\n",
      "\n",
      "Epoch:  7021/40000, total loss = 3.229, Fit loss U = 9.244, Fit loss F = 5.804, KL loss = 495.224\n",
      "Epoch:  7021/40000, alpha = 1.19403\n",
      "\n",
      "Epoch:  7031/40000, total loss = 3.328, Fit loss U = 11.506, Fit loss F = 5.788, KL loss = 492.590\n",
      "Epoch:  7031/40000, alpha = 1.19283\n",
      "\n",
      "Epoch:  7041/40000, total loss = 3.280, Fit loss U = 10.798, Fit loss F = 5.773, KL loss = 490.361\n",
      "Epoch:  7041/40000, alpha = 1.19165\n",
      "\n",
      "Epoch:  7051/40000, total loss = 3.215, Fit loss U = 9.754, Fit loss F = 5.758, KL loss = 487.808\n",
      "Epoch:  7051/40000, alpha = 1.19047\n",
      "\n",
      "Epoch:  7061/40000, total loss = 3.100, Fit loss U = 7.771, Fit loss F = 5.743, KL loss = 484.782\n",
      "Epoch:  7061/40000, alpha = 1.18929\n",
      "\n",
      "Epoch:  7071/40000, total loss = 3.355, Fit loss U = 13.203, Fit loss F = 5.727, KL loss = 481.696\n",
      "Epoch:  7071/40000, alpha = 1.18813\n",
      "\n",
      "Epoch:  7081/40000, total loss = 3.173, Fit loss U = 9.778, Fit loss F = 5.712, KL loss = 479.743\n",
      "Epoch:  7081/40000, alpha = 1.18697\n",
      "\n",
      "Epoch:  7091/40000, total loss = 3.253, Fit loss U = 11.604, Fit loss F = 5.697, KL loss = 477.648\n",
      "Epoch:  7091/40000, alpha = 1.18582\n",
      "\n",
      "Epoch:  7101/40000, total loss = 3.106, Fit loss U = 8.816, Fit loss F = 5.682, KL loss = 476.217\n",
      "Epoch:  7101/40000, error_test = 1.00268, error_train = 1.04655\n",
      "Epoch:  7101/40000, error_f = 1.00000\n",
      "Epoch:  7101/40000, alpha = 1.18468\n",
      "\n",
      "Epoch:  7111/40000, total loss = 3.117, Fit loss U = 9.254, Fit loss F = 5.668, KL loss = 474.241\n",
      "Epoch:  7111/40000, alpha = 1.18354\n",
      "\n",
      "Epoch:  7121/40000, total loss = 3.210, Fit loss U = 11.284, Fit loss F = 5.653, KL loss = 472.638\n",
      "Epoch:  7121/40000, alpha = 1.18242\n",
      "\n",
      "Epoch:  7131/40000, total loss = 3.147, Fit loss U = 10.187, Fit loss F = 5.639, KL loss = 471.051\n",
      "Epoch:  7131/40000, alpha = 1.18130\n",
      "\n",
      "Epoch:  7141/40000, total loss = 3.121, Fit loss U = 9.829, Fit loss F = 5.624, KL loss = 469.598\n",
      "Epoch:  7141/40000, alpha = 1.18018\n",
      "\n",
      "Epoch:  7151/40000, total loss = 3.053, Fit loss U = 8.703, Fit loss F = 5.610, KL loss = 467.544\n",
      "Epoch:  7151/40000, alpha = 1.17908\n",
      "\n",
      "Epoch:  7161/40000, total loss = 3.150, Fit loss U = 10.837, Fit loss F = 5.595, KL loss = 465.756\n",
      "Epoch:  7161/40000, alpha = 1.17798\n",
      "\n",
      "Epoch:  7171/40000, total loss = 3.040, Fit loss U = 8.733, Fit loss F = 5.581, KL loss = 464.786\n",
      "Epoch:  7171/40000, alpha = 1.17689\n",
      "\n",
      "Epoch:  7181/40000, total loss = 3.014, Fit loss U = 8.391, Fit loss F = 5.567, KL loss = 463.309\n",
      "Epoch:  7181/40000, alpha = 1.17580\n",
      "\n",
      "Epoch:  7191/40000, total loss = 3.115, Fit loss U = 10.573, Fit loss F = 5.553, KL loss = 461.655\n",
      "Epoch:  7191/40000, alpha = 1.17473\n",
      "\n",
      "Epoch:  7201/40000, total loss = 2.908, Fit loss U = 6.571, Fit loss F = 5.539, KL loss = 460.461\n",
      "Epoch:  7201/40000, error_test = 1.01357, error_train = 1.00460\n",
      "Epoch:  7201/40000, error_f = 1.00000\n",
      "Epoch:  7201/40000, alpha = 1.17366\n",
      "\n",
      "Epoch:  7211/40000, total loss = 3.081, Fit loss U = 10.082, Fit loss F = 5.525, KL loss = 460.120\n",
      "Epoch:  7211/40000, alpha = 1.17260\n",
      "\n",
      "Epoch:  7221/40000, total loss = 2.981, Fit loss U = 8.196, Fit loss F = 5.511, KL loss = 459.200\n",
      "Epoch:  7221/40000, alpha = 1.17154\n",
      "\n",
      "Epoch:  7231/40000, total loss = 3.073, Fit loss U = 10.214, Fit loss F = 5.498, KL loss = 457.514\n",
      "Epoch:  7231/40000, alpha = 1.17049\n",
      "\n",
      "Epoch:  7241/40000, total loss = 3.154, Fit loss U = 11.999, Fit loss F = 5.484, KL loss = 456.034\n",
      "Epoch:  7241/40000, alpha = 1.16945\n",
      "\n",
      "Epoch:  7251/40000, total loss = 2.954, Fit loss U = 8.109, Fit loss F = 5.470, KL loss = 454.929\n",
      "Epoch:  7251/40000, alpha = 1.16841\n",
      "\n",
      "Epoch:  7261/40000, total loss = 2.962, Fit loss U = 8.415, Fit loss F = 5.457, KL loss = 453.584\n",
      "Epoch:  7261/40000, alpha = 1.16739\n",
      "\n",
      "Epoch:  7271/40000, total loss = 3.029, Fit loss U = 9.886, Fit loss F = 5.443, KL loss = 452.586\n",
      "Epoch:  7271/40000, alpha = 1.16637\n",
      "\n",
      "Epoch:  7281/40000, total loss = 3.098, Fit loss U = 11.402, Fit loss F = 5.430, KL loss = 451.340\n",
      "Epoch:  7281/40000, alpha = 1.16535\n",
      "\n",
      "Epoch:  7291/40000, total loss = 3.037, Fit loss U = 10.277, Fit loss F = 5.417, KL loss = 450.457\n",
      "Epoch:  7291/40000, alpha = 1.16434\n",
      "\n",
      "Epoch:  7301/40000, total loss = 2.825, Fit loss U = 6.127, Fit loss F = 5.404, KL loss = 449.772\n",
      "Epoch:  7301/40000, error_test = 1.01573, error_train = 1.05833\n",
      "Epoch:  7301/40000, error_f = 1.00000\n",
      "Epoch:  7301/40000, alpha = 1.16334\n",
      "\n",
      "Epoch:  7311/40000, total loss = 2.964, Fit loss U = 8.986, Fit loss F = 5.391, KL loss = 449.068\n",
      "Epoch:  7311/40000, alpha = 1.16235\n",
      "\n",
      "Epoch:  7321/40000, total loss = 2.942, Fit loss U = 8.630, Fit loss F = 5.378, KL loss = 448.376\n",
      "Epoch:  7321/40000, alpha = 1.16136\n",
      "\n",
      "Epoch:  7331/40000, total loss = 2.841, Fit loss U = 6.689, Fit loss F = 5.365, KL loss = 447.736\n",
      "Epoch:  7331/40000, alpha = 1.16037\n",
      "\n",
      "Epoch:  7341/40000, total loss = 2.907, Fit loss U = 8.063, Fit loss F = 5.352, KL loss = 447.295\n",
      "Epoch:  7341/40000, alpha = 1.15940\n",
      "\n",
      "Epoch:  7351/40000, total loss = 2.933, Fit loss U = 8.653, Fit loss F = 5.340, KL loss = 446.725\n",
      "Epoch:  7351/40000, alpha = 1.15843\n",
      "\n",
      "Epoch:  7361/40000, total loss = 2.965, Fit loss U = 9.369, Fit loss F = 5.327, KL loss = 446.068\n",
      "Epoch:  7361/40000, alpha = 1.15747\n",
      "\n",
      "Epoch:  7371/40000, total loss = 2.908, Fit loss U = 8.290, Fit loss F = 5.314, KL loss = 445.506\n",
      "Epoch:  7371/40000, alpha = 1.15651\n",
      "\n",
      "Epoch:  7381/40000, total loss = 2.826, Fit loss U = 6.746, Fit loss F = 5.302, KL loss = 444.737\n",
      "Epoch:  7381/40000, alpha = 1.15556\n",
      "\n",
      "Epoch:  7391/40000, total loss = 2.953, Fit loss U = 9.365, Fit loss F = 5.290, KL loss = 443.966\n",
      "Epoch:  7391/40000, alpha = 1.15461\n",
      "\n",
      "Epoch:  7401/40000, total loss = 2.867, Fit loss U = 7.716, Fit loss F = 5.277, KL loss = 443.480\n",
      "Epoch:  7401/40000, error_test = 1.01660, error_train = 0.92030\n",
      "Epoch:  7401/40000, error_f = 1.00000\n",
      "Epoch:  7401/40000, alpha = 1.15368\n",
      "\n",
      "Epoch:  7411/40000, total loss = 3.007, Fit loss U = 10.547, Fit loss F = 5.265, KL loss = 443.293\n",
      "Epoch:  7411/40000, alpha = 1.15274\n",
      "\n",
      "Epoch:  7421/40000, total loss = 2.907, Fit loss U = 8.559, Fit loss F = 5.253, KL loss = 443.297\n",
      "Epoch:  7421/40000, alpha = 1.15182\n",
      "\n",
      "Epoch:  7431/40000, total loss = 3.145, Fit loss U = 13.293, Fit loss F = 5.241, KL loss = 443.637\n",
      "Epoch:  7431/40000, alpha = 1.15090\n",
      "\n",
      "Epoch:  7441/40000, total loss = 2.998, Fit loss U = 10.316, Fit loss F = 5.229, KL loss = 444.199\n",
      "Epoch:  7441/40000, alpha = 1.14998\n",
      "\n",
      "Epoch:  7451/40000, total loss = 2.943, Fit loss U = 9.161, Fit loss F = 5.217, KL loss = 444.788\n",
      "Epoch:  7451/40000, alpha = 1.14908\n",
      "\n",
      "Epoch:  7461/40000, total loss = 3.120, Fit loss U = 12.732, Fit loss F = 5.205, KL loss = 444.619\n",
      "Epoch:  7461/40000, alpha = 1.14817\n",
      "\n",
      "Epoch:  7471/40000, total loss = 2.974, Fit loss U = 9.792, Fit loss F = 5.193, KL loss = 444.988\n",
      "Epoch:  7471/40000, alpha = 1.14728\n",
      "\n",
      "Epoch:  7481/40000, total loss = 3.046, Fit loss U = 11.269, Fit loss F = 5.181, KL loss = 444.631\n",
      "Epoch:  7481/40000, alpha = 1.14639\n",
      "\n",
      "Epoch:  7491/40000, total loss = 2.868, Fit loss U = 7.768, Fit loss F = 5.170, KL loss = 444.317\n",
      "Epoch:  7491/40000, alpha = 1.14550\n",
      "\n",
      "Epoch:  7501/40000, total loss = 2.928, Fit loss U = 9.020, Fit loss F = 5.158, KL loss = 443.864\n",
      "Epoch:  7501/40000, error_test = 1.03081, error_train = 1.00428\n",
      "Epoch:  7501/40000, error_f = 1.00000\n",
      "Epoch:  7501/40000, alpha = 1.14462\n",
      "\n",
      "Epoch:  7511/40000, total loss = 3.008, Fit loss U = 10.676, Fit loss F = 5.146, KL loss = 443.347\n",
      "Epoch:  7511/40000, alpha = 1.14375\n",
      "\n",
      "Epoch:  7521/40000, total loss = 2.962, Fit loss U = 9.831, Fit loss F = 5.135, KL loss = 442.743\n",
      "Epoch:  7521/40000, alpha = 1.14288\n",
      "\n",
      "Epoch:  7531/40000, total loss = 2.962, Fit loss U = 9.893, Fit loss F = 5.124, KL loss = 442.228\n",
      "Epoch:  7531/40000, alpha = 1.14202\n",
      "\n",
      "Epoch:  7541/40000, total loss = 3.017, Fit loss U = 11.069, Fit loss F = 5.112, KL loss = 441.489\n",
      "Epoch:  7541/40000, alpha = 1.14117\n",
      "\n",
      "Epoch:  7551/40000, total loss = 2.895, Fit loss U = 8.715, Fit loss F = 5.101, KL loss = 440.780\n",
      "Epoch:  7551/40000, alpha = 1.14032\n",
      "\n",
      "Epoch:  7561/40000, total loss = 2.856, Fit loss U = 8.048, Fit loss F = 5.090, KL loss = 439.820\n",
      "Epoch:  7561/40000, alpha = 1.13947\n",
      "\n",
      "Epoch:  7571/40000, total loss = 3.016, Fit loss U = 11.339, Fit loss F = 5.079, KL loss = 438.947\n",
      "Epoch:  7571/40000, alpha = 1.13863\n",
      "\n",
      "Epoch:  7581/40000, total loss = 2.855, Fit loss U = 8.137, Fit loss F = 5.068, KL loss = 438.937\n",
      "Epoch:  7581/40000, alpha = 1.13780\n",
      "\n",
      "Epoch:  7591/40000, total loss = 2.768, Fit loss U = 6.449, Fit loss F = 5.057, KL loss = 438.521\n",
      "Epoch:  7591/40000, alpha = 1.13697\n",
      "\n",
      "Epoch:  7601/40000, total loss = 3.026, Fit loss U = 11.601, Fit loss F = 5.046, KL loss = 438.725\n",
      "Epoch:  7601/40000, error_test = 1.01563, error_train = 0.99371\n",
      "Epoch:  7601/40000, error_f = 1.00000\n",
      "Epoch:  7601/40000, alpha = 1.13614\n",
      "\n",
      "Epoch:  7611/40000, total loss = 2.890, Fit loss U = 8.865, Fit loss F = 5.035, KL loss = 438.942\n",
      "Epoch:  7611/40000, alpha = 1.13533\n",
      "\n",
      "Epoch:  7621/40000, total loss = 2.877, Fit loss U = 8.670, Fit loss F = 5.024, KL loss = 438.559\n",
      "Epoch:  7621/40000, alpha = 1.13451\n",
      "\n",
      "Epoch:  7631/40000, total loss = 2.908, Fit loss U = 9.336, Fit loss F = 5.014, KL loss = 438.091\n",
      "Epoch:  7631/40000, alpha = 1.13371\n",
      "\n",
      "Epoch:  7641/40000, total loss = 3.065, Fit loss U = 12.520, Fit loss F = 5.003, KL loss = 437.824\n",
      "Epoch:  7641/40000, alpha = 1.13290\n",
      "\n",
      "Epoch:  7651/40000, total loss = 2.879, Fit loss U = 8.733, Fit loss F = 4.993, KL loss = 438.575\n",
      "Epoch:  7651/40000, alpha = 1.13211\n",
      "\n",
      "Epoch:  7661/40000, total loss = 2.756, Fit loss U = 6.292, Fit loss F = 4.982, KL loss = 438.517\n",
      "Epoch:  7661/40000, alpha = 1.13131\n",
      "\n",
      "Epoch:  7671/40000, total loss = 3.008, Fit loss U = 11.388, Fit loss F = 4.972, KL loss = 437.944\n",
      "Epoch:  7671/40000, alpha = 1.13053\n",
      "\n",
      "Epoch:  7681/40000, total loss = 2.968, Fit loss U = 10.535, Fit loss F = 4.961, KL loss = 438.583\n",
      "Epoch:  7681/40000, alpha = 1.12975\n",
      "\n",
      "Epoch:  7691/40000, total loss = 2.966, Fit loss U = 10.418, Fit loss F = 4.951, KL loss = 439.474\n",
      "Epoch:  7691/40000, alpha = 1.12897\n",
      "\n",
      "Epoch:  7701/40000, total loss = 2.836, Fit loss U = 7.777, Fit loss F = 4.941, KL loss = 440.050\n",
      "Epoch:  7701/40000, error_test = 0.99082, error_train = 1.00724\n",
      "Epoch:  7701/40000, error_f = 1.00000\n",
      "Epoch:  7701/40000, alpha = 1.12820\n",
      "\n",
      "Epoch:  7711/40000, total loss = 3.215, Fit loss U = 15.449, Fit loss F = 4.931, KL loss = 439.164\n",
      "Epoch:  7711/40000, alpha = 1.12743\n",
      "\n",
      "Epoch:  7721/40000, total loss = 2.920, Fit loss U = 9.488, Fit loss F = 4.921, KL loss = 439.820\n",
      "Epoch:  7721/40000, alpha = 1.12667\n",
      "\n",
      "Epoch:  7731/40000, total loss = 2.921, Fit loss U = 9.489, Fit loss F = 4.911, KL loss = 440.153\n",
      "Epoch:  7731/40000, alpha = 1.12591\n",
      "\n",
      "Epoch:  7741/40000, total loss = 2.805, Fit loss U = 7.151, Fit loss F = 4.901, KL loss = 440.392\n",
      "Epoch:  7741/40000, alpha = 1.12516\n",
      "\n",
      "Epoch:  7751/40000, total loss = 2.891, Fit loss U = 8.985, Fit loss F = 4.891, KL loss = 439.532\n",
      "Epoch:  7751/40000, alpha = 1.12441\n",
      "\n",
      "Epoch:  7761/40000, total loss = 3.095, Fit loss U = 13.128, Fit loss F = 4.881, KL loss = 438.825\n",
      "Epoch:  7761/40000, alpha = 1.12367\n",
      "\n",
      "Epoch:  7771/40000, total loss = 2.823, Fit loss U = 7.632, Fit loss F = 4.871, KL loss = 439.555\n",
      "Epoch:  7771/40000, alpha = 1.12293\n",
      "\n",
      "Epoch:  7781/40000, total loss = 2.840, Fit loss U = 7.969, Fit loss F = 4.861, KL loss = 439.605\n",
      "Epoch:  7781/40000, alpha = 1.12220\n",
      "\n",
      "Epoch:  7791/40000, total loss = 2.918, Fit loss U = 9.656, Fit loss F = 4.852, KL loss = 438.608\n",
      "Epoch:  7791/40000, alpha = 1.12147\n",
      "\n",
      "Epoch:  7801/40000, total loss = 2.862, Fit loss U = 8.558, Fit loss F = 4.842, KL loss = 438.442\n",
      "Epoch:  7801/40000, error_test = 1.00336, error_train = 1.03098\n",
      "Epoch:  7801/40000, error_f = 1.00000\n",
      "Epoch:  7801/40000, alpha = 1.12075\n",
      "\n",
      "Epoch:  7811/40000, total loss = 2.930, Fit loss U = 9.904, Fit loss F = 4.833, KL loss = 438.624\n",
      "Epoch:  7811/40000, alpha = 1.12003\n",
      "\n",
      "Epoch:  7821/40000, total loss = 2.791, Fit loss U = 7.148, Fit loss F = 4.823, KL loss = 438.579\n",
      "Epoch:  7821/40000, alpha = 1.11931\n",
      "\n",
      "Epoch:  7831/40000, total loss = 2.850, Fit loss U = 8.320, Fit loss F = 4.814, KL loss = 438.576\n",
      "Epoch:  7831/40000, alpha = 1.11861\n",
      "\n",
      "Epoch:  7841/40000, total loss = 2.844, Fit loss U = 8.298, Fit loss F = 4.804, KL loss = 437.721\n",
      "Epoch:  7841/40000, alpha = 1.11790\n",
      "\n",
      "Epoch:  7851/40000, total loss = 2.853, Fit loss U = 8.536, Fit loss F = 4.795, KL loss = 437.196\n",
      "Epoch:  7851/40000, alpha = 1.11720\n",
      "\n",
      "Epoch:  7861/40000, total loss = 2.966, Fit loss U = 10.803, Fit loss F = 4.786, KL loss = 437.356\n",
      "Epoch:  7861/40000, alpha = 1.11650\n",
      "\n",
      "Epoch:  7871/40000, total loss = 2.867, Fit loss U = 8.758, Fit loss F = 4.777, KL loss = 438.053\n",
      "Epoch:  7871/40000, alpha = 1.11581\n",
      "\n",
      "Epoch:  7881/40000, total loss = 2.831, Fit loss U = 8.041, Fit loss F = 4.767, KL loss = 438.032\n",
      "Epoch:  7881/40000, alpha = 1.11513\n",
      "\n",
      "Epoch:  7891/40000, total loss = 2.809, Fit loss U = 7.673, Fit loss F = 4.759, KL loss = 437.540\n",
      "Epoch:  7891/40000, alpha = 1.11444\n",
      "\n",
      "Epoch:  7901/40000, total loss = 3.015, Fit loss U = 11.840, Fit loss F = 4.750, KL loss = 437.124\n",
      "Epoch:  7901/40000, error_test = 1.03715, error_train = 0.96354\n",
      "Epoch:  7901/40000, error_f = 1.00000\n",
      "Epoch:  7901/40000, alpha = 1.11376\n",
      "\n",
      "Epoch:  7911/40000, total loss = 2.869, Fit loss U = 8.912, Fit loss F = 4.740, KL loss = 437.321\n",
      "Epoch:  7911/40000, alpha = 1.11309\n",
      "\n",
      "Epoch:  7921/40000, total loss = 2.877, Fit loss U = 9.098, Fit loss F = 4.732, KL loss = 437.176\n",
      "Epoch:  7921/40000, alpha = 1.11242\n",
      "\n",
      "Epoch:  7931/40000, total loss = 2.881, Fit loss U = 9.180, Fit loss F = 4.723, KL loss = 437.186\n",
      "Epoch:  7931/40000, alpha = 1.11176\n",
      "\n",
      "Epoch:  7941/40000, total loss = 2.863, Fit loss U = 8.817, Fit loss F = 4.714, KL loss = 437.383\n",
      "Epoch:  7941/40000, alpha = 1.11109\n",
      "\n",
      "Epoch:  7951/40000, total loss = 2.809, Fit loss U = 7.773, Fit loss F = 4.705, KL loss = 437.085\n",
      "Epoch:  7951/40000, alpha = 1.11044\n",
      "\n",
      "Epoch:  7961/40000, total loss = 3.098, Fit loss U = 13.565, Fit loss F = 4.696, KL loss = 437.041\n",
      "Epoch:  7961/40000, alpha = 1.10979\n",
      "\n",
      "Epoch:  7971/40000, total loss = 3.004, Fit loss U = 11.639, Fit loss F = 4.688, KL loss = 437.538\n",
      "Epoch:  7971/40000, alpha = 1.10914\n",
      "\n",
      "Epoch:  7981/40000, total loss = 2.810, Fit loss U = 7.751, Fit loss F = 4.679, KL loss = 437.753\n",
      "Epoch:  7981/40000, alpha = 1.10849\n",
      "\n",
      "Epoch:  7991/40000, total loss = 2.820, Fit loss U = 7.925, Fit loss F = 4.671, KL loss = 438.040\n",
      "Epoch:  7991/40000, alpha = 1.10785\n",
      "\n",
      "Epoch:  8001/40000, total loss = 3.028, Fit loss U = 12.106, Fit loss F = 4.662, KL loss = 437.822\n",
      "Epoch:  8001/40000, error_test = 1.00936, error_train = 0.96622\n",
      "Epoch:  8001/40000, error_f = 1.00001\n",
      "Epoch:  8001/40000, alpha = 1.10722\n",
      "\n",
      "Epoch:  8011/40000, total loss = 2.892, Fit loss U = 9.410, Fit loss F = 4.654, KL loss = 437.779\n",
      "Epoch:  8011/40000, alpha = 1.10658\n",
      "\n",
      "Epoch:  8021/40000, total loss = 3.024, Fit loss U = 12.081, Fit loss F = 4.645, KL loss = 437.626\n",
      "Epoch:  8021/40000, alpha = 1.10596\n",
      "\n",
      "Epoch:  8031/40000, total loss = 2.928, Fit loss U = 10.083, Fit loss F = 4.637, KL loss = 438.482\n",
      "Epoch:  8031/40000, alpha = 1.10533\n",
      "\n",
      "Epoch:  8041/40000, total loss = 2.889, Fit loss U = 9.256, Fit loss F = 4.629, KL loss = 438.921\n",
      "Epoch:  8041/40000, alpha = 1.10471\n",
      "\n",
      "Epoch:  8051/40000, total loss = 2.945, Fit loss U = 10.468, Fit loss F = 4.621, KL loss = 438.193\n",
      "Epoch:  8051/40000, alpha = 1.10410\n",
      "\n",
      "Epoch:  8061/40000, total loss = 2.881, Fit loss U = 9.230, Fit loss F = 4.612, KL loss = 437.853\n",
      "Epoch:  8061/40000, alpha = 1.10348\n",
      "\n",
      "Epoch:  8071/40000, total loss = 2.947, Fit loss U = 10.516, Fit loss F = 4.604, KL loss = 438.239\n",
      "Epoch:  8071/40000, alpha = 1.10288\n",
      "\n",
      "Epoch:  8081/40000, total loss = 2.949, Fit loss U = 10.581, Fit loss F = 4.596, KL loss = 437.943\n",
      "Epoch:  8081/40000, alpha = 1.10227\n",
      "\n",
      "Epoch:  8091/40000, total loss = 2.988, Fit loss U = 11.334, Fit loss F = 4.588, KL loss = 438.313\n",
      "Epoch:  8091/40000, alpha = 1.10167\n",
      "\n",
      "Epoch:  8101/40000, total loss = 3.339, Fit loss U = 18.381, Fit loss F = 4.580, KL loss = 438.238\n",
      "Epoch:  8101/40000, error_test = 1.00941, error_train = 1.01017\n",
      "Epoch:  8101/40000, error_f = 1.00000\n",
      "Epoch:  8101/40000, alpha = 1.10107\n",
      "\n",
      "Epoch:  8111/40000, total loss = 2.833, Fit loss U = 8.076, Fit loss F = 4.572, KL loss = 440.213\n",
      "Epoch:  8111/40000, alpha = 1.10048\n",
      "\n",
      "Epoch:  8121/40000, total loss = 2.959, Fit loss U = 10.531, Fit loss F = 4.565, KL loss = 440.839\n",
      "Epoch:  8121/40000, alpha = 1.09989\n",
      "\n",
      "Epoch:  8131/40000, total loss = 2.914, Fit loss U = 9.597, Fit loss F = 4.557, KL loss = 441.332\n",
      "Epoch:  8131/40000, alpha = 1.09931\n",
      "\n",
      "Epoch:  8141/40000, total loss = 2.929, Fit loss U = 9.898, Fit loss F = 4.549, KL loss = 441.408\n",
      "Epoch:  8141/40000, alpha = 1.09872\n",
      "\n",
      "Epoch:  8151/40000, total loss = 2.873, Fit loss U = 8.880, Fit loss F = 4.541, KL loss = 440.452\n",
      "Epoch:  8151/40000, alpha = 1.09815\n",
      "\n",
      "Epoch:  8161/40000, total loss = 2.942, Fit loss U = 10.272, Fit loss F = 4.534, KL loss = 440.340\n",
      "Epoch:  8161/40000, alpha = 1.09757\n",
      "\n",
      "Epoch:  8171/40000, total loss = 2.811, Fit loss U = 7.594, Fit loss F = 4.526, KL loss = 440.995\n",
      "Epoch:  8171/40000, alpha = 1.09700\n",
      "\n",
      "Epoch:  8181/40000, total loss = 2.871, Fit loss U = 8.793, Fit loss F = 4.518, KL loss = 441.161\n",
      "Epoch:  8181/40000, alpha = 1.09643\n",
      "\n",
      "Epoch:  8191/40000, total loss = 2.945, Fit loss U = 10.314, Fit loss F = 4.511, KL loss = 440.711\n",
      "Epoch:  8191/40000, alpha = 1.09587\n",
      "\n",
      "Epoch:  8201/40000, total loss = 2.801, Fit loss U = 7.514, Fit loss F = 4.503, KL loss = 440.010\n",
      "Epoch:  8201/40000, error_test = 1.02407, error_train = 0.97181\n",
      "Epoch:  8201/40000, error_f = 1.00000\n",
      "Epoch:  8201/40000, alpha = 1.09531\n",
      "\n",
      "Epoch:  8211/40000, total loss = 2.966, Fit loss U = 10.890, Fit loss F = 4.496, KL loss = 439.426\n",
      "Epoch:  8211/40000, alpha = 1.09475\n",
      "\n",
      "Epoch:  8221/40000, total loss = 2.879, Fit loss U = 9.128, Fit loss F = 4.489, KL loss = 439.621\n",
      "Epoch:  8221/40000, alpha = 1.09420\n",
      "\n",
      "Epoch:  8231/40000, total loss = 2.816, Fit loss U = 7.820, Fit loss F = 4.481, KL loss = 440.160\n",
      "Epoch:  8231/40000, alpha = 1.09365\n",
      "\n",
      "Epoch:  8241/40000, total loss = 2.883, Fit loss U = 9.211, Fit loss F = 4.474, KL loss = 439.751\n",
      "Epoch:  8241/40000, alpha = 1.09311\n",
      "\n",
      "Epoch:  8251/40000, total loss = 2.768, Fit loss U = 6.992, Fit loss F = 4.467, KL loss = 439.046\n",
      "Epoch:  8251/40000, alpha = 1.09256\n",
      "\n",
      "Epoch:  8261/40000, total loss = 2.886, Fit loss U = 9.411, Fit loss F = 4.460, KL loss = 438.409\n",
      "Epoch:  8261/40000, alpha = 1.09202\n",
      "\n",
      "Epoch:  8271/40000, total loss = 2.907, Fit loss U = 9.806, Fit loss F = 4.452, KL loss = 438.763\n",
      "Epoch:  8271/40000, alpha = 1.09149\n",
      "\n",
      "Epoch:  8281/40000, total loss = 2.881, Fit loss U = 9.319, Fit loss F = 4.445, KL loss = 438.538\n",
      "Epoch:  8281/40000, alpha = 1.09096\n",
      "\n",
      "Epoch:  8291/40000, total loss = 3.053, Fit loss U = 12.760, Fit loss F = 4.438, KL loss = 438.676\n",
      "Epoch:  8291/40000, alpha = 1.09043\n",
      "\n",
      "Epoch:  8301/40000, total loss = 2.752, Fit loss U = 6.732, Fit loss F = 4.431, KL loss = 438.814\n",
      "Epoch:  8301/40000, error_test = 1.04504, error_train = 1.00677\n",
      "Epoch:  8301/40000, error_f = 1.00000\n",
      "Epoch:  8301/40000, alpha = 1.08990\n",
      "\n",
      "Epoch:  8311/40000, total loss = 2.949, Fit loss U = 10.786, Fit loss F = 4.424, KL loss = 437.632\n",
      "Epoch:  8311/40000, alpha = 1.08938\n",
      "\n",
      "Epoch:  8321/40000, total loss = 2.900, Fit loss U = 9.831, Fit loss F = 4.417, KL loss = 437.616\n",
      "Epoch:  8321/40000, alpha = 1.08886\n",
      "\n",
      "Epoch:  8331/40000, total loss = 2.831, Fit loss U = 8.313, Fit loss F = 4.410, KL loss = 438.915\n",
      "Epoch:  8331/40000, alpha = 1.08835\n",
      "\n",
      "Epoch:  8341/40000, total loss = 2.918, Fit loss U = 10.012, Fit loss F = 4.403, KL loss = 439.489\n",
      "Epoch:  8341/40000, alpha = 1.08783\n",
      "\n",
      "Epoch:  8351/40000, total loss = 2.752, Fit loss U = 6.657, Fit loss F = 4.397, KL loss = 439.882\n",
      "Epoch:  8351/40000, alpha = 1.08732\n",
      "\n",
      "Epoch:  8361/40000, total loss = 2.828, Fit loss U = 8.210, Fit loss F = 4.390, KL loss = 439.645\n",
      "Epoch:  8361/40000, alpha = 1.08682\n",
      "\n",
      "Epoch:  8371/40000, total loss = 2.813, Fit loss U = 7.938, Fit loss F = 4.383, KL loss = 439.410\n",
      "Epoch:  8371/40000, alpha = 1.08632\n",
      "\n",
      "Epoch:  8381/40000, total loss = 2.847, Fit loss U = 8.644, Fit loss F = 4.376, KL loss = 439.132\n",
      "Epoch:  8381/40000, alpha = 1.08582\n",
      "\n",
      "Epoch:  8391/40000, total loss = 2.822, Fit loss U = 8.224, Fit loss F = 4.370, KL loss = 438.493\n",
      "Epoch:  8391/40000, alpha = 1.08532\n",
      "\n",
      "Epoch:  8401/40000, total loss = 2.802, Fit loss U = 7.919, Fit loss F = 4.363, KL loss = 437.618\n",
      "Epoch:  8401/40000, error_test = 1.00406, error_train = 0.99404\n",
      "Epoch:  8401/40000, error_f = 1.00000\n",
      "Epoch:  8401/40000, alpha = 1.08483\n",
      "\n",
      "Epoch:  8411/40000, total loss = 2.957, Fit loss U = 11.077, Fit loss F = 4.357, KL loss = 437.159\n",
      "Epoch:  8411/40000, alpha = 1.08434\n",
      "\n",
      "Epoch:  8421/40000, total loss = 2.841, Fit loss U = 8.687, Fit loss F = 4.350, KL loss = 437.901\n",
      "Epoch:  8421/40000, alpha = 1.08385\n",
      "\n",
      "Epoch:  8431/40000, total loss = 2.864, Fit loss U = 9.044, Fit loss F = 4.344, KL loss = 438.918\n",
      "Epoch:  8431/40000, alpha = 1.08336\n",
      "\n",
      "Epoch:  8441/40000, total loss = 2.795, Fit loss U = 7.567, Fit loss F = 4.337, KL loss = 439.973\n",
      "Epoch:  8441/40000, alpha = 1.08288\n",
      "\n",
      "Epoch:  8451/40000, total loss = 2.912, Fit loss U = 9.904, Fit loss F = 4.331, KL loss = 440.032\n",
      "Epoch:  8451/40000, alpha = 1.08240\n",
      "\n",
      "Epoch:  8461/40000, total loss = 2.875, Fit loss U = 9.159, Fit loss F = 4.324, KL loss = 440.084\n",
      "Epoch:  8461/40000, alpha = 1.08193\n",
      "\n",
      "Epoch:  8471/40000, total loss = 2.966, Fit loss U = 11.097, Fit loss F = 4.318, KL loss = 439.147\n",
      "Epoch:  8471/40000, alpha = 1.08146\n",
      "\n",
      "Epoch:  8481/40000, total loss = 2.861, Fit loss U = 8.973, Fit loss F = 4.312, KL loss = 439.349\n",
      "Epoch:  8481/40000, alpha = 1.08099\n",
      "\n",
      "Epoch:  8491/40000, total loss = 2.827, Fit loss U = 8.272, Fit loss F = 4.305, KL loss = 439.648\n",
      "Epoch:  8491/40000, alpha = 1.08052\n",
      "\n",
      "Epoch:  8501/40000, total loss = 2.876, Fit loss U = 9.305, Fit loss F = 4.299, KL loss = 439.133\n",
      "Epoch:  8501/40000, error_test = 0.99091, error_train = 1.01795\n",
      "Epoch:  8501/40000, error_f = 0.99999\n",
      "Epoch:  8501/40000, alpha = 1.08006\n",
      "\n",
      "Epoch:  8511/40000, total loss = 2.851, Fit loss U = 8.911, Fit loss F = 4.293, KL loss = 438.215\n",
      "Epoch:  8511/40000, alpha = 1.07960\n",
      "\n",
      "Epoch:  8521/40000, total loss = 3.022, Fit loss U = 12.338, Fit loss F = 4.287, KL loss = 438.104\n",
      "Epoch:  8521/40000, alpha = 1.07914\n",
      "\n",
      "Epoch:  8531/40000, total loss = 2.845, Fit loss U = 8.807, Fit loss F = 4.281, KL loss = 438.108\n",
      "Epoch:  8531/40000, alpha = 1.07869\n",
      "\n",
      "Epoch:  8541/40000, total loss = 2.951, Fit loss U = 10.964, Fit loss F = 4.275, KL loss = 437.817\n",
      "Epoch:  8541/40000, alpha = 1.07823\n",
      "\n",
      "Epoch:  8551/40000, total loss = 2.715, Fit loss U = 6.288, Fit loss F = 4.269, KL loss = 437.519\n",
      "Epoch:  8551/40000, alpha = 1.07778\n",
      "\n",
      "Epoch:  8561/40000, total loss = 2.814, Fit loss U = 8.351, Fit loss F = 4.263, KL loss = 436.567\n",
      "Epoch:  8561/40000, alpha = 1.07734\n",
      "\n",
      "Epoch:  8571/40000, total loss = 3.031, Fit loss U = 12.684, Fit loss F = 4.257, KL loss = 436.835\n",
      "Epoch:  8571/40000, alpha = 1.07689\n",
      "\n",
      "Epoch:  8581/40000, total loss = 2.840, Fit loss U = 8.738, Fit loss F = 4.251, KL loss = 438.104\n",
      "Epoch:  8581/40000, alpha = 1.07645\n",
      "\n",
      "Epoch:  8591/40000, total loss = 2.922, Fit loss U = 10.356, Fit loss F = 4.245, KL loss = 438.419\n",
      "Epoch:  8591/40000, alpha = 1.07602\n",
      "\n",
      "Epoch:  8601/40000, total loss = 2.747, Fit loss U = 6.896, Fit loss F = 4.239, KL loss = 437.988\n",
      "Epoch:  8601/40000, error_test = 0.98380, error_train = 0.99124\n",
      "Epoch:  8601/40000, error_f = 1.00000\n",
      "Epoch:  8601/40000, alpha = 1.07558\n",
      "\n",
      "Epoch:  8611/40000, total loss = 2.822, Fit loss U = 8.445, Fit loss F = 4.233, KL loss = 437.587\n",
      "Epoch:  8611/40000, alpha = 1.07515\n",
      "\n",
      "Epoch:  8621/40000, total loss = 2.752, Fit loss U = 7.097, Fit loss F = 4.228, KL loss = 437.165\n",
      "Epoch:  8621/40000, alpha = 1.07472\n",
      "\n",
      "Epoch:  8631/40000, total loss = 2.968, Fit loss U = 11.295, Fit loss F = 4.222, KL loss = 438.509\n",
      "Epoch:  8631/40000, alpha = 1.07429\n",
      "\n",
      "Epoch:  8641/40000, total loss = 3.040, Fit loss U = 12.677, Fit loss F = 4.216, KL loss = 439.124\n",
      "Epoch:  8641/40000, alpha = 1.07387\n",
      "\n",
      "Epoch:  8651/40000, total loss = 2.892, Fit loss U = 9.593, Fit loss F = 4.211, KL loss = 440.270\n",
      "Epoch:  8651/40000, alpha = 1.07344\n",
      "\n",
      "Epoch:  8661/40000, total loss = 2.919, Fit loss U = 10.028, Fit loss F = 4.205, KL loss = 441.462\n",
      "Epoch:  8661/40000, alpha = 1.07303\n",
      "\n",
      "Epoch:  8671/40000, total loss = 2.887, Fit loss U = 9.452, Fit loss F = 4.199, KL loss = 440.911\n",
      "Epoch:  8671/40000, alpha = 1.07261\n",
      "\n",
      "Epoch:  8681/40000, total loss = 2.974, Fit loss U = 11.255, Fit loss F = 4.194, KL loss = 440.226\n",
      "Epoch:  8681/40000, alpha = 1.07219\n",
      "\n",
      "Epoch:  8691/40000, total loss = 2.848, Fit loss U = 8.853, Fit loss F = 4.188, KL loss = 439.160\n",
      "Epoch:  8691/40000, alpha = 1.07178\n",
      "\n",
      "Epoch:  8701/40000, total loss = 2.774, Fit loss U = 7.454, Fit loss F = 4.183, KL loss = 438.495\n",
      "Epoch:  8701/40000, error_test = 1.01936, error_train = 1.02290\n",
      "Epoch:  8701/40000, error_f = 1.00000\n",
      "Epoch:  8701/40000, alpha = 1.07137\n",
      "\n",
      "Epoch:  8711/40000, total loss = 2.894, Fit loss U = 9.970, Fit loss F = 4.177, KL loss = 437.396\n",
      "Epoch:  8711/40000, alpha = 1.07097\n",
      "\n",
      "Epoch:  8721/40000, total loss = 2.904, Fit loss U = 10.127, Fit loss F = 4.172, KL loss = 437.833\n",
      "Epoch:  8721/40000, alpha = 1.07056\n",
      "\n",
      "Epoch:  8731/40000, total loss = 2.844, Fit loss U = 8.878, Fit loss F = 4.166, KL loss = 438.447\n",
      "Epoch:  8731/40000, alpha = 1.07016\n",
      "\n",
      "Epoch:  8741/40000, total loss = 2.835, Fit loss U = 8.691, Fit loss F = 4.161, KL loss = 438.481\n",
      "Epoch:  8741/40000, alpha = 1.06976\n",
      "\n",
      "Epoch:  8751/40000, total loss = 2.819, Fit loss U = 8.463, Fit loss F = 4.156, KL loss = 437.691\n",
      "Epoch:  8751/40000, alpha = 1.06937\n",
      "\n",
      "Epoch:  8761/40000, total loss = 2.816, Fit loss U = 8.415, Fit loss F = 4.151, KL loss = 437.527\n",
      "Epoch:  8761/40000, alpha = 1.06897\n",
      "\n",
      "Epoch:  8771/40000, total loss = 3.018, Fit loss U = 12.378, Fit loss F = 4.145, KL loss = 438.449\n",
      "Epoch:  8771/40000, alpha = 1.06858\n",
      "\n",
      "Epoch:  8781/40000, total loss = 2.863, Fit loss U = 9.130, Fit loss F = 4.140, KL loss = 439.958\n",
      "Epoch:  8781/40000, alpha = 1.06819\n",
      "\n",
      "Epoch:  8791/40000, total loss = 2.801, Fit loss U = 7.907, Fit loss F = 4.135, KL loss = 439.859\n",
      "Epoch:  8791/40000, alpha = 1.06781\n",
      "\n",
      "Epoch:  8801/40000, total loss = 2.900, Fit loss U = 9.923, Fit loss F = 4.129, KL loss = 439.375\n",
      "Epoch:  8801/40000, error_test = 1.04023, error_train = 0.97625\n",
      "Epoch:  8801/40000, error_f = 1.00000\n",
      "Epoch:  8801/40000, alpha = 1.06742\n",
      "\n",
      "Epoch:  8811/40000, total loss = 2.824, Fit loss U = 8.399, Fit loss F = 4.124, KL loss = 439.479\n",
      "Epoch:  8811/40000, alpha = 1.06704\n",
      "\n",
      "Epoch:  8821/40000, total loss = 2.919, Fit loss U = 10.433, Fit loss F = 4.119, KL loss = 438.327\n",
      "Epoch:  8821/40000, alpha = 1.06666\n",
      "\n",
      "Epoch:  8831/40000, total loss = 2.939, Fit loss U = 10.914, Fit loss F = 4.114, KL loss = 437.468\n",
      "Epoch:  8831/40000, alpha = 1.06628\n",
      "\n",
      "Epoch:  8841/40000, total loss = 2.883, Fit loss U = 9.822, Fit loss F = 4.109, KL loss = 437.313\n",
      "Epoch:  8841/40000, alpha = 1.06591\n",
      "\n",
      "Epoch:  8851/40000, total loss = 2.965, Fit loss U = 11.479, Fit loss F = 4.104, KL loss = 437.178\n",
      "Epoch:  8851/40000, alpha = 1.06553\n",
      "\n",
      "Epoch:  8861/40000, total loss = 2.860, Fit loss U = 9.300, Fit loss F = 4.099, KL loss = 438.083\n",
      "Epoch:  8861/40000, alpha = 1.06516\n",
      "\n",
      "Epoch:  8871/40000, total loss = 2.878, Fit loss U = 9.600, Fit loss F = 4.094, KL loss = 438.621\n",
      "Epoch:  8871/40000, alpha = 1.06480\n",
      "\n",
      "Epoch:  8881/40000, total loss = 2.775, Fit loss U = 7.493, Fit loss F = 4.089, KL loss = 439.213\n",
      "Epoch:  8881/40000, alpha = 1.06443\n",
      "\n",
      "Epoch:  8891/40000, total loss = 2.798, Fit loss U = 7.958, Fit loss F = 4.084, KL loss = 439.198\n",
      "Epoch:  8891/40000, alpha = 1.06407\n",
      "\n",
      "Epoch:  8901/40000, total loss = 2.928, Fit loss U = 10.544, Fit loss F = 4.080, KL loss = 439.374\n",
      "Epoch:  8901/40000, error_test = 0.99478, error_train = 0.99767\n",
      "Epoch:  8901/40000, error_f = 1.00000\n",
      "Epoch:  8901/40000, alpha = 1.06370\n",
      "\n",
      "Epoch:  8911/40000, total loss = 2.895, Fit loss U = 9.875, Fit loss F = 4.075, KL loss = 439.494\n",
      "Epoch:  8911/40000, alpha = 1.06335\n",
      "\n",
      "Epoch:  8921/40000, total loss = 2.775, Fit loss U = 7.488, Fit loss F = 4.070, KL loss = 439.365\n",
      "Epoch:  8921/40000, alpha = 1.06299\n",
      "\n",
      "Epoch:  8931/40000, total loss = 2.887, Fit loss U = 9.677, Fit loss F = 4.065, KL loss = 439.883\n",
      "Epoch:  8931/40000, alpha = 1.06263\n",
      "\n",
      "Epoch:  8941/40000, total loss = 2.790, Fit loss U = 7.771, Fit loss F = 4.060, KL loss = 439.735\n",
      "Epoch:  8941/40000, alpha = 1.06228\n",
      "\n",
      "Epoch:  8951/40000, total loss = 2.790, Fit loss U = 7.822, Fit loss F = 4.056, KL loss = 439.287\n",
      "Epoch:  8951/40000, alpha = 1.06193\n",
      "\n",
      "Epoch:  8961/40000, total loss = 2.896, Fit loss U = 9.890, Fit loss F = 4.051, KL loss = 439.785\n",
      "Epoch:  8961/40000, alpha = 1.06158\n",
      "\n",
      "Epoch:  8971/40000, total loss = 2.770, Fit loss U = 7.392, Fit loss F = 4.046, KL loss = 439.661\n",
      "Epoch:  8971/40000, alpha = 1.06124\n",
      "\n",
      "Epoch:  8981/40000, total loss = 2.688, Fit loss U = 5.844, Fit loss F = 4.041, KL loss = 438.786\n",
      "Epoch:  8981/40000, alpha = 1.06089\n",
      "\n",
      "Epoch:  8991/40000, total loss = 2.832, Fit loss U = 8.809, Fit loss F = 4.037, KL loss = 437.948\n",
      "Epoch:  8991/40000, alpha = 1.06055\n",
      "\n",
      "Epoch:  9001/40000, total loss = 2.843, Fit loss U = 8.958, Fit loss F = 4.033, KL loss = 438.687\n",
      "Epoch:  9001/40000, error_test = 0.96205, error_train = 0.98632\n",
      "Epoch:  9001/40000, error_f = 0.99999\n",
      "Epoch:  9001/40000, alpha = 1.06021\n",
      "\n",
      "Epoch:  9011/40000, total loss = 2.991, Fit loss U = 11.909, Fit loss F = 4.028, KL loss = 438.909\n",
      "Epoch:  9011/40000, alpha = 1.05987\n",
      "\n",
      "Epoch:  9021/40000, total loss = 2.864, Fit loss U = 9.271, Fit loss F = 4.023, KL loss = 439.833\n",
      "Epoch:  9021/40000, alpha = 1.05954\n",
      "\n",
      "Epoch:  9031/40000, total loss = 2.857, Fit loss U = 9.176, Fit loss F = 4.019, KL loss = 439.410\n",
      "Epoch:  9031/40000, alpha = 1.05920\n",
      "\n",
      "Epoch:  9041/40000, total loss = 2.902, Fit loss U = 10.191, Fit loss F = 4.015, KL loss = 438.373\n",
      "Epoch:  9041/40000, alpha = 1.05887\n",
      "\n",
      "Epoch:  9051/40000, total loss = 2.907, Fit loss U = 10.347, Fit loss F = 4.010, KL loss = 437.793\n",
      "Epoch:  9051/40000, alpha = 1.05854\n",
      "\n",
      "Epoch:  9061/40000, total loss = 2.814, Fit loss U = 8.522, Fit loss F = 4.006, KL loss = 437.609\n",
      "Epoch:  9061/40000, alpha = 1.05821\n",
      "\n",
      "Epoch:  9071/40000, total loss = 2.962, Fit loss U = 11.477, Fit loss F = 4.001, KL loss = 437.665\n",
      "Epoch:  9071/40000, alpha = 1.05789\n",
      "\n",
      "Epoch:  9081/40000, total loss = 2.757, Fit loss U = 7.287, Fit loss F = 3.997, KL loss = 438.560\n",
      "Epoch:  9081/40000, alpha = 1.05756\n",
      "\n",
      "Epoch:  9091/40000, total loss = 2.828, Fit loss U = 8.682, Fit loss F = 3.992, KL loss = 438.808\n",
      "Epoch:  9091/40000, alpha = 1.05724\n",
      "\n",
      "Epoch:  9101/40000, total loss = 2.846, Fit loss U = 9.063, Fit loss F = 3.988, KL loss = 438.610\n",
      "Epoch:  9101/40000, error_test = 1.03047, error_train = 0.97953\n",
      "Epoch:  9101/40000, error_f = 1.00000\n",
      "Epoch:  9101/40000, alpha = 1.05692\n",
      "\n",
      "Epoch:  9111/40000, total loss = 2.774, Fit loss U = 7.623, Fit loss F = 3.984, KL loss = 438.683\n",
      "Epoch:  9111/40000, alpha = 1.05661\n",
      "\n",
      "Epoch:  9121/40000, total loss = 2.891, Fit loss U = 9.969, Fit loss F = 3.980, KL loss = 438.634\n",
      "Epoch:  9121/40000, alpha = 1.05629\n",
      "\n",
      "Epoch:  9131/40000, total loss = 2.924, Fit loss U = 10.720, Fit loss F = 3.976, KL loss = 437.876\n",
      "Epoch:  9131/40000, alpha = 1.05598\n",
      "\n",
      "Epoch:  9141/40000, total loss = 2.910, Fit loss U = 10.463, Fit loss F = 3.971, KL loss = 437.658\n",
      "Epoch:  9141/40000, alpha = 1.05566\n",
      "\n",
      "Epoch:  9151/40000, total loss = 2.825, Fit loss U = 8.780, Fit loss F = 3.967, KL loss = 437.495\n",
      "Epoch:  9151/40000, alpha = 1.05535\n",
      "\n",
      "Epoch:  9161/40000, total loss = 2.789, Fit loss U = 8.170, Fit loss F = 3.963, KL loss = 436.527\n",
      "Epoch:  9161/40000, alpha = 1.05505\n",
      "\n",
      "Epoch:  9171/40000, total loss = 2.880, Fit loss U = 10.068, Fit loss F = 3.959, KL loss = 435.747\n",
      "Epoch:  9171/40000, alpha = 1.05474\n",
      "\n",
      "Epoch:  9181/40000, total loss = 2.837, Fit loss U = 9.163, Fit loss F = 3.955, KL loss = 436.145\n",
      "Epoch:  9181/40000, alpha = 1.05443\n",
      "\n",
      "Epoch:  9191/40000, total loss = 2.824, Fit loss U = 8.843, Fit loss F = 3.951, KL loss = 436.865\n",
      "Epoch:  9191/40000, alpha = 1.05413\n",
      "\n",
      "Epoch:  9201/40000, total loss = 2.801, Fit loss U = 8.430, Fit loss F = 3.947, KL loss = 436.341\n",
      "Epoch:  9201/40000, error_test = 0.99357, error_train = 0.99797\n",
      "Epoch:  9201/40000, error_f = 1.00000\n",
      "Epoch:  9201/40000, alpha = 1.05383\n",
      "\n",
      "Epoch:  9211/40000, total loss = 2.830, Fit loss U = 9.051, Fit loss F = 3.943, KL loss = 436.085\n",
      "Epoch:  9211/40000, alpha = 1.05353\n",
      "\n",
      "Epoch:  9221/40000, total loss = 3.039, Fit loss U = 13.256, Fit loss F = 3.939, KL loss = 435.840\n",
      "Epoch:  9221/40000, alpha = 1.05323\n",
      "\n",
      "Epoch:  9231/40000, total loss = 2.861, Fit loss U = 9.652, Fit loss F = 3.935, KL loss = 436.427\n",
      "Epoch:  9231/40000, alpha = 1.05294\n",
      "\n",
      "Epoch:  9241/40000, total loss = 2.870, Fit loss U = 9.827, Fit loss F = 3.931, KL loss = 436.501\n",
      "Epoch:  9241/40000, alpha = 1.05265\n",
      "\n",
      "Epoch:  9251/40000, total loss = 2.832, Fit loss U = 8.989, Fit loss F = 3.927, KL loss = 437.263\n",
      "Epoch:  9251/40000, alpha = 1.05235\n",
      "\n",
      "Epoch:  9261/40000, total loss = 2.730, Fit loss U = 6.936, Fit loss F = 3.923, KL loss = 437.424\n",
      "Epoch:  9261/40000, alpha = 1.05206\n",
      "\n",
      "Epoch:  9271/40000, total loss = 2.896, Fit loss U = 10.323, Fit loss F = 3.919, KL loss = 436.871\n",
      "Epoch:  9271/40000, alpha = 1.05177\n",
      "\n",
      "Epoch:  9281/40000, total loss = 2.836, Fit loss U = 9.185, Fit loss F = 3.915, KL loss = 436.281\n",
      "Epoch:  9281/40000, alpha = 1.05149\n",
      "\n",
      "Epoch:  9291/40000, total loss = 2.875, Fit loss U = 9.940, Fit loss F = 3.911, KL loss = 436.576\n",
      "Epoch:  9291/40000, alpha = 1.05120\n",
      "\n",
      "Epoch:  9301/40000, total loss = 2.895, Fit loss U = 10.278, Fit loss F = 3.907, KL loss = 437.121\n",
      "Epoch:  9301/40000, error_test = 0.99753, error_train = 0.97042\n",
      "Epoch:  9301/40000, error_f = 1.00000\n",
      "Epoch:  9301/40000, alpha = 1.05092\n",
      "\n",
      "Epoch:  9311/40000, total loss = 2.912, Fit loss U = 10.583, Fit loss F = 3.903, KL loss = 437.616\n",
      "Epoch:  9311/40000, alpha = 1.05064\n",
      "\n",
      "Epoch:  9321/40000, total loss = 2.918, Fit loss U = 10.617, Fit loss F = 3.900, KL loss = 438.426\n",
      "Epoch:  9321/40000, alpha = 1.05036\n",
      "\n",
      "Epoch:  9331/40000, total loss = 2.763, Fit loss U = 7.408, Fit loss F = 3.896, KL loss = 439.645\n",
      "Epoch:  9331/40000, alpha = 1.05008\n",
      "\n",
      "Epoch:  9341/40000, total loss = 2.924, Fit loss U = 10.578, Fit loss F = 3.892, KL loss = 440.092\n",
      "Epoch:  9341/40000, alpha = 1.04980\n",
      "\n",
      "Epoch:  9351/40000, total loss = 3.090, Fit loss U = 13.946, Fit loss F = 3.888, KL loss = 439.604\n",
      "Epoch:  9351/40000, alpha = 1.04953\n",
      "\n",
      "Epoch:  9361/40000, total loss = 2.852, Fit loss U = 9.134, Fit loss F = 3.885, KL loss = 440.284\n",
      "Epoch:  9361/40000, alpha = 1.04926\n",
      "\n",
      "Epoch:  9371/40000, total loss = 2.846, Fit loss U = 9.113, Fit loss F = 3.881, KL loss = 439.294\n",
      "Epoch:  9371/40000, alpha = 1.04899\n",
      "\n",
      "Epoch:  9381/40000, total loss = 2.708, Fit loss U = 6.443, Fit loss F = 3.878, KL loss = 438.376\n",
      "Epoch:  9381/40000, alpha = 1.04872\n",
      "\n",
      "Epoch:  9391/40000, total loss = 2.837, Fit loss U = 9.046, Fit loss F = 3.874, KL loss = 438.100\n",
      "Epoch:  9391/40000, alpha = 1.04845\n",
      "\n",
      "Epoch:  9401/40000, total loss = 2.777, Fit loss U = 7.855, Fit loss F = 3.870, KL loss = 438.216\n",
      "Epoch:  9401/40000, error_test = 1.00241, error_train = 1.01494\n",
      "Epoch:  9401/40000, error_f = 1.00001\n",
      "Epoch:  9401/40000, alpha = 1.04818\n",
      "\n",
      "Epoch:  9411/40000, total loss = 2.895, Fit loss U = 10.248, Fit loss F = 3.867, KL loss = 437.855\n",
      "Epoch:  9411/40000, alpha = 1.04792\n",
      "\n",
      "Epoch:  9421/40000, total loss = 2.778, Fit loss U = 7.985, Fit loss F = 3.863, KL loss = 437.027\n",
      "Epoch:  9421/40000, alpha = 1.04765\n",
      "\n",
      "Epoch:  9431/40000, total loss = 3.056, Fit loss U = 13.566, Fit loss F = 3.860, KL loss = 436.916\n",
      "Epoch:  9431/40000, alpha = 1.04739\n",
      "\n",
      "Epoch:  9441/40000, total loss = 2.853, Fit loss U = 9.301, Fit loss F = 3.856, KL loss = 439.030\n",
      "Epoch:  9441/40000, alpha = 1.04713\n",
      "\n",
      "Epoch:  9451/40000, total loss = 2.817, Fit loss U = 8.453, Fit loss F = 3.853, KL loss = 440.374\n",
      "Epoch:  9451/40000, alpha = 1.04687\n",
      "\n",
      "Epoch:  9461/40000, total loss = 2.805, Fit loss U = 8.222, Fit loss F = 3.849, KL loss = 440.300\n",
      "Epoch:  9461/40000, alpha = 1.04661\n",
      "\n",
      "Epoch:  9471/40000, total loss = 2.908, Fit loss U = 10.365, Fit loss F = 3.846, KL loss = 439.530\n",
      "Epoch:  9471/40000, alpha = 1.04636\n",
      "\n",
      "Epoch:  9481/40000, total loss = 2.797, Fit loss U = 8.177, Fit loss F = 3.842, KL loss = 439.289\n",
      "Epoch:  9481/40000, alpha = 1.04610\n",
      "\n",
      "Epoch:  9491/40000, total loss = 2.885, Fit loss U = 9.966, Fit loss F = 3.839, KL loss = 438.878\n",
      "Epoch:  9491/40000, alpha = 1.04585\n",
      "\n",
      "Epoch:  9501/40000, total loss = 2.831, Fit loss U = 8.924, Fit loss F = 3.836, KL loss = 438.541\n",
      "Epoch:  9501/40000, error_test = 1.00490, error_train = 0.98443\n",
      "Epoch:  9501/40000, error_f = 1.00000\n",
      "Epoch:  9501/40000, alpha = 1.04560\n",
      "\n",
      "Epoch:  9511/40000, total loss = 2.826, Fit loss U = 8.816, Fit loss F = 3.832, KL loss = 438.627\n",
      "Epoch:  9511/40000, alpha = 1.04535\n",
      "\n",
      "Epoch:  9521/40000, total loss = 2.791, Fit loss U = 8.197, Fit loss F = 3.829, KL loss = 438.037\n",
      "Epoch:  9521/40000, alpha = 1.04510\n",
      "\n",
      "Epoch:  9531/40000, total loss = 2.804, Fit loss U = 8.622, Fit loss F = 3.826, KL loss = 436.418\n",
      "Epoch:  9531/40000, alpha = 1.04486\n",
      "\n",
      "Epoch:  9541/40000, total loss = 2.871, Fit loss U = 10.001, Fit loss F = 3.822, KL loss = 436.029\n",
      "Epoch:  9541/40000, alpha = 1.04461\n",
      "\n",
      "Epoch:  9551/40000, total loss = 2.749, Fit loss U = 7.422, Fit loss F = 3.819, KL loss = 437.442\n",
      "Epoch:  9551/40000, alpha = 1.04437\n",
      "\n",
      "Epoch:  9561/40000, total loss = 2.928, Fit loss U = 10.991, Fit loss F = 3.816, KL loss = 437.557\n",
      "Epoch:  9561/40000, alpha = 1.04413\n",
      "\n",
      "Epoch:  9571/40000, total loss = 2.797, Fit loss U = 8.343, Fit loss F = 3.812, KL loss = 437.815\n",
      "Epoch:  9571/40000, alpha = 1.04388\n",
      "\n",
      "Epoch:  9581/40000, total loss = 2.843, Fit loss U = 9.297, Fit loss F = 3.809, KL loss = 437.446\n",
      "Epoch:  9581/40000, alpha = 1.04365\n",
      "\n",
      "Epoch:  9591/40000, total loss = 2.823, Fit loss U = 8.859, Fit loss F = 3.806, KL loss = 437.900\n",
      "Epoch:  9591/40000, alpha = 1.04341\n",
      "\n",
      "Epoch:  9601/40000, total loss = 2.843, Fit loss U = 9.236, Fit loss F = 3.803, KL loss = 438.236\n",
      "Epoch:  9601/40000, error_test = 1.00753, error_train = 1.02288\n",
      "Epoch:  9601/40000, error_f = 1.00000\n",
      "Epoch:  9601/40000, alpha = 1.04317\n",
      "\n",
      "Epoch:  9611/40000, total loss = 2.809, Fit loss U = 8.537, Fit loss F = 3.800, KL loss = 438.473\n",
      "Epoch:  9611/40000, alpha = 1.04294\n",
      "\n",
      "Epoch:  9621/40000, total loss = 2.815, Fit loss U = 8.596, Fit loss F = 3.797, KL loss = 439.066\n",
      "Epoch:  9621/40000, alpha = 1.04270\n",
      "\n",
      "Epoch:  9631/40000, total loss = 2.790, Fit loss U = 7.936, Fit loss F = 3.793, KL loss = 440.624\n",
      "Epoch:  9631/40000, alpha = 1.04247\n",
      "\n",
      "Epoch:  9641/40000, total loss = 2.957, Fit loss U = 11.371, Fit loss F = 3.790, KL loss = 439.835\n",
      "Epoch:  9641/40000, alpha = 1.04224\n",
      "\n",
      "Epoch:  9651/40000, total loss = 2.837, Fit loss U = 9.091, Fit loss F = 3.787, KL loss = 438.621\n",
      "Epoch:  9651/40000, alpha = 1.04201\n",
      "\n",
      "Epoch:  9661/40000, total loss = 2.798, Fit loss U = 8.295, Fit loss F = 3.784, KL loss = 438.776\n",
      "Epoch:  9661/40000, alpha = 1.04178\n",
      "\n",
      "Epoch:  9671/40000, total loss = 2.830, Fit loss U = 8.873, Fit loss F = 3.781, KL loss = 439.384\n",
      "Epoch:  9671/40000, alpha = 1.04155\n",
      "\n",
      "Epoch:  9681/40000, total loss = 2.854, Fit loss U = 9.341, Fit loss F = 3.778, KL loss = 439.559\n",
      "Epoch:  9681/40000, alpha = 1.04133\n",
      "\n",
      "Epoch:  9691/40000, total loss = 2.776, Fit loss U = 7.659, Fit loss F = 3.775, KL loss = 440.908\n",
      "Epoch:  9691/40000, alpha = 1.04110\n",
      "\n",
      "Epoch:  9701/40000, total loss = 2.840, Fit loss U = 8.996, Fit loss F = 3.772, KL loss = 440.360\n",
      "Epoch:  9701/40000, error_test = 0.99030, error_train = 1.02402\n",
      "Epoch:  9701/40000, error_f = 1.00001\n",
      "Epoch:  9701/40000, alpha = 1.04088\n",
      "\n",
      "Epoch:  9711/40000, total loss = 2.939, Fit loss U = 11.112, Fit loss F = 3.769, KL loss = 438.992\n",
      "Epoch:  9711/40000, alpha = 1.04066\n",
      "\n",
      "Epoch:  9721/40000, total loss = 2.918, Fit loss U = 10.892, Fit loss F = 3.766, KL loss = 437.004\n",
      "Epoch:  9721/40000, alpha = 1.04044\n",
      "\n",
      "Epoch:  9731/40000, total loss = 2.829, Fit loss U = 9.175, Fit loss F = 3.763, KL loss = 436.455\n",
      "Epoch:  9731/40000, alpha = 1.04022\n",
      "\n",
      "Epoch:  9741/40000, total loss = 2.857, Fit loss U = 9.640, Fit loss F = 3.760, KL loss = 437.483\n",
      "Epoch:  9741/40000, alpha = 1.04000\n",
      "\n",
      "Epoch:  9751/40000, total loss = 2.638, Fit loss U = 5.198, Fit loss F = 3.757, KL loss = 438.076\n",
      "Epoch:  9751/40000, alpha = 1.03979\n",
      "\n",
      "Epoch:  9761/40000, total loss = 2.903, Fit loss U = 10.547, Fit loss F = 3.754, KL loss = 437.592\n",
      "Epoch:  9761/40000, alpha = 1.03957\n",
      "\n",
      "Epoch:  9771/40000, total loss = 2.756, Fit loss U = 7.744, Fit loss F = 3.751, KL loss = 436.339\n",
      "Epoch:  9771/40000, alpha = 1.03936\n",
      "\n",
      "Epoch:  9781/40000, total loss = 2.901, Fit loss U = 10.758, Fit loss F = 3.748, KL loss = 435.096\n",
      "Epoch:  9781/40000, alpha = 1.03915\n",
      "\n",
      "Epoch:  9791/40000, total loss = 2.754, Fit loss U = 7.652, Fit loss F = 3.746, KL loss = 436.874\n",
      "Epoch:  9791/40000, alpha = 1.03893\n",
      "\n",
      "Epoch:  9801/40000, total loss = 3.123, Fit loss U = 14.973, Fit loss F = 3.743, KL loss = 437.359\n",
      "Epoch:  9801/40000, error_test = 1.07355, error_train = 1.00696\n",
      "Epoch:  9801/40000, error_f = 1.00000\n",
      "Epoch:  9801/40000, alpha = 1.03872\n",
      "\n",
      "Epoch:  9811/40000, total loss = 2.768, Fit loss U = 7.779, Fit loss F = 3.740, KL loss = 438.479\n",
      "Epoch:  9811/40000, alpha = 1.03852\n",
      "\n",
      "Epoch:  9821/40000, total loss = 2.797, Fit loss U = 8.373, Fit loss F = 3.737, KL loss = 438.329\n",
      "Epoch:  9821/40000, alpha = 1.03831\n",
      "\n",
      "Epoch:  9831/40000, total loss = 2.789, Fit loss U = 8.299, Fit loss F = 3.735, KL loss = 437.445\n",
      "Epoch:  9831/40000, alpha = 1.03810\n",
      "\n",
      "Epoch:  9841/40000, total loss = 2.991, Fit loss U = 12.392, Fit loss F = 3.731, KL loss = 436.998\n",
      "Epoch:  9841/40000, alpha = 1.03790\n",
      "\n",
      "Epoch:  9851/40000, total loss = 2.812, Fit loss U = 8.819, Fit loss F = 3.729, KL loss = 436.995\n",
      "Epoch:  9851/40000, alpha = 1.03769\n",
      "\n",
      "Epoch:  9861/40000, total loss = 2.780, Fit loss U = 8.244, Fit loss F = 3.726, KL loss = 436.264\n",
      "Epoch:  9861/40000, alpha = 1.03749\n",
      "\n",
      "Epoch:  9871/40000, total loss = 3.004, Fit loss U = 12.716, Fit loss F = 3.723, KL loss = 436.490\n",
      "Epoch:  9871/40000, alpha = 1.03729\n",
      "\n",
      "Epoch:  9881/40000, total loss = 2.892, Fit loss U = 10.337, Fit loss F = 3.721, KL loss = 437.903\n",
      "Epoch:  9881/40000, alpha = 1.03709\n",
      "\n",
      "Epoch:  9891/40000, total loss = 2.873, Fit loss U = 9.842, Fit loss F = 3.718, KL loss = 439.015\n",
      "Epoch:  9891/40000, alpha = 1.03689\n",
      "\n",
      "Epoch:  9901/40000, total loss = 2.761, Fit loss U = 7.494, Fit loss F = 3.715, KL loss = 440.020\n",
      "Epoch:  9901/40000, error_test = 1.04043, error_train = 1.00432\n",
      "Epoch:  9901/40000, error_f = 1.00000\n",
      "Epoch:  9901/40000, alpha = 1.03669\n",
      "\n",
      "Epoch:  9911/40000, total loss = 2.836, Fit loss U = 9.026, Fit loss F = 3.713, KL loss = 439.824\n",
      "Epoch:  9911/40000, alpha = 1.03649\n",
      "\n",
      "Epoch:  9921/40000, total loss = 3.048, Fit loss U = 13.392, Fit loss F = 3.710, KL loss = 438.549\n",
      "Epoch:  9921/40000, alpha = 1.03630\n",
      "\n",
      "Epoch:  9931/40000, total loss = 2.822, Fit loss U = 8.846, Fit loss F = 3.707, KL loss = 438.827\n",
      "Epoch:  9931/40000, alpha = 1.03610\n",
      "\n",
      "Epoch:  9941/40000, total loss = 2.710, Fit loss U = 6.681, Fit loss F = 3.704, KL loss = 438.094\n",
      "Epoch:  9941/40000, alpha = 1.03591\n",
      "\n",
      "Epoch:  9951/40000, total loss = 2.772, Fit loss U = 7.933, Fit loss F = 3.702, KL loss = 437.963\n",
      "Epoch:  9951/40000, alpha = 1.03572\n",
      "\n",
      "Epoch:  9961/40000, total loss = 2.749, Fit loss U = 7.536, Fit loss F = 3.699, KL loss = 437.451\n",
      "Epoch:  9961/40000, alpha = 1.03553\n",
      "\n",
      "Epoch:  9971/40000, total loss = 2.875, Fit loss U = 9.944, Fit loss F = 3.697, KL loss = 438.658\n",
      "Epoch:  9971/40000, alpha = 1.03534\n",
      "\n",
      "Epoch:  9981/40000, total loss = 2.838, Fit loss U = 9.185, Fit loss F = 3.694, KL loss = 438.880\n",
      "Epoch:  9981/40000, alpha = 1.03515\n",
      "\n",
      "Epoch:  9991/40000, total loss = 2.890, Fit loss U = 10.248, Fit loss F = 3.692, KL loss = 438.681\n",
      "Epoch:  9991/40000, alpha = 1.03496\n",
      "\n",
      "Epoch: 10001/40000, total loss = 2.697, Fit loss U = 6.364, Fit loss F = 3.690, KL loss = 438.950\n",
      "Epoch: 10001/40000, error_test = 1.02928, error_train = 1.04437\n",
      "Epoch: 10001/40000, error_f = 1.00000\n",
      "Epoch: 10001/40000, alpha = 1.03477\n",
      "\n",
      "Epoch: 10011/40000, total loss = 2.746, Fit loss U = 7.439, Fit loss F = 3.687, KL loss = 438.007\n",
      "Epoch: 10011/40000, alpha = 1.03459\n",
      "\n",
      "Epoch: 10021/40000, total loss = 2.951, Fit loss U = 11.615, Fit loss F = 3.685, KL loss = 437.258\n",
      "Epoch: 10021/40000, alpha = 1.03440\n",
      "\n",
      "Epoch: 10031/40000, total loss = 2.966, Fit loss U = 11.849, Fit loss F = 3.682, KL loss = 437.910\n",
      "Epoch: 10031/40000, alpha = 1.03422\n",
      "\n",
      "Epoch: 10041/40000, total loss = 2.765, Fit loss U = 7.815, Fit loss F = 3.679, KL loss = 437.956\n",
      "Epoch: 10041/40000, alpha = 1.03404\n",
      "\n",
      "Epoch: 10051/40000, total loss = 2.803, Fit loss U = 8.489, Fit loss F = 3.677, KL loss = 438.876\n",
      "Epoch: 10051/40000, alpha = 1.03385\n",
      "\n",
      "Epoch: 10061/40000, total loss = 2.767, Fit loss U = 7.747, Fit loss F = 3.674, KL loss = 439.117\n",
      "Epoch: 10061/40000, alpha = 1.03367\n",
      "\n",
      "Epoch: 10071/40000, total loss = 2.723, Fit loss U = 6.936, Fit loss F = 3.672, KL loss = 438.434\n",
      "Epoch: 10071/40000, alpha = 1.03350\n",
      "\n",
      "Epoch: 10081/40000, total loss = 2.806, Fit loss U = 8.580, Fit loss F = 3.670, KL loss = 438.645\n",
      "Epoch: 10081/40000, alpha = 1.03332\n",
      "\n",
      "Epoch: 10091/40000, total loss = 2.799, Fit loss U = 8.527, Fit loss F = 3.667, KL loss = 437.794\n",
      "Epoch: 10091/40000, alpha = 1.03314\n",
      "\n",
      "Epoch: 10101/40000, total loss = 2.688, Fit loss U = 6.435, Fit loss F = 3.665, KL loss = 436.662\n",
      "Epoch: 10101/40000, error_test = 1.02111, error_train = 1.00562\n",
      "Epoch: 10101/40000, error_f = 1.00000\n",
      "Epoch: 10101/40000, alpha = 1.03296\n",
      "\n",
      "Epoch: 10111/40000, total loss = 2.748, Fit loss U = 7.708, Fit loss F = 3.662, KL loss = 435.875\n",
      "Epoch: 10111/40000, alpha = 1.03279\n",
      "\n",
      "Epoch: 10121/40000, total loss = 2.719, Fit loss U = 7.082, Fit loss F = 3.660, KL loss = 436.425\n",
      "Epoch: 10121/40000, alpha = 1.03261\n",
      "\n",
      "Epoch: 10131/40000, total loss = 2.977, Fit loss U = 12.214, Fit loss F = 3.658, KL loss = 436.758\n",
      "Epoch: 10131/40000, alpha = 1.03244\n",
      "\n",
      "Epoch: 10141/40000, total loss = 2.677, Fit loss U = 6.063, Fit loss F = 3.655, KL loss = 438.315\n",
      "Epoch: 10141/40000, alpha = 1.03227\n",
      "\n",
      "Epoch: 10151/40000, total loss = 2.954, Fit loss U = 11.605, Fit loss F = 3.653, KL loss = 438.306\n",
      "Epoch: 10151/40000, alpha = 1.03210\n",
      "\n",
      "Epoch: 10161/40000, total loss = 2.743, Fit loss U = 7.412, Fit loss F = 3.651, KL loss = 437.903\n",
      "Epoch: 10161/40000, alpha = 1.03193\n",
      "\n",
      "Epoch: 10171/40000, total loss = 2.804, Fit loss U = 8.741, Fit loss F = 3.648, KL loss = 436.870\n",
      "Epoch: 10171/40000, alpha = 1.03176\n",
      "\n",
      "Epoch: 10181/40000, total loss = 2.743, Fit loss U = 7.509, Fit loss F = 3.646, KL loss = 436.986\n",
      "Epoch: 10181/40000, alpha = 1.03159\n",
      "\n",
      "Epoch: 10191/40000, total loss = 2.795, Fit loss U = 8.517, Fit loss F = 3.644, KL loss = 437.439\n",
      "Epoch: 10191/40000, alpha = 1.03142\n",
      "\n",
      "Epoch: 10201/40000, total loss = 2.829, Fit loss U = 9.250, Fit loss F = 3.642, KL loss = 436.791\n",
      "Epoch: 10201/40000, error_test = 1.02535, error_train = 1.02816\n",
      "Epoch: 10201/40000, error_f = 1.00000\n",
      "Epoch: 10201/40000, alpha = 1.03126\n",
      "\n",
      "Epoch: 10211/40000, total loss = 2.754, Fit loss U = 7.756, Fit loss F = 3.639, KL loss = 436.867\n",
      "Epoch: 10211/40000, alpha = 1.03109\n",
      "\n",
      "Epoch: 10221/40000, total loss = 2.777, Fit loss U = 8.208, Fit loss F = 3.637, KL loss = 436.914\n",
      "Epoch: 10221/40000, alpha = 1.03093\n",
      "\n",
      "Epoch: 10231/40000, total loss = 2.754, Fit loss U = 7.534, Fit loss F = 3.635, KL loss = 439.159\n",
      "Epoch: 10231/40000, alpha = 1.03076\n",
      "\n",
      "Epoch: 10241/40000, total loss = 2.771, Fit loss U = 7.886, Fit loss F = 3.633, KL loss = 439.018\n",
      "Epoch: 10241/40000, alpha = 1.03060\n",
      "\n",
      "Epoch: 10251/40000, total loss = 2.717, Fit loss U = 6.867, Fit loss F = 3.631, KL loss = 438.430\n",
      "Epoch: 10251/40000, alpha = 1.03044\n",
      "\n",
      "Epoch: 10261/40000, total loss = 2.795, Fit loss U = 8.525, Fit loss F = 3.629, KL loss = 437.529\n",
      "Epoch: 10261/40000, alpha = 1.03028\n",
      "\n",
      "Epoch: 10271/40000, total loss = 3.039, Fit loss U = 13.488, Fit loss F = 3.627, KL loss = 436.687\n",
      "Epoch: 10271/40000, alpha = 1.03012\n",
      "\n",
      "Epoch: 10281/40000, total loss = 2.844, Fit loss U = 9.477, Fit loss F = 3.624, KL loss = 437.821\n",
      "Epoch: 10281/40000, alpha = 1.02996\n",
      "\n",
      "Epoch: 10291/40000, total loss = 2.886, Fit loss U = 10.182, Fit loss F = 3.622, KL loss = 439.065\n",
      "Epoch: 10291/40000, alpha = 1.02980\n",
      "\n",
      "Epoch: 10301/40000, total loss = 2.765, Fit loss U = 7.721, Fit loss F = 3.620, KL loss = 439.663\n",
      "Epoch: 10301/40000, error_test = 0.97786, error_train = 0.99563\n",
      "Epoch: 10301/40000, error_f = 1.00001\n",
      "Epoch: 10301/40000, alpha = 1.02965\n",
      "\n",
      "Epoch: 10311/40000, total loss = 2.777, Fit loss U = 8.051, Fit loss F = 3.618, KL loss = 438.786\n",
      "Epoch: 10311/40000, alpha = 1.02949\n",
      "\n",
      "Epoch: 10321/40000, total loss = 2.803, Fit loss U = 8.468, Fit loss F = 3.616, KL loss = 439.813\n",
      "Epoch: 10321/40000, alpha = 1.02934\n",
      "\n",
      "Epoch: 10331/40000, total loss = 2.946, Fit loss U = 11.292, Fit loss F = 3.614, KL loss = 440.213\n",
      "Epoch: 10331/40000, alpha = 1.02918\n",
      "\n",
      "Epoch: 10341/40000, total loss = 2.820, Fit loss U = 8.805, Fit loss F = 3.612, KL loss = 439.809\n",
      "Epoch: 10341/40000, alpha = 1.02903\n",
      "\n",
      "Epoch: 10351/40000, total loss = 2.774, Fit loss U = 7.929, Fit loss F = 3.610, KL loss = 439.470\n",
      "Epoch: 10351/40000, alpha = 1.02888\n",
      "\n",
      "Epoch: 10361/40000, total loss = 2.989, Fit loss U = 12.367, Fit loss F = 3.608, KL loss = 438.032\n",
      "Epoch: 10361/40000, alpha = 1.02872\n",
      "\n",
      "Epoch: 10371/40000, total loss = 2.981, Fit loss U = 12.209, Fit loss F = 3.605, KL loss = 438.047\n",
      "Epoch: 10371/40000, alpha = 1.02857\n",
      "\n",
      "Epoch: 10381/40000, total loss = 2.895, Fit loss U = 10.368, Fit loss F = 3.603, KL loss = 439.306\n",
      "Epoch: 10381/40000, alpha = 1.02842\n",
      "\n",
      "Epoch: 10391/40000, total loss = 2.791, Fit loss U = 8.231, Fit loss F = 3.601, KL loss = 439.953\n",
      "Epoch: 10391/40000, alpha = 1.02827\n",
      "\n",
      "Epoch: 10401/40000, total loss = 2.866, Fit loss U = 9.694, Fit loss F = 3.600, KL loss = 440.349\n",
      "Epoch: 10401/40000, error_test = 1.00183, error_train = 0.97614\n",
      "Epoch: 10401/40000, error_f = 1.00001\n",
      "Epoch: 10401/40000, alpha = 1.02813\n",
      "\n",
      "Epoch: 10411/40000, total loss = 2.958, Fit loss U = 11.508, Fit loss F = 3.597, KL loss = 440.595\n",
      "Epoch: 10411/40000, alpha = 1.02798\n",
      "\n",
      "Epoch: 10421/40000, total loss = 2.795, Fit loss U = 8.288, Fit loss F = 3.595, KL loss = 440.116\n",
      "Epoch: 10421/40000, alpha = 1.02783\n",
      "\n",
      "Epoch: 10431/40000, total loss = 2.763, Fit loss U = 7.730, Fit loss F = 3.593, KL loss = 439.384\n",
      "Epoch: 10431/40000, alpha = 1.02769\n",
      "\n",
      "Epoch: 10441/40000, total loss = 2.902, Fit loss U = 10.562, Fit loss F = 3.591, KL loss = 438.783\n",
      "Epoch: 10441/40000, alpha = 1.02754\n",
      "\n",
      "Epoch: 10451/40000, total loss = 2.882, Fit loss U = 10.269, Fit loss F = 3.590, KL loss = 437.745\n",
      "Epoch: 10451/40000, alpha = 1.02740\n",
      "\n",
      "Epoch: 10461/40000, total loss = 2.767, Fit loss U = 8.053, Fit loss F = 3.588, KL loss = 436.915\n",
      "Epoch: 10461/40000, alpha = 1.02726\n",
      "\n",
      "Epoch: 10471/40000, total loss = 2.797, Fit loss U = 8.732, Fit loss F = 3.586, KL loss = 436.174\n",
      "Epoch: 10471/40000, alpha = 1.02711\n",
      "\n",
      "Epoch: 10481/40000, total loss = 2.793, Fit loss U = 8.766, Fit loss F = 3.584, KL loss = 435.184\n",
      "Epoch: 10481/40000, alpha = 1.02697\n",
      "\n",
      "Epoch: 10491/40000, total loss = 2.790, Fit loss U = 8.687, Fit loss F = 3.582, KL loss = 435.299\n",
      "Epoch: 10491/40000, alpha = 1.02683\n",
      "\n",
      "Epoch: 10501/40000, total loss = 2.729, Fit loss U = 7.428, Fit loss F = 3.580, KL loss = 435.633\n",
      "Epoch: 10501/40000, error_test = 1.03376, error_train = 0.97080\n",
      "Epoch: 10501/40000, error_f = 1.00000\n",
      "Epoch: 10501/40000, alpha = 1.02669\n",
      "\n",
      "Epoch: 10511/40000, total loss = 3.058, Fit loss U = 13.999, Fit loss F = 3.578, KL loss = 435.758\n",
      "Epoch: 10511/40000, alpha = 1.02655\n",
      "\n",
      "Epoch: 10521/40000, total loss = 2.824, Fit loss U = 9.275, Fit loss F = 3.576, KL loss = 436.220\n",
      "Epoch: 10521/40000, alpha = 1.02641\n",
      "\n",
      "Epoch: 10531/40000, total loss = 2.802, Fit loss U = 8.903, Fit loss F = 3.574, KL loss = 435.584\n",
      "Epoch: 10531/40000, alpha = 1.02628\n",
      "\n",
      "Epoch: 10541/40000, total loss = 2.765, Fit loss U = 8.173, Fit loss F = 3.573, KL loss = 435.479\n",
      "Epoch: 10541/40000, alpha = 1.02614\n",
      "\n",
      "Epoch: 10551/40000, total loss = 2.796, Fit loss U = 8.657, Fit loss F = 3.571, KL loss = 436.869\n",
      "Epoch: 10551/40000, alpha = 1.02600\n",
      "\n",
      "Epoch: 10561/40000, total loss = 2.879, Fit loss U = 10.281, Fit loss F = 3.569, KL loss = 437.326\n",
      "Epoch: 10561/40000, alpha = 1.02587\n",
      "\n",
      "Epoch: 10571/40000, total loss = 2.803, Fit loss U = 8.734, Fit loss F = 3.567, KL loss = 437.675\n",
      "Epoch: 10571/40000, alpha = 1.02573\n",
      "\n",
      "Epoch: 10581/40000, total loss = 2.811, Fit loss U = 9.029, Fit loss F = 3.565, KL loss = 436.323\n",
      "Epoch: 10581/40000, alpha = 1.02560\n",
      "\n",
      "Epoch: 10591/40000, total loss = 2.797, Fit loss U = 8.819, Fit loss F = 3.563, KL loss = 435.655\n",
      "Epoch: 10591/40000, alpha = 1.02547\n",
      "\n",
      "Epoch: 10601/40000, total loss = 2.861, Fit loss U = 10.001, Fit loss F = 3.562, KL loss = 436.535\n",
      "Epoch: 10601/40000, error_test = 0.99792, error_train = 1.02077\n",
      "Epoch: 10601/40000, error_f = 1.00000\n",
      "Epoch: 10601/40000, alpha = 1.02534\n",
      "\n",
      "Epoch: 10611/40000, total loss = 2.785, Fit loss U = 8.369, Fit loss F = 3.560, KL loss = 437.632\n",
      "Epoch: 10611/40000, alpha = 1.02520\n",
      "\n",
      "Epoch: 10621/40000, total loss = 2.911, Fit loss U = 10.972, Fit loss F = 3.558, KL loss = 436.998\n",
      "Epoch: 10621/40000, alpha = 1.02507\n",
      "\n",
      "Epoch: 10631/40000, total loss = 2.824, Fit loss U = 9.276, Fit loss F = 3.556, KL loss = 436.515\n",
      "Epoch: 10631/40000, alpha = 1.02494\n",
      "\n",
      "Epoch: 10641/40000, total loss = 2.712, Fit loss U = 7.041, Fit loss F = 3.555, KL loss = 436.438\n",
      "Epoch: 10641/40000, alpha = 1.02481\n",
      "\n",
      "Epoch: 10651/40000, total loss = 2.976, Fit loss U = 12.332, Fit loss F = 3.553, KL loss = 436.422\n",
      "Epoch: 10651/40000, alpha = 1.02469\n",
      "\n",
      "Epoch: 10661/40000, total loss = 2.726, Fit loss U = 7.244, Fit loss F = 3.551, KL loss = 437.329\n",
      "Epoch: 10661/40000, alpha = 1.02456\n",
      "\n",
      "Epoch: 10671/40000, total loss = 2.744, Fit loss U = 7.684, Fit loss F = 3.549, KL loss = 436.544\n",
      "Epoch: 10671/40000, alpha = 1.02443\n",
      "\n",
      "Epoch: 10681/40000, total loss = 2.771, Fit loss U = 8.163, Fit loss F = 3.548, KL loss = 437.158\n",
      "Epoch: 10681/40000, alpha = 1.02431\n",
      "\n",
      "Epoch: 10691/40000, total loss = 2.851, Fit loss U = 9.663, Fit loss F = 3.546, KL loss = 438.183\n",
      "Epoch: 10691/40000, alpha = 1.02418\n",
      "\n",
      "Epoch: 10701/40000, total loss = 2.753, Fit loss U = 7.642, Fit loss F = 3.545, KL loss = 438.814\n",
      "Epoch: 10701/40000, error_test = 1.01229, error_train = 1.03128\n",
      "Epoch: 10701/40000, error_f = 1.00001\n",
      "Epoch: 10701/40000, alpha = 1.02406\n",
      "\n",
      "Epoch: 10711/40000, total loss = 2.803, Fit loss U = 8.650, Fit loss F = 3.543, KL loss = 438.603\n",
      "Epoch: 10711/40000, alpha = 1.02393\n",
      "\n",
      "Epoch: 10721/40000, total loss = 2.822, Fit loss U = 9.070, Fit loss F = 3.541, KL loss = 438.293\n",
      "Epoch: 10721/40000, alpha = 1.02381\n",
      "\n",
      "Epoch: 10731/40000, total loss = 2.736, Fit loss U = 7.430, Fit loss F = 3.539, KL loss = 437.436\n",
      "Epoch: 10731/40000, alpha = 1.02369\n",
      "\n",
      "Epoch: 10741/40000, total loss = 2.654, Fit loss U = 5.944, Fit loss F = 3.538, KL loss = 436.046\n",
      "Epoch: 10741/40000, alpha = 1.02356\n",
      "\n",
      "Epoch: 10751/40000, total loss = 2.856, Fit loss U = 10.016, Fit loss F = 3.536, KL loss = 435.622\n",
      "Epoch: 10751/40000, alpha = 1.02344\n",
      "\n",
      "Epoch: 10761/40000, total loss = 2.664, Fit loss U = 6.215, Fit loss F = 3.534, KL loss = 435.245\n",
      "Epoch: 10761/40000, alpha = 1.02332\n",
      "\n",
      "Epoch: 10771/40000, total loss = 2.683, Fit loss U = 6.527, Fit loss F = 3.533, KL loss = 435.951\n",
      "Epoch: 10771/40000, alpha = 1.02320\n",
      "\n",
      "Epoch: 10781/40000, total loss = 2.791, Fit loss U = 8.679, Fit loss F = 3.531, KL loss = 436.166\n",
      "Epoch: 10781/40000, alpha = 1.02308\n",
      "\n",
      "Epoch: 10791/40000, total loss = 2.875, Fit loss U = 10.372, Fit loss F = 3.529, KL loss = 436.018\n",
      "Epoch: 10791/40000, alpha = 1.02296\n",
      "\n",
      "Epoch: 10801/40000, total loss = 2.723, Fit loss U = 7.344, Fit loss F = 3.528, KL loss = 435.927\n",
      "Epoch: 10801/40000, error_test = 1.03964, error_train = 0.97039\n",
      "Epoch: 10801/40000, error_f = 1.00000\n",
      "Epoch: 10801/40000, alpha = 1.02285\n",
      "\n",
      "Epoch: 10811/40000, total loss = 2.731, Fit loss U = 7.600, Fit loss F = 3.526, KL loss = 435.005\n",
      "Epoch: 10811/40000, alpha = 1.02273\n",
      "\n",
      "Epoch: 10821/40000, total loss = 3.053, Fit loss U = 13.910, Fit loss F = 3.525, KL loss = 436.176\n",
      "Epoch: 10821/40000, alpha = 1.02261\n",
      "\n",
      "Epoch: 10831/40000, total loss = 2.773, Fit loss U = 8.122, Fit loss F = 3.523, KL loss = 438.240\n",
      "Epoch: 10831/40000, alpha = 1.02250\n",
      "\n",
      "Epoch: 10841/40000, total loss = 2.903, Fit loss U = 10.709, Fit loss F = 3.522, KL loss = 438.370\n",
      "Epoch: 10841/40000, alpha = 1.02238\n",
      "\n",
      "Epoch: 10851/40000, total loss = 2.733, Fit loss U = 7.240, Fit loss F = 3.520, KL loss = 439.066\n",
      "Epoch: 10851/40000, alpha = 1.02227\n",
      "\n",
      "Epoch: 10861/40000, total loss = 2.834, Fit loss U = 9.229, Fit loss F = 3.519, KL loss = 439.269\n",
      "Epoch: 10861/40000, alpha = 1.02215\n",
      "\n",
      "Epoch: 10871/40000, total loss = 2.724, Fit loss U = 7.068, Fit loss F = 3.517, KL loss = 438.964\n",
      "Epoch: 10871/40000, alpha = 1.02204\n",
      "\n",
      "Epoch: 10881/40000, total loss = 2.706, Fit loss U = 6.758, Fit loss F = 3.515, KL loss = 438.507\n",
      "Epoch: 10881/40000, alpha = 1.02193\n",
      "\n",
      "Epoch: 10891/40000, total loss = 2.757, Fit loss U = 7.837, Fit loss F = 3.514, KL loss = 437.946\n",
      "Epoch: 10891/40000, alpha = 1.02181\n",
      "\n",
      "Epoch: 10901/40000, total loss = 2.954, Fit loss U = 11.816, Fit loss F = 3.512, KL loss = 437.448\n",
      "Epoch: 10901/40000, error_test = 1.00882, error_train = 1.01696\n",
      "Epoch: 10901/40000, error_f = 1.00000\n",
      "Epoch: 10901/40000, alpha = 1.02170\n",
      "\n",
      "Epoch: 10911/40000, total loss = 2.808, Fit loss U = 8.855, Fit loss F = 3.511, KL loss = 437.953\n",
      "Epoch: 10911/40000, alpha = 1.02159\n",
      "\n",
      "Epoch: 10921/40000, total loss = 2.757, Fit loss U = 7.878, Fit loss F = 3.510, KL loss = 437.619\n",
      "Epoch: 10921/40000, alpha = 1.02148\n",
      "\n",
      "Epoch: 10931/40000, total loss = 2.719, Fit loss U = 7.185, Fit loss F = 3.508, KL loss = 436.781\n",
      "Epoch: 10931/40000, alpha = 1.02137\n",
      "\n",
      "Epoch: 10941/40000, total loss = 2.834, Fit loss U = 9.464, Fit loss F = 3.507, KL loss = 437.173\n",
      "Epoch: 10941/40000, alpha = 1.02126\n",
      "\n",
      "Epoch: 10951/40000, total loss = 2.858, Fit loss U = 9.976, Fit loss F = 3.505, KL loss = 436.823\n",
      "Epoch: 10951/40000, alpha = 1.02115\n",
      "\n",
      "Epoch: 10961/40000, total loss = 2.947, Fit loss U = 11.754, Fit loss F = 3.504, KL loss = 436.842\n",
      "Epoch: 10961/40000, alpha = 1.02105\n",
      "\n",
      "Epoch: 10971/40000, total loss = 2.812, Fit loss U = 9.042, Fit loss F = 3.502, KL loss = 436.904\n",
      "Epoch: 10971/40000, alpha = 1.02094\n",
      "\n",
      "Epoch: 10981/40000, total loss = 2.972, Fit loss U = 12.290, Fit loss F = 3.501, KL loss = 436.529\n",
      "Epoch: 10981/40000, alpha = 1.02083\n",
      "\n",
      "Epoch: 10991/40000, total loss = 2.875, Fit loss U = 10.223, Fit loss F = 3.499, KL loss = 437.771\n",
      "Epoch: 10991/40000, alpha = 1.02073\n",
      "\n",
      "Epoch: 11001/40000, total loss = 2.842, Fit loss U = 9.575, Fit loss F = 3.498, KL loss = 437.740\n",
      "Epoch: 11001/40000, error_test = 1.02400, error_train = 0.99905\n",
      "Epoch: 11001/40000, error_f = 1.00000\n",
      "Epoch: 11001/40000, alpha = 1.02062\n",
      "\n",
      "Epoch: 11011/40000, total loss = 2.765, Fit loss U = 8.035, Fit loss F = 3.496, KL loss = 437.675\n",
      "Epoch: 11011/40000, alpha = 1.02052\n",
      "\n",
      "Epoch: 11021/40000, total loss = 2.772, Fit loss U = 8.234, Fit loss F = 3.495, KL loss = 437.077\n",
      "Epoch: 11021/40000, alpha = 1.02041\n",
      "\n",
      "Epoch: 11031/40000, total loss = 2.850, Fit loss U = 9.728, Fit loss F = 3.494, KL loss = 437.852\n",
      "Epoch: 11031/40000, alpha = 1.02031\n",
      "\n",
      "Epoch: 11041/40000, total loss = 2.701, Fit loss U = 6.780, Fit loss F = 3.492, KL loss = 437.461\n",
      "Epoch: 11041/40000, alpha = 1.02021\n",
      "\n",
      "Epoch: 11051/40000, total loss = 2.792, Fit loss U = 8.715, Fit loss F = 3.491, KL loss = 436.403\n",
      "Epoch: 11051/40000, alpha = 1.02010\n",
      "\n",
      "Epoch: 11061/40000, total loss = 2.914, Fit loss U = 11.138, Fit loss F = 3.490, KL loss = 436.522\n",
      "Epoch: 11061/40000, alpha = 1.02000\n",
      "\n",
      "Epoch: 11071/40000, total loss = 3.093, Fit loss U = 14.675, Fit loss F = 3.488, KL loss = 436.935\n",
      "Epoch: 11071/40000, alpha = 1.01990\n",
      "\n",
      "Epoch: 11081/40000, total loss = 2.753, Fit loss U = 7.762, Fit loss F = 3.487, KL loss = 438.104\n",
      "Epoch: 11081/40000, alpha = 1.01980\n",
      "\n",
      "Epoch: 11091/40000, total loss = 2.775, Fit loss U = 8.247, Fit loss F = 3.485, KL loss = 437.714\n",
      "Epoch: 11091/40000, alpha = 1.01970\n",
      "\n",
      "Epoch: 11101/40000, total loss = 2.880, Fit loss U = 10.266, Fit loss F = 3.484, KL loss = 438.408\n",
      "Epoch: 11101/40000, error_test = 0.99425, error_train = 1.02796\n",
      "Epoch: 11101/40000, error_f = 1.00001\n",
      "Epoch: 11101/40000, alpha = 1.01960\n",
      "\n",
      "Epoch: 11111/40000, total loss = 2.937, Fit loss U = 11.369, Fit loss F = 3.483, KL loss = 438.957\n",
      "Epoch: 11111/40000, alpha = 1.01950\n",
      "\n",
      "Epoch: 11121/40000, total loss = 2.835, Fit loss U = 9.334, Fit loss F = 3.481, KL loss = 438.853\n",
      "Epoch: 11121/40000, alpha = 1.01940\n",
      "\n",
      "Epoch: 11131/40000, total loss = 2.926, Fit loss U = 11.150, Fit loss F = 3.480, KL loss = 438.890\n",
      "Epoch: 11131/40000, alpha = 1.01930\n",
      "\n",
      "Epoch: 11141/40000, total loss = 2.853, Fit loss U = 9.676, Fit loss F = 3.479, KL loss = 439.106\n",
      "Epoch: 11141/40000, alpha = 1.01921\n",
      "\n",
      "Epoch: 11151/40000, total loss = 2.830, Fit loss U = 9.075, Fit loss F = 3.477, KL loss = 440.404\n",
      "Epoch: 11151/40000, alpha = 1.01911\n",
      "\n",
      "Epoch: 11161/40000, total loss = 2.725, Fit loss U = 6.926, Fit loss F = 3.476, KL loss = 440.978\n",
      "Epoch: 11161/40000, alpha = 1.01901\n",
      "\n",
      "Epoch: 11171/40000, total loss = 2.837, Fit loss U = 9.403, Fit loss F = 3.475, KL loss = 438.684\n",
      "Epoch: 11171/40000, alpha = 1.01892\n",
      "\n",
      "Epoch: 11181/40000, total loss = 2.832, Fit loss U = 9.432, Fit loss F = 3.473, KL loss = 437.263\n",
      "Epoch: 11181/40000, alpha = 1.01882\n",
      "\n",
      "Epoch: 11191/40000, total loss = 2.866, Fit loss U = 10.092, Fit loss F = 3.472, KL loss = 437.616\n",
      "Epoch: 11191/40000, alpha = 1.01873\n",
      "\n",
      "Epoch: 11201/40000, total loss = 2.958, Fit loss U = 11.861, Fit loss F = 3.471, KL loss = 438.198\n",
      "Epoch: 11201/40000, error_test = 1.02652, error_train = 1.03234\n",
      "Epoch: 11201/40000, error_f = 1.00001\n",
      "Epoch: 11201/40000, alpha = 1.01863\n",
      "\n",
      "Epoch: 11211/40000, total loss = 2.779, Fit loss U = 8.146, Fit loss F = 3.470, KL loss = 439.603\n",
      "Epoch: 11211/40000, alpha = 1.01854\n",
      "\n",
      "Epoch: 11221/40000, total loss = 2.826, Fit loss U = 9.087, Fit loss F = 3.468, KL loss = 439.664\n",
      "Epoch: 11221/40000, alpha = 1.01844\n",
      "\n",
      "Epoch: 11231/40000, total loss = 2.796, Fit loss U = 8.530, Fit loss F = 3.467, KL loss = 439.138\n",
      "Epoch: 11231/40000, alpha = 1.01835\n",
      "\n",
      "Epoch: 11241/40000, total loss = 2.835, Fit loss U = 9.442, Fit loss F = 3.466, KL loss = 437.984\n",
      "Epoch: 11241/40000, alpha = 1.01826\n",
      "\n",
      "Epoch: 11251/40000, total loss = 2.856, Fit loss U = 10.007, Fit loss F = 3.464, KL loss = 436.475\n",
      "Epoch: 11251/40000, alpha = 1.01817\n",
      "\n",
      "Epoch: 11261/40000, total loss = 2.765, Fit loss U = 8.152, Fit loss F = 3.463, KL loss = 436.917\n",
      "Epoch: 11261/40000, alpha = 1.01808\n",
      "\n",
      "Epoch: 11271/40000, total loss = 2.747, Fit loss U = 7.837, Fit loss F = 3.462, KL loss = 436.314\n",
      "Epoch: 11271/40000, alpha = 1.01799\n",
      "\n",
      "Epoch: 11281/40000, total loss = 2.763, Fit loss U = 8.145, Fit loss F = 3.461, KL loss = 436.605\n",
      "Epoch: 11281/40000, alpha = 1.01790\n",
      "\n",
      "Epoch: 11291/40000, total loss = 2.731, Fit loss U = 7.441, Fit loss F = 3.460, KL loss = 437.287\n",
      "Epoch: 11291/40000, alpha = 1.01781\n",
      "\n",
      "Epoch: 11301/40000, total loss = 2.796, Fit loss U = 8.735, Fit loss F = 3.459, KL loss = 437.273\n",
      "Epoch: 11301/40000, error_test = 1.00307, error_train = 1.03442\n",
      "Epoch: 11301/40000, error_f = 1.00000\n",
      "Epoch: 11301/40000, alpha = 1.01772\n",
      "\n",
      "Epoch: 11311/40000, total loss = 2.862, Fit loss U = 10.019, Fit loss F = 3.457, KL loss = 437.545\n",
      "Epoch: 11311/40000, alpha = 1.01763\n",
      "\n",
      "Epoch: 11321/40000, total loss = 2.814, Fit loss U = 9.078, Fit loss F = 3.456, KL loss = 437.409\n",
      "Epoch: 11321/40000, alpha = 1.01754\n",
      "\n",
      "Epoch: 11331/40000, total loss = 2.874, Fit loss U = 10.321, Fit loss F = 3.455, KL loss = 436.984\n",
      "Epoch: 11331/40000, alpha = 1.01745\n",
      "\n",
      "Epoch: 11341/40000, total loss = 2.800, Fit loss U = 8.672, Fit loss F = 3.454, KL loss = 438.761\n",
      "Epoch: 11341/40000, alpha = 1.01736\n",
      "\n",
      "Epoch: 11351/40000, total loss = 2.827, Fit loss U = 9.122, Fit loss F = 3.453, KL loss = 439.575\n",
      "Epoch: 11351/40000, alpha = 1.01728\n",
      "\n",
      "Epoch: 11361/40000, total loss = 2.754, Fit loss U = 7.586, Fit loss F = 3.451, KL loss = 440.421\n",
      "Epoch: 11361/40000, alpha = 1.01719\n",
      "\n",
      "Epoch: 11371/40000, total loss = 2.730, Fit loss U = 7.229, Fit loss F = 3.450, KL loss = 439.302\n",
      "Epoch: 11371/40000, alpha = 1.01711\n",
      "\n",
      "Epoch: 11381/40000, total loss = 2.841, Fit loss U = 9.611, Fit loss F = 3.449, KL loss = 437.655\n",
      "Epoch: 11381/40000, alpha = 1.01702\n",
      "\n",
      "Epoch: 11391/40000, total loss = 2.720, Fit loss U = 7.250, Fit loss F = 3.448, KL loss = 436.960\n",
      "Epoch: 11391/40000, alpha = 1.01694\n",
      "\n",
      "Epoch: 11401/40000, total loss = 2.738, Fit loss U = 7.548, Fit loss F = 3.447, KL loss = 437.687\n",
      "Epoch: 11401/40000, error_test = 1.00057, error_train = 0.97284\n",
      "Epoch: 11401/40000, error_f = 1.00000\n",
      "Epoch: 11401/40000, alpha = 1.01685\n",
      "\n",
      "Epoch: 11411/40000, total loss = 2.840, Fit loss U = 9.396, Fit loss F = 3.446, KL loss = 439.678\n",
      "Epoch: 11411/40000, alpha = 1.01677\n",
      "\n",
      "Epoch: 11421/40000, total loss = 2.953, Fit loss U = 11.538, Fit loss F = 3.445, KL loss = 440.838\n",
      "Epoch: 11421/40000, alpha = 1.01668\n",
      "\n",
      "Epoch: 11431/40000, total loss = 2.745, Fit loss U = 7.374, Fit loss F = 3.444, KL loss = 440.915\n",
      "Epoch: 11431/40000, alpha = 1.01660\n",
      "\n",
      "Epoch: 11441/40000, total loss = 2.729, Fit loss U = 7.110, Fit loss F = 3.442, KL loss = 440.186\n",
      "Epoch: 11441/40000, alpha = 1.01652\n",
      "\n",
      "Epoch: 11451/40000, total loss = 2.860, Fit loss U = 9.924, Fit loss F = 3.441, KL loss = 438.424\n",
      "Epoch: 11451/40000, alpha = 1.01644\n",
      "\n",
      "Epoch: 11461/40000, total loss = 2.765, Fit loss U = 8.070, Fit loss F = 3.440, KL loss = 437.955\n",
      "Epoch: 11461/40000, alpha = 1.01635\n",
      "\n",
      "Epoch: 11471/40000, total loss = 2.741, Fit loss U = 7.550, Fit loss F = 3.439, KL loss = 438.269\n",
      "Epoch: 11471/40000, alpha = 1.01627\n",
      "\n",
      "Epoch: 11481/40000, total loss = 2.823, Fit loss U = 9.274, Fit loss F = 3.438, KL loss = 437.560\n",
      "Epoch: 11481/40000, alpha = 1.01619\n",
      "\n",
      "Epoch: 11491/40000, total loss = 2.755, Fit loss U = 7.868, Fit loss F = 3.437, KL loss = 437.865\n",
      "Epoch: 11491/40000, alpha = 1.01611\n",
      "\n",
      "Epoch: 11501/40000, total loss = 2.925, Fit loss U = 11.345, Fit loss F = 3.436, KL loss = 437.124\n",
      "Epoch: 11501/40000, error_test = 1.01271, error_train = 0.97826\n",
      "Epoch: 11501/40000, error_f = 1.00000\n",
      "Epoch: 11501/40000, alpha = 1.01603\n",
      "\n",
      "Epoch: 11511/40000, total loss = 2.868, Fit loss U = 10.160, Fit loss F = 3.435, KL loss = 437.701\n",
      "Epoch: 11511/40000, alpha = 1.01595\n",
      "\n",
      "Epoch: 11521/40000, total loss = 2.768, Fit loss U = 8.006, Fit loss F = 3.434, KL loss = 439.301\n",
      "Epoch: 11521/40000, alpha = 1.01587\n",
      "\n",
      "Epoch: 11531/40000, total loss = 3.030, Fit loss U = 13.264, Fit loss F = 3.432, KL loss = 439.136\n",
      "Epoch: 11531/40000, alpha = 1.01579\n",
      "\n",
      "Epoch: 11541/40000, total loss = 2.788, Fit loss U = 8.272, Fit loss F = 3.431, KL loss = 440.542\n",
      "Epoch: 11541/40000, alpha = 1.01572\n",
      "\n",
      "Epoch: 11551/40000, total loss = 2.816, Fit loss U = 8.939, Fit loss F = 3.430, KL loss = 439.585\n",
      "Epoch: 11551/40000, alpha = 1.01564\n",
      "\n",
      "Epoch: 11561/40000, total loss = 2.730, Fit loss U = 7.240, Fit loss F = 3.429, KL loss = 439.350\n",
      "Epoch: 11561/40000, alpha = 1.01556\n",
      "\n",
      "Epoch: 11571/40000, total loss = 2.955, Fit loss U = 11.793, Fit loss F = 3.428, KL loss = 438.755\n",
      "Epoch: 11571/40000, alpha = 1.01548\n",
      "\n",
      "Epoch: 11581/40000, total loss = 2.812, Fit loss U = 8.881, Fit loss F = 3.427, KL loss = 439.326\n",
      "Epoch: 11581/40000, alpha = 1.01541\n",
      "\n",
      "Epoch: 11591/40000, total loss = 2.765, Fit loss U = 7.902, Fit loss F = 3.426, KL loss = 439.683\n",
      "Epoch: 11591/40000, alpha = 1.01533\n",
      "\n",
      "Epoch: 11601/40000, total loss = 2.745, Fit loss U = 7.507, Fit loss F = 3.425, KL loss = 439.639\n",
      "Epoch: 11601/40000, error_test = 1.01832, error_train = 1.01006\n",
      "Epoch: 11601/40000, error_f = 0.99999\n",
      "Epoch: 11601/40000, alpha = 1.01526\n",
      "\n",
      "Epoch: 11611/40000, total loss = 2.826, Fit loss U = 9.227, Fit loss F = 3.424, KL loss = 438.598\n",
      "Epoch: 11611/40000, alpha = 1.01518\n",
      "\n",
      "Epoch: 11621/40000, total loss = 2.842, Fit loss U = 9.554, Fit loss F = 3.423, KL loss = 438.621\n",
      "Epoch: 11621/40000, alpha = 1.01511\n",
      "\n",
      "Epoch: 11631/40000, total loss = 3.093, Fit loss U = 14.542, Fit loss F = 3.422, KL loss = 438.899\n",
      "Epoch: 11631/40000, alpha = 1.01503\n",
      "\n",
      "Epoch: 11641/40000, total loss = 2.792, Fit loss U = 8.380, Fit loss F = 3.421, KL loss = 440.434\n",
      "Epoch: 11641/40000, alpha = 1.01496\n",
      "\n",
      "Epoch: 11651/40000, total loss = 2.750, Fit loss U = 7.465, Fit loss F = 3.420, KL loss = 441.186\n",
      "Epoch: 11651/40000, alpha = 1.01488\n",
      "\n",
      "Epoch: 11661/40000, total loss = 2.837, Fit loss U = 9.292, Fit loss F = 3.419, KL loss = 440.296\n",
      "Epoch: 11661/40000, alpha = 1.01481\n",
      "\n",
      "Epoch: 11671/40000, total loss = 2.785, Fit loss U = 8.254, Fit loss F = 3.418, KL loss = 440.349\n",
      "Epoch: 11671/40000, alpha = 1.01474\n",
      "\n",
      "Epoch: 11681/40000, total loss = 2.821, Fit loss U = 8.991, Fit loss F = 3.417, KL loss = 440.107\n",
      "Epoch: 11681/40000, alpha = 1.01466\n",
      "\n",
      "Epoch: 11691/40000, total loss = 2.708, Fit loss U = 6.817, Fit loss F = 3.416, KL loss = 439.227\n",
      "Epoch: 11691/40000, alpha = 1.01459\n",
      "\n",
      "Epoch: 11701/40000, total loss = 2.884, Fit loss U = 10.148, Fit loss F = 3.415, KL loss = 441.248\n",
      "Epoch: 11701/40000, error_test = 1.03335, error_train = 1.02603\n",
      "Epoch: 11701/40000, error_f = 1.00000\n",
      "Epoch: 11701/40000, alpha = 1.01452\n",
      "\n",
      "Epoch: 11711/40000, total loss = 2.883, Fit loss U = 10.090, Fit loss F = 3.414, KL loss = 441.647\n",
      "Epoch: 11711/40000, alpha = 1.01445\n",
      "\n",
      "Epoch: 11721/40000, total loss = 2.931, Fit loss U = 11.156, Fit loss F = 3.413, KL loss = 440.536\n",
      "Epoch: 11721/40000, alpha = 1.01438\n",
      "\n",
      "Epoch: 11731/40000, total loss = 2.704, Fit loss U = 6.718, Fit loss F = 3.412, KL loss = 439.561\n",
      "Epoch: 11731/40000, alpha = 1.01431\n",
      "\n",
      "Epoch: 11741/40000, total loss = 2.809, Fit loss U = 8.864, Fit loss F = 3.411, KL loss = 439.100\n",
      "Epoch: 11741/40000, alpha = 1.01424\n",
      "\n",
      "Epoch: 11751/40000, total loss = 2.719, Fit loss U = 7.058, Fit loss F = 3.410, KL loss = 439.179\n",
      "Epoch: 11751/40000, alpha = 1.01417\n",
      "\n",
      "Epoch: 11761/40000, total loss = 2.756, Fit loss U = 7.817, Fit loss F = 3.409, KL loss = 438.856\n",
      "Epoch: 11761/40000, alpha = 1.01410\n",
      "\n",
      "Epoch: 11771/40000, total loss = 2.781, Fit loss U = 8.388, Fit loss F = 3.409, KL loss = 438.173\n",
      "Epoch: 11771/40000, alpha = 1.01403\n",
      "\n",
      "Epoch: 11781/40000, total loss = 2.714, Fit loss U = 7.106, Fit loss F = 3.408, KL loss = 437.709\n",
      "Epoch: 11781/40000, alpha = 1.01396\n",
      "\n",
      "Epoch: 11791/40000, total loss = 2.835, Fit loss U = 9.482, Fit loss F = 3.407, KL loss = 438.184\n",
      "Epoch: 11791/40000, alpha = 1.01389\n",
      "\n",
      "Epoch: 11801/40000, total loss = 2.790, Fit loss U = 8.571, Fit loss F = 3.406, KL loss = 438.192\n",
      "Epoch: 11801/40000, error_test = 1.01073, error_train = 1.00854\n",
      "Epoch: 11801/40000, error_f = 1.00000\n",
      "Epoch: 11801/40000, alpha = 1.01382\n",
      "\n",
      "Epoch: 11811/40000, total loss = 2.721, Fit loss U = 7.254, Fit loss F = 3.405, KL loss = 437.590\n",
      "Epoch: 11811/40000, alpha = 1.01376\n",
      "\n",
      "Epoch: 11821/40000, total loss = 2.822, Fit loss U = 9.267, Fit loss F = 3.404, KL loss = 437.666\n",
      "Epoch: 11821/40000, alpha = 1.01369\n",
      "\n",
      "Epoch: 11831/40000, total loss = 2.776, Fit loss U = 8.273, Fit loss F = 3.403, KL loss = 438.454\n",
      "Epoch: 11831/40000, alpha = 1.01362\n",
      "\n",
      "Epoch: 11841/40000, total loss = 2.731, Fit loss U = 7.437, Fit loss F = 3.402, KL loss = 437.778\n",
      "Epoch: 11841/40000, alpha = 1.01356\n",
      "\n",
      "Epoch: 11851/40000, total loss = 2.805, Fit loss U = 8.965, Fit loss F = 3.401, KL loss = 437.305\n",
      "Epoch: 11851/40000, alpha = 1.01349\n",
      "\n",
      "Epoch: 11861/40000, total loss = 2.805, Fit loss U = 9.065, Fit loss F = 3.400, KL loss = 436.330\n",
      "Epoch: 11861/40000, alpha = 1.01342\n",
      "\n",
      "Epoch: 11871/40000, total loss = 2.746, Fit loss U = 7.872, Fit loss F = 3.399, KL loss = 436.550\n",
      "Epoch: 11871/40000, alpha = 1.01336\n",
      "\n",
      "Epoch: 11881/40000, total loss = 2.906, Fit loss U = 11.015, Fit loss F = 3.399, KL loss = 437.062\n",
      "Epoch: 11881/40000, alpha = 1.01329\n",
      "\n",
      "Epoch: 11891/40000, total loss = 2.809, Fit loss U = 8.967, Fit loss F = 3.397, KL loss = 438.202\n",
      "Epoch: 11891/40000, alpha = 1.01323\n",
      "\n",
      "Epoch: 11901/40000, total loss = 2.850, Fit loss U = 9.625, Fit loss F = 3.397, KL loss = 439.874\n",
      "Epoch: 11901/40000, error_test = 1.00752, error_train = 1.00097\n",
      "Epoch: 11901/40000, error_f = 1.00000\n",
      "Epoch: 11901/40000, alpha = 1.01316\n",
      "\n",
      "Epoch: 11911/40000, total loss = 2.810, Fit loss U = 8.783, Fit loss F = 3.396, KL loss = 440.221\n",
      "Epoch: 11911/40000, alpha = 1.01310\n",
      "\n",
      "Epoch: 11921/40000, total loss = 2.787, Fit loss U = 8.429, Fit loss F = 3.395, KL loss = 439.206\n",
      "Epoch: 11921/40000, alpha = 1.01304\n",
      "\n",
      "Epoch: 11931/40000, total loss = 2.831, Fit loss U = 9.273, Fit loss F = 3.394, KL loss = 439.486\n",
      "Epoch: 11931/40000, alpha = 1.01297\n",
      "\n",
      "Epoch: 11941/40000, total loss = 2.747, Fit loss U = 7.634, Fit loss F = 3.393, KL loss = 439.042\n",
      "Epoch: 11941/40000, alpha = 1.01291\n",
      "\n",
      "Epoch: 11951/40000, total loss = 2.811, Fit loss U = 9.067, Fit loss F = 3.393, KL loss = 437.584\n",
      "Epoch: 11951/40000, alpha = 1.01285\n",
      "\n",
      "Epoch: 11961/40000, total loss = 2.839, Fit loss U = 9.713, Fit loss F = 3.392, KL loss = 436.735\n",
      "Epoch: 11961/40000, alpha = 1.01279\n",
      "\n",
      "Epoch: 11971/40000, total loss = 2.747, Fit loss U = 7.982, Fit loss F = 3.391, KL loss = 435.720\n",
      "Epoch: 11971/40000, alpha = 1.01272\n",
      "\n",
      "Epoch: 11981/40000, total loss = 2.764, Fit loss U = 8.412, Fit loss F = 3.390, KL loss = 434.689\n",
      "Epoch: 11981/40000, alpha = 1.01266\n",
      "\n",
      "Epoch: 11991/40000, total loss = 2.763, Fit loss U = 8.486, Fit loss F = 3.389, KL loss = 433.902\n",
      "Epoch: 11991/40000, alpha = 1.01260\n",
      "\n",
      "Epoch: 12001/40000, total loss = 2.946, Fit loss U = 12.022, Fit loss F = 3.388, KL loss = 435.138\n",
      "Epoch: 12001/40000, error_test = 1.00349, error_train = 0.98861\n",
      "Epoch: 12001/40000, error_f = 1.00000\n",
      "Epoch: 12001/40000, alpha = 1.01254\n",
      "\n",
      "Epoch: 12011/40000, total loss = 2.744, Fit loss U = 7.841, Fit loss F = 3.387, KL loss = 436.451\n",
      "Epoch: 12011/40000, alpha = 1.01248\n",
      "\n",
      "Epoch: 12021/40000, total loss = 2.856, Fit loss U = 10.102, Fit loss F = 3.387, KL loss = 436.370\n",
      "Epoch: 12021/40000, alpha = 1.01242\n",
      "\n",
      "Epoch: 12031/40000, total loss = 2.784, Fit loss U = 8.585, Fit loss F = 3.386, KL loss = 437.049\n",
      "Epoch: 12031/40000, alpha = 1.01236\n",
      "\n",
      "Epoch: 12041/40000, total loss = 2.776, Fit loss U = 8.424, Fit loss F = 3.385, KL loss = 437.194\n",
      "Epoch: 12041/40000, alpha = 1.01230\n",
      "\n",
      "Epoch: 12051/40000, total loss = 2.771, Fit loss U = 8.359, Fit loss F = 3.384, KL loss = 436.721\n",
      "Epoch: 12051/40000, alpha = 1.01224\n",
      "\n",
      "Epoch: 12061/40000, total loss = 2.863, Fit loss U = 10.240, Fit loss F = 3.383, KL loss = 436.443\n",
      "Epoch: 12061/40000, alpha = 1.01218\n",
      "\n",
      "Epoch: 12071/40000, total loss = 2.840, Fit loss U = 9.676, Fit loss F = 3.383, KL loss = 437.503\n",
      "Epoch: 12071/40000, alpha = 1.01212\n",
      "\n",
      "Epoch: 12081/40000, total loss = 2.807, Fit loss U = 8.964, Fit loss F = 3.382, KL loss = 437.981\n",
      "Epoch: 12081/40000, alpha = 1.01206\n",
      "\n",
      "Epoch: 12091/40000, total loss = 2.806, Fit loss U = 8.956, Fit loss F = 3.381, KL loss = 437.849\n",
      "Epoch: 12091/40000, alpha = 1.01201\n",
      "\n",
      "Epoch: 12101/40000, total loss = 2.712, Fit loss U = 7.032, Fit loss F = 3.380, KL loss = 438.253\n",
      "Epoch: 12101/40000, error_test = 0.99588, error_train = 1.02502\n",
      "Epoch: 12101/40000, error_f = 1.00000\n",
      "Epoch: 12101/40000, alpha = 1.01195\n",
      "\n",
      "Epoch: 12111/40000, total loss = 2.752, Fit loss U = 7.811, Fit loss F = 3.380, KL loss = 438.460\n",
      "Epoch: 12111/40000, alpha = 1.01189\n",
      "\n",
      "Epoch: 12121/40000, total loss = 2.950, Fit loss U = 11.804, Fit loss F = 3.379, KL loss = 438.146\n",
      "Epoch: 12121/40000, alpha = 1.01183\n",
      "\n",
      "Epoch: 12131/40000, total loss = 2.766, Fit loss U = 8.143, Fit loss F = 3.378, KL loss = 438.057\n",
      "Epoch: 12131/40000, alpha = 1.01178\n",
      "\n",
      "Epoch: 12141/40000, total loss = 2.664, Fit loss U = 6.160, Fit loss F = 3.377, KL loss = 437.335\n",
      "Epoch: 12141/40000, alpha = 1.01172\n",
      "\n",
      "Epoch: 12151/40000, total loss = 2.751, Fit loss U = 7.914, Fit loss F = 3.377, KL loss = 437.293\n",
      "Epoch: 12151/40000, alpha = 1.01166\n",
      "\n",
      "Epoch: 12161/40000, total loss = 2.796, Fit loss U = 8.751, Fit loss F = 3.376, KL loss = 437.884\n",
      "Epoch: 12161/40000, alpha = 1.01161\n",
      "\n",
      "Epoch: 12171/40000, total loss = 2.694, Fit loss U = 6.677, Fit loss F = 3.375, KL loss = 438.268\n",
      "Epoch: 12171/40000, alpha = 1.01155\n",
      "\n",
      "Epoch: 12181/40000, total loss = 2.948, Fit loss U = 11.721, Fit loss F = 3.374, KL loss = 438.704\n",
      "Epoch: 12181/40000, alpha = 1.01150\n",
      "\n",
      "Epoch: 12191/40000, total loss = 2.839, Fit loss U = 9.395, Fit loss F = 3.374, KL loss = 440.079\n",
      "Epoch: 12191/40000, alpha = 1.01144\n",
      "\n",
      "Epoch: 12201/40000, total loss = 2.859, Fit loss U = 9.783, Fit loss F = 3.373, KL loss = 440.208\n",
      "Epoch: 12201/40000, error_test = 0.99092, error_train = 1.09525\n",
      "Epoch: 12201/40000, error_f = 1.00000\n",
      "Epoch: 12201/40000, alpha = 1.01139\n",
      "\n",
      "Epoch: 12211/40000, total loss = 2.813, Fit loss U = 8.894, Fit loss F = 3.372, KL loss = 439.850\n",
      "Epoch: 12211/40000, alpha = 1.01133\n",
      "\n",
      "Epoch: 12221/40000, total loss = 2.896, Fit loss U = 10.697, Fit loss F = 3.371, KL loss = 438.415\n",
      "Epoch: 12221/40000, alpha = 1.01128\n",
      "\n",
      "Epoch: 12231/40000, total loss = 2.829, Fit loss U = 9.420, Fit loss F = 3.371, KL loss = 437.848\n",
      "Epoch: 12231/40000, alpha = 1.01122\n",
      "\n",
      "Epoch: 12241/40000, total loss = 2.655, Fit loss U = 5.699, Fit loss F = 3.370, KL loss = 440.347\n",
      "Epoch: 12241/40000, alpha = 1.01117\n",
      "\n",
      "Epoch: 12251/40000, total loss = 2.785, Fit loss U = 8.299, Fit loss F = 3.369, KL loss = 440.233\n",
      "Epoch: 12251/40000, alpha = 1.01112\n",
      "\n",
      "Epoch: 12261/40000, total loss = 2.788, Fit loss U = 8.442, Fit loss F = 3.368, KL loss = 439.504\n",
      "Epoch: 12261/40000, alpha = 1.01106\n",
      "\n",
      "Epoch: 12271/40000, total loss = 2.785, Fit loss U = 8.445, Fit loss F = 3.368, KL loss = 438.924\n",
      "Epoch: 12271/40000, alpha = 1.01101\n",
      "\n",
      "Epoch: 12281/40000, total loss = 2.822, Fit loss U = 8.909, Fit loss F = 3.367, KL loss = 441.710\n",
      "Epoch: 12281/40000, alpha = 1.01096\n",
      "\n",
      "Epoch: 12291/40000, total loss = 2.785, Fit loss U = 8.136, Fit loss F = 3.366, KL loss = 442.082\n",
      "Epoch: 12291/40000, alpha = 1.01091\n",
      "\n",
      "Epoch: 12301/40000, total loss = 2.913, Fit loss U = 10.852, Fit loss F = 3.365, KL loss = 440.511\n",
      "Epoch: 12301/40000, error_test = 0.97862, error_train = 1.03089\n",
      "Epoch: 12301/40000, error_f = 1.00000\n",
      "Epoch: 12301/40000, alpha = 1.01085\n",
      "\n",
      "Epoch: 12311/40000, total loss = 2.861, Fit loss U = 9.785, Fit loss F = 3.365, KL loss = 440.658\n",
      "Epoch: 12311/40000, alpha = 1.01080\n",
      "\n",
      "Epoch: 12321/40000, total loss = 2.885, Fit loss U = 10.284, Fit loss F = 3.364, KL loss = 440.594\n",
      "Epoch: 12321/40000, alpha = 1.01075\n",
      "\n",
      "Epoch: 12331/40000, total loss = 2.755, Fit loss U = 7.686, Fit loss F = 3.363, KL loss = 440.599\n",
      "Epoch: 12331/40000, alpha = 1.01070\n",
      "\n",
      "Epoch: 12341/40000, total loss = 2.908, Fit loss U = 10.816, Fit loss F = 3.363, KL loss = 439.892\n",
      "Epoch: 12341/40000, alpha = 1.01065\n",
      "\n",
      "Epoch: 12351/40000, total loss = 2.772, Fit loss U = 8.148, Fit loss F = 3.362, KL loss = 439.311\n",
      "Epoch: 12351/40000, alpha = 1.01060\n",
      "\n",
      "Epoch: 12361/40000, total loss = 2.822, Fit loss U = 9.228, Fit loss F = 3.361, KL loss = 438.564\n",
      "Epoch: 12361/40000, alpha = 1.01055\n",
      "\n",
      "Epoch: 12371/40000, total loss = 2.850, Fit loss U = 9.820, Fit loss F = 3.361, KL loss = 438.121\n",
      "Epoch: 12371/40000, alpha = 1.01050\n",
      "\n",
      "Epoch: 12381/40000, total loss = 2.745, Fit loss U = 7.694, Fit loss F = 3.360, KL loss = 438.458\n",
      "Epoch: 12381/40000, alpha = 1.01045\n",
      "\n",
      "Epoch: 12391/40000, total loss = 2.973, Fit loss U = 12.217, Fit loss F = 3.359, KL loss = 438.762\n",
      "Epoch: 12391/40000, alpha = 1.01040\n",
      "\n",
      "Epoch: 12401/40000, total loss = 2.915, Fit loss U = 10.968, Fit loss F = 3.359, KL loss = 439.746\n",
      "Epoch: 12401/40000, error_test = 1.00327, error_train = 1.02878\n",
      "Epoch: 12401/40000, error_f = 0.99999\n",
      "Epoch: 12401/40000, alpha = 1.01035\n",
      "\n",
      "Epoch: 12411/40000, total loss = 2.793, Fit loss U = 8.584, Fit loss F = 3.358, KL loss = 439.096\n",
      "Epoch: 12411/40000, alpha = 1.01030\n",
      "\n",
      "Epoch: 12421/40000, total loss = 2.854, Fit loss U = 9.934, Fit loss F = 3.357, KL loss = 437.882\n",
      "Epoch: 12421/40000, alpha = 1.01025\n",
      "\n",
      "Epoch: 12431/40000, total loss = 2.941, Fit loss U = 11.767, Fit loss F = 3.357, KL loss = 436.884\n",
      "Epoch: 12431/40000, alpha = 1.01020\n",
      "\n",
      "Epoch: 12441/40000, total loss = 2.860, Fit loss U = 10.127, Fit loss F = 3.356, KL loss = 437.226\n",
      "Epoch: 12441/40000, alpha = 1.01015\n",
      "\n",
      "Epoch: 12451/40000, total loss = 2.856, Fit loss U = 10.000, Fit loss F = 3.355, KL loss = 437.740\n",
      "Epoch: 12451/40000, alpha = 1.01010\n",
      "\n",
      "Epoch: 12461/40000, total loss = 2.916, Fit loss U = 11.179, Fit loss F = 3.355, KL loss = 437.914\n",
      "Epoch: 12461/40000, alpha = 1.01006\n",
      "\n",
      "Epoch: 12471/40000, total loss = 2.900, Fit loss U = 10.752, Fit loss F = 3.354, KL loss = 438.927\n",
      "Epoch: 12471/40000, alpha = 1.01001\n",
      "\n",
      "Epoch: 12481/40000, total loss = 2.788, Fit loss U = 8.466, Fit loss F = 3.353, KL loss = 439.459\n",
      "Epoch: 12481/40000, alpha = 1.00996\n",
      "\n",
      "Epoch: 12491/40000, total loss = 2.958, Fit loss U = 11.844, Fit loss F = 3.353, KL loss = 439.671\n",
      "Epoch: 12491/40000, alpha = 1.00991\n",
      "\n",
      "Epoch: 12501/40000, total loss = 2.789, Fit loss U = 8.471, Fit loss F = 3.352, KL loss = 439.634\n",
      "Epoch: 12501/40000, error_test = 0.97978, error_train = 1.02521\n",
      "Epoch: 12501/40000, error_f = 0.99999\n",
      "Epoch: 12501/40000, alpha = 1.00987\n",
      "\n",
      "Epoch: 12511/40000, total loss = 2.741, Fit loss U = 7.645, Fit loss F = 3.351, KL loss = 438.175\n",
      "Epoch: 12511/40000, alpha = 1.00982\n",
      "\n",
      "Epoch: 12521/40000, total loss = 2.767, Fit loss U = 8.219, Fit loss F = 3.351, KL loss = 437.783\n",
      "Epoch: 12521/40000, alpha = 1.00977\n",
      "\n",
      "Epoch: 12531/40000, total loss = 2.737, Fit loss U = 7.608, Fit loss F = 3.350, KL loss = 437.716\n",
      "Epoch: 12531/40000, alpha = 1.00973\n",
      "\n",
      "Epoch: 12541/40000, total loss = 2.854, Fit loss U = 10.009, Fit loss F = 3.350, KL loss = 437.190\n",
      "Epoch: 12541/40000, alpha = 1.00968\n",
      "\n",
      "Epoch: 12551/40000, total loss = 2.772, Fit loss U = 8.461, Fit loss F = 3.349, KL loss = 436.255\n",
      "Epoch: 12551/40000, alpha = 1.00964\n",
      "\n",
      "Epoch: 12561/40000, total loss = 2.748, Fit loss U = 8.057, Fit loss F = 3.348, KL loss = 435.521\n",
      "Epoch: 12561/40000, alpha = 1.00959\n",
      "\n",
      "Epoch: 12571/40000, total loss = 2.728, Fit loss U = 7.517, Fit loss F = 3.348, KL loss = 436.986\n",
      "Epoch: 12571/40000, alpha = 1.00954\n",
      "\n",
      "Epoch: 12581/40000, total loss = 2.911, Fit loss U = 10.978, Fit loss F = 3.347, KL loss = 439.005\n",
      "Epoch: 12581/40000, alpha = 1.00950\n",
      "\n",
      "Epoch: 12591/40000, total loss = 2.732, Fit loss U = 7.285, Fit loss F = 3.347, KL loss = 439.984\n",
      "Epoch: 12591/40000, alpha = 1.00945\n",
      "\n",
      "Epoch: 12601/40000, total loss = 2.750, Fit loss U = 7.668, Fit loss F = 3.346, KL loss = 439.830\n",
      "Epoch: 12601/40000, error_test = 1.02010, error_train = 1.05238\n",
      "Epoch: 12601/40000, error_f = 0.99999\n",
      "Epoch: 12601/40000, alpha = 1.00941\n",
      "\n",
      "Epoch: 12611/40000, total loss = 2.988, Fit loss U = 12.398, Fit loss F = 3.345, KL loss = 440.227\n",
      "Epoch: 12611/40000, alpha = 1.00937\n",
      "\n",
      "Epoch: 12621/40000, total loss = 2.786, Fit loss U = 8.304, Fit loss F = 3.345, KL loss = 440.763\n",
      "Epoch: 12621/40000, alpha = 1.00932\n",
      "\n",
      "Epoch: 12631/40000, total loss = 2.850, Fit loss U = 9.551, Fit loss F = 3.344, KL loss = 441.073\n",
      "Epoch: 12631/40000, alpha = 1.00928\n",
      "\n",
      "Epoch: 12641/40000, total loss = 2.793, Fit loss U = 8.407, Fit loss F = 3.344, KL loss = 441.133\n",
      "Epoch: 12641/40000, alpha = 1.00923\n",
      "\n",
      "Epoch: 12651/40000, total loss = 2.831, Fit loss U = 9.266, Fit loss F = 3.343, KL loss = 440.135\n",
      "Epoch: 12651/40000, alpha = 1.00919\n",
      "\n",
      "Epoch: 12661/40000, total loss = 2.888, Fit loss U = 10.395, Fit loss F = 3.342, KL loss = 440.161\n",
      "Epoch: 12661/40000, alpha = 1.00915\n",
      "\n",
      "Epoch: 12671/40000, total loss = 2.745, Fit loss U = 7.456, Fit loss F = 3.342, KL loss = 440.996\n",
      "Epoch: 12671/40000, alpha = 1.00910\n",
      "\n",
      "Epoch: 12681/40000, total loss = 2.807, Fit loss U = 8.773, Fit loss F = 3.341, KL loss = 440.302\n",
      "Epoch: 12681/40000, alpha = 1.00906\n",
      "\n",
      "Epoch: 12691/40000, total loss = 2.763, Fit loss U = 8.036, Fit loss F = 3.341, KL loss = 438.858\n",
      "Epoch: 12691/40000, alpha = 1.00902\n",
      "\n",
      "Epoch: 12701/40000, total loss = 2.982, Fit loss U = 12.491, Fit loss F = 3.340, KL loss = 438.146\n",
      "Epoch: 12701/40000, error_test = 0.99164, error_train = 1.02155\n",
      "Epoch: 12701/40000, error_f = 1.00000\n",
      "Epoch: 12701/40000, alpha = 1.00898\n",
      "\n",
      "Epoch: 12711/40000, total loss = 2.883, Fit loss U = 10.473, Fit loss F = 3.340, KL loss = 438.443\n",
      "Epoch: 12711/40000, alpha = 1.00893\n",
      "\n",
      "Epoch: 12721/40000, total loss = 2.812, Fit loss U = 9.095, Fit loss F = 3.339, KL loss = 438.018\n",
      "Epoch: 12721/40000, alpha = 1.00889\n",
      "\n",
      "Epoch: 12731/40000, total loss = 2.671, Fit loss U = 6.300, Fit loss F = 3.338, KL loss = 437.728\n",
      "Epoch: 12731/40000, alpha = 1.00885\n",
      "\n",
      "Epoch: 12741/40000, total loss = 2.752, Fit loss U = 7.938, Fit loss F = 3.338, KL loss = 437.665\n",
      "Epoch: 12741/40000, alpha = 1.00881\n",
      "\n",
      "Epoch: 12751/40000, total loss = 2.772, Fit loss U = 8.349, Fit loss F = 3.337, KL loss = 437.630\n",
      "Epoch: 12751/40000, alpha = 1.00877\n",
      "\n",
      "Epoch: 12761/40000, total loss = 2.859, Fit loss U = 10.053, Fit loss F = 3.336, KL loss = 437.820\n",
      "Epoch: 12761/40000, alpha = 1.00873\n",
      "\n",
      "Epoch: 12771/40000, total loss = 2.715, Fit loss U = 7.235, Fit loss F = 3.336, KL loss = 437.374\n",
      "Epoch: 12771/40000, alpha = 1.00869\n",
      "\n",
      "Epoch: 12781/40000, total loss = 2.774, Fit loss U = 8.550, Fit loss F = 3.336, KL loss = 436.005\n",
      "Epoch: 12781/40000, alpha = 1.00865\n",
      "\n",
      "Epoch: 12791/40000, total loss = 2.775, Fit loss U = 8.593, Fit loss F = 3.335, KL loss = 435.804\n",
      "Epoch: 12791/40000, alpha = 1.00860\n",
      "\n",
      "Epoch: 12801/40000, total loss = 2.756, Fit loss U = 8.136, Fit loss F = 3.334, KL loss = 436.482\n",
      "Epoch: 12801/40000, error_test = 1.00847, error_train = 1.04082\n",
      "Epoch: 12801/40000, error_f = 1.00000\n",
      "Epoch: 12801/40000, alpha = 1.00856\n",
      "\n",
      "Epoch: 12811/40000, total loss = 2.899, Fit loss U = 11.036, Fit loss F = 3.334, KL loss = 436.028\n",
      "Epoch: 12811/40000, alpha = 1.00852\n",
      "\n",
      "Epoch: 12821/40000, total loss = 2.637, Fit loss U = 5.811, Fit loss F = 3.333, KL loss = 435.951\n",
      "Epoch: 12821/40000, alpha = 1.00848\n",
      "\n",
      "Epoch: 12831/40000, total loss = 2.877, Fit loss U = 10.709, Fit loss F = 3.333, KL loss = 434.957\n",
      "Epoch: 12831/40000, alpha = 1.00844\n",
      "\n",
      "Epoch: 12841/40000, total loss = 2.894, Fit loss U = 10.963, Fit loss F = 3.332, KL loss = 435.944\n",
      "Epoch: 12841/40000, alpha = 1.00841\n",
      "\n",
      "Epoch: 12851/40000, total loss = 2.754, Fit loss U = 7.957, Fit loss F = 3.332, KL loss = 437.854\n",
      "Epoch: 12851/40000, alpha = 1.00837\n",
      "\n",
      "Epoch: 12861/40000, total loss = 2.856, Fit loss U = 9.979, Fit loss F = 3.331, KL loss = 438.006\n",
      "Epoch: 12861/40000, alpha = 1.00833\n",
      "\n",
      "Epoch: 12871/40000, total loss = 2.827, Fit loss U = 9.356, Fit loss F = 3.331, KL loss = 438.549\n",
      "Epoch: 12871/40000, alpha = 1.00829\n",
      "\n",
      "Epoch: 12881/40000, total loss = 2.863, Fit loss U = 9.990, Fit loss F = 3.330, KL loss = 439.420\n",
      "Epoch: 12881/40000, alpha = 1.00825\n",
      "\n",
      "Epoch: 12891/40000, total loss = 2.875, Fit loss U = 10.144, Fit loss F = 3.329, KL loss = 440.257\n",
      "Epoch: 12891/40000, alpha = 1.00821\n",
      "\n",
      "Epoch: 12901/40000, total loss = 2.826, Fit loss U = 9.108, Fit loss F = 3.329, KL loss = 440.921\n",
      "Epoch: 12901/40000, error_test = 1.01842, error_train = 0.96636\n",
      "Epoch: 12901/40000, error_f = 1.00001\n",
      "Epoch: 12901/40000, alpha = 1.00817\n",
      "\n",
      "Epoch: 12911/40000, total loss = 2.781, Fit loss U = 8.219, Fit loss F = 3.329, KL loss = 440.642\n",
      "Epoch: 12911/40000, alpha = 1.00813\n",
      "\n",
      "Epoch: 12921/40000, total loss = 2.845, Fit loss U = 9.561, Fit loss F = 3.328, KL loss = 440.092\n",
      "Epoch: 12921/40000, alpha = 1.00810\n",
      "\n",
      "Epoch: 12931/40000, total loss = 2.765, Fit loss U = 8.105, Fit loss F = 3.328, KL loss = 438.717\n",
      "Epoch: 12931/40000, alpha = 1.00806\n",
      "\n",
      "Epoch: 12941/40000, total loss = 2.803, Fit loss U = 8.865, Fit loss F = 3.327, KL loss = 438.658\n",
      "Epoch: 12941/40000, alpha = 1.00802\n",
      "\n",
      "Epoch: 12951/40000, total loss = 2.731, Fit loss U = 7.478, Fit loss F = 3.327, KL loss = 438.208\n",
      "Epoch: 12951/40000, alpha = 1.00798\n",
      "\n",
      "Epoch: 12961/40000, total loss = 2.810, Fit loss U = 9.018, Fit loss F = 3.326, KL loss = 438.641\n",
      "Epoch: 12961/40000, alpha = 1.00795\n",
      "\n",
      "Epoch: 12971/40000, total loss = 2.999, Fit loss U = 12.608, Fit loss F = 3.326, KL loss = 440.548\n",
      "Epoch: 12971/40000, alpha = 1.00791\n",
      "\n",
      "Epoch: 12981/40000, total loss = 2.881, Fit loss U = 10.058, Fit loss F = 3.325, KL loss = 442.280\n",
      "Epoch: 12981/40000, alpha = 1.00787\n",
      "\n",
      "Epoch: 12991/40000, total loss = 2.739, Fit loss U = 7.286, Fit loss F = 3.325, KL loss = 441.761\n",
      "Epoch: 12991/40000, alpha = 1.00784\n",
      "\n",
      "Epoch: 13001/40000, total loss = 2.798, Fit loss U = 8.614, Fit loss F = 3.324, KL loss = 440.139\n",
      "Epoch: 13001/40000, error_test = 1.02158, error_train = 1.05423\n",
      "Epoch: 13001/40000, error_f = 0.99999\n",
      "Epoch: 13001/40000, alpha = 1.00780\n",
      "\n",
      "Epoch: 13011/40000, total loss = 2.761, Fit loss U = 8.058, Fit loss F = 3.324, KL loss = 438.313\n",
      "Epoch: 13011/40000, alpha = 1.00776\n",
      "\n",
      "Epoch: 13021/40000, total loss = 2.825, Fit loss U = 9.431, Fit loss F = 3.323, KL loss = 437.515\n",
      "Epoch: 13021/40000, alpha = 1.00773\n",
      "\n",
      "Epoch: 13031/40000, total loss = 2.839, Fit loss U = 9.703, Fit loss F = 3.323, KL loss = 437.613\n",
      "Epoch: 13031/40000, alpha = 1.00769\n",
      "\n",
      "Epoch: 13041/40000, total loss = 2.835, Fit loss U = 9.492, Fit loss F = 3.322, KL loss = 438.921\n",
      "Epoch: 13041/40000, alpha = 1.00766\n",
      "\n",
      "Epoch: 13051/40000, total loss = 2.756, Fit loss U = 7.906, Fit loss F = 3.322, KL loss = 438.893\n",
      "Epoch: 13051/40000, alpha = 1.00762\n",
      "\n",
      "Epoch: 13061/40000, total loss = 2.958, Fit loss U = 11.971, Fit loss F = 3.321, KL loss = 438.613\n",
      "Epoch: 13061/40000, alpha = 1.00759\n",
      "\n",
      "Epoch: 13071/40000, total loss = 2.786, Fit loss U = 8.535, Fit loss F = 3.321, KL loss = 438.688\n",
      "Epoch: 13071/40000, alpha = 1.00755\n",
      "\n",
      "Epoch: 13081/40000, total loss = 2.782, Fit loss U = 8.424, Fit loss F = 3.320, KL loss = 439.056\n",
      "Epoch: 13081/40000, alpha = 1.00751\n",
      "\n",
      "Epoch: 13091/40000, total loss = 3.059, Fit loss U = 13.852, Fit loss F = 3.320, KL loss = 439.995\n",
      "Epoch: 13091/40000, alpha = 1.00748\n",
      "\n",
      "Epoch: 13101/40000, total loss = 2.887, Fit loss U = 10.359, Fit loss F = 3.319, KL loss = 440.609\n",
      "Epoch: 13101/40000, error_test = 1.06030, error_train = 1.00682\n",
      "Epoch: 13101/40000, error_f = 1.00000\n",
      "Epoch: 13101/40000, alpha = 1.00745\n",
      "\n",
      "Epoch: 13111/40000, total loss = 2.898, Fit loss U = 10.560, Fit loss F = 3.319, KL loss = 440.736\n",
      "Epoch: 13111/40000, alpha = 1.00741\n",
      "\n",
      "Epoch: 13121/40000, total loss = 2.889, Fit loss U = 10.403, Fit loss F = 3.318, KL loss = 440.644\n",
      "Epoch: 13121/40000, alpha = 1.00738\n",
      "\n",
      "Epoch: 13131/40000, total loss = 2.956, Fit loss U = 11.726, Fit loss F = 3.318, KL loss = 440.840\n",
      "Epoch: 13131/40000, alpha = 1.00734\n",
      "\n",
      "Epoch: 13141/40000, total loss = 2.800, Fit loss U = 8.672, Fit loss F = 3.317, KL loss = 440.127\n",
      "Epoch: 13141/40000, alpha = 1.00731\n",
      "\n",
      "Epoch: 13151/40000, total loss = 2.831, Fit loss U = 9.344, Fit loss F = 3.317, KL loss = 439.521\n",
      "Epoch: 13151/40000, alpha = 1.00727\n",
      "\n",
      "Epoch: 13161/40000, total loss = 2.826, Fit loss U = 9.136, Fit loss F = 3.316, KL loss = 440.592\n",
      "Epoch: 13161/40000, alpha = 1.00724\n",
      "\n",
      "Epoch: 13171/40000, total loss = 2.872, Fit loss U = 9.997, Fit loss F = 3.316, KL loss = 441.220\n",
      "Epoch: 13171/40000, alpha = 1.00721\n",
      "\n",
      "Epoch: 13181/40000, total loss = 2.838, Fit loss U = 9.291, Fit loss F = 3.316, KL loss = 441.587\n",
      "Epoch: 13181/40000, alpha = 1.00717\n",
      "\n",
      "Epoch: 13191/40000, total loss = 2.899, Fit loss U = 10.516, Fit loss F = 3.315, KL loss = 441.571\n",
      "Epoch: 13191/40000, alpha = 1.00714\n",
      "\n",
      "Epoch: 13201/40000, total loss = 2.769, Fit loss U = 7.818, Fit loss F = 3.315, KL loss = 442.514\n",
      "Epoch: 13201/40000, error_test = 1.02300, error_train = 0.97853\n",
      "Epoch: 13201/40000, error_f = 1.00000\n",
      "Epoch: 13201/40000, alpha = 1.00711\n",
      "\n",
      "Epoch: 13211/40000, total loss = 2.863, Fit loss U = 9.747, Fit loss F = 3.314, KL loss = 441.969\n",
      "Epoch: 13211/40000, alpha = 1.00708\n",
      "\n",
      "Epoch: 13221/40000, total loss = 2.789, Fit loss U = 8.402, Fit loss F = 3.314, KL loss = 440.607\n",
      "Epoch: 13221/40000, alpha = 1.00704\n",
      "\n",
      "Epoch: 13231/40000, total loss = 2.815, Fit loss U = 9.089, Fit loss F = 3.313, KL loss = 439.016\n",
      "Epoch: 13231/40000, alpha = 1.00701\n",
      "\n",
      "Epoch: 13241/40000, total loss = 2.945, Fit loss U = 11.749, Fit loss F = 3.313, KL loss = 438.297\n",
      "Epoch: 13241/40000, alpha = 1.00698\n",
      "\n",
      "Epoch: 13251/40000, total loss = 2.809, Fit loss U = 8.919, Fit loss F = 3.312, KL loss = 439.461\n",
      "Epoch: 13251/40000, alpha = 1.00695\n",
      "\n",
      "Epoch: 13261/40000, total loss = 2.763, Fit loss U = 8.007, Fit loss F = 3.312, KL loss = 439.474\n",
      "Epoch: 13261/40000, alpha = 1.00691\n",
      "\n",
      "Epoch: 13271/40000, total loss = 2.835, Fit loss U = 9.451, Fit loss F = 3.312, KL loss = 439.450\n",
      "Epoch: 13271/40000, alpha = 1.00688\n",
      "\n",
      "Epoch: 13281/40000, total loss = 2.744, Fit loss U = 7.709, Fit loss F = 3.311, KL loss = 438.511\n",
      "Epoch: 13281/40000, alpha = 1.00685\n",
      "\n",
      "Epoch: 13291/40000, total loss = 2.744, Fit loss U = 7.768, Fit loss F = 3.311, KL loss = 437.979\n",
      "Epoch: 13291/40000, alpha = 1.00682\n",
      "\n",
      "Epoch: 13301/40000, total loss = 2.883, Fit loss U = 10.589, Fit loss F = 3.310, KL loss = 437.582\n",
      "Epoch: 13301/40000, error_test = 1.01779, error_train = 0.95730\n",
      "Epoch: 13301/40000, error_f = 0.99999\n",
      "Epoch: 13301/40000, alpha = 1.00679\n",
      "\n",
      "Epoch: 13311/40000, total loss = 2.872, Fit loss U = 10.265, Fit loss F = 3.310, KL loss = 438.727\n",
      "Epoch: 13311/40000, alpha = 1.00676\n",
      "\n",
      "Epoch: 13321/40000, total loss = 2.761, Fit loss U = 8.060, Fit loss F = 3.310, KL loss = 438.584\n",
      "Epoch: 13321/40000, alpha = 1.00672\n",
      "\n",
      "Epoch: 13331/40000, total loss = 2.764, Fit loss U = 8.210, Fit loss F = 3.309, KL loss = 437.689\n",
      "Epoch: 13331/40000, alpha = 1.00669\n",
      "\n",
      "Epoch: 13341/40000, total loss = 2.836, Fit loss U = 9.733, Fit loss F = 3.309, KL loss = 436.882\n",
      "Epoch: 13341/40000, alpha = 1.00666\n",
      "\n",
      "Epoch: 13351/40000, total loss = 2.766, Fit loss U = 8.436, Fit loss F = 3.308, KL loss = 435.826\n",
      "Epoch: 13351/40000, alpha = 1.00663\n",
      "\n",
      "Epoch: 13361/40000, total loss = 2.867, Fit loss U = 10.546, Fit loss F = 3.308, KL loss = 434.775\n",
      "Epoch: 13361/40000, alpha = 1.00660\n",
      "\n",
      "Epoch: 13371/40000, total loss = 2.755, Fit loss U = 8.278, Fit loss F = 3.308, KL loss = 435.076\n",
      "Epoch: 13371/40000, alpha = 1.00657\n",
      "\n",
      "Epoch: 13381/40000, total loss = 2.782, Fit loss U = 8.703, Fit loss F = 3.307, KL loss = 436.323\n",
      "Epoch: 13381/40000, alpha = 1.00654\n",
      "\n",
      "Epoch: 13391/40000, total loss = 2.889, Fit loss U = 10.427, Fit loss F = 3.307, KL loss = 440.397\n",
      "Epoch: 13391/40000, alpha = 1.00651\n",
      "\n",
      "Epoch: 13401/40000, total loss = 2.719, Fit loss U = 6.958, Fit loss F = 3.306, KL loss = 441.157\n",
      "Epoch: 13401/40000, error_test = 1.01225, error_train = 0.98787\n",
      "Epoch: 13401/40000, error_f = 1.00000\n",
      "Epoch: 13401/40000, alpha = 1.00648\n",
      "\n",
      "Epoch: 13411/40000, total loss = 2.864, Fit loss U = 9.944, Fit loss F = 3.306, KL loss = 440.334\n",
      "Epoch: 13411/40000, alpha = 1.00645\n",
      "\n",
      "Epoch: 13421/40000, total loss = 2.755, Fit loss U = 7.843, Fit loss F = 3.306, KL loss = 439.508\n",
      "Epoch: 13421/40000, alpha = 1.00642\n",
      "\n",
      "Epoch: 13431/40000, total loss = 2.783, Fit loss U = 8.467, Fit loss F = 3.305, KL loss = 438.947\n",
      "Epoch: 13431/40000, alpha = 1.00639\n",
      "\n",
      "Epoch: 13441/40000, total loss = 2.894, Fit loss U = 10.776, Fit loss F = 3.305, KL loss = 438.062\n",
      "Epoch: 13441/40000, alpha = 1.00636\n",
      "\n",
      "Epoch: 13451/40000, total loss = 2.779, Fit loss U = 8.496, Fit loss F = 3.304, KL loss = 437.747\n",
      "Epoch: 13451/40000, alpha = 1.00633\n",
      "\n",
      "Epoch: 13461/40000, total loss = 2.863, Fit loss U = 10.134, Fit loss F = 3.304, KL loss = 438.290\n",
      "Epoch: 13461/40000, alpha = 1.00630\n",
      "\n",
      "Epoch: 13471/40000, total loss = 2.843, Fit loss U = 9.513, Fit loss F = 3.303, KL loss = 440.388\n",
      "Epoch: 13471/40000, alpha = 1.00628\n",
      "\n",
      "Epoch: 13481/40000, total loss = 2.760, Fit loss U = 7.686, Fit loss F = 3.303, KL loss = 442.038\n",
      "Epoch: 13481/40000, alpha = 1.00625\n",
      "\n",
      "Epoch: 13491/40000, total loss = 2.794, Fit loss U = 8.444, Fit loss F = 3.303, KL loss = 441.272\n",
      "Epoch: 13491/40000, alpha = 1.00622\n",
      "\n",
      "Epoch: 13501/40000, total loss = 2.756, Fit loss U = 7.806, Fit loss F = 3.302, KL loss = 440.175\n",
      "Epoch: 13501/40000, error_test = 1.01447, error_train = 1.01617\n",
      "Epoch: 13501/40000, error_f = 1.00000\n",
      "Epoch: 13501/40000, alpha = 1.00619\n",
      "\n",
      "Epoch: 13511/40000, total loss = 2.996, Fit loss U = 12.722, Fit loss F = 3.302, KL loss = 439.001\n",
      "Epoch: 13511/40000, alpha = 1.00616\n",
      "\n",
      "Epoch: 13521/40000, total loss = 2.802, Fit loss U = 8.841, Fit loss F = 3.302, KL loss = 438.914\n",
      "Epoch: 13521/40000, alpha = 1.00613\n",
      "\n",
      "Epoch: 13531/40000, total loss = 2.782, Fit loss U = 8.442, Fit loss F = 3.301, KL loss = 438.874\n",
      "Epoch: 13531/40000, alpha = 1.00611\n",
      "\n",
      "Epoch: 13541/40000, total loss = 2.839, Fit loss U = 9.546, Fit loss F = 3.301, KL loss = 439.337\n",
      "Epoch: 13541/40000, alpha = 1.00608\n",
      "\n",
      "Epoch: 13551/40000, total loss = 2.987, Fit loss U = 12.619, Fit loss F = 3.300, KL loss = 438.127\n",
      "Epoch: 13551/40000, alpha = 1.00605\n",
      "\n",
      "Epoch: 13561/40000, total loss = 2.763, Fit loss U = 8.204, Fit loss F = 3.300, KL loss = 437.489\n",
      "Epoch: 13561/40000, alpha = 1.00602\n",
      "\n",
      "Epoch: 13571/40000, total loss = 2.768, Fit loss U = 8.212, Fit loss F = 3.300, KL loss = 438.413\n",
      "Epoch: 13571/40000, alpha = 1.00599\n",
      "\n",
      "Epoch: 13581/40000, total loss = 2.912, Fit loss U = 10.953, Fit loss F = 3.299, KL loss = 439.915\n",
      "Epoch: 13581/40000, alpha = 1.00597\n",
      "\n",
      "Epoch: 13591/40000, total loss = 2.777, Fit loss U = 8.201, Fit loss F = 3.299, KL loss = 440.332\n",
      "Epoch: 13591/40000, alpha = 1.00594\n",
      "\n",
      "Epoch: 13601/40000, total loss = 2.809, Fit loss U = 8.936, Fit loss F = 3.299, KL loss = 439.515\n",
      "Epoch: 13601/40000, error_test = 1.00253, error_train = 1.01460\n",
      "Epoch: 13601/40000, error_f = 1.00000\n",
      "Epoch: 13601/40000, alpha = 1.00591\n",
      "\n",
      "Epoch: 13611/40000, total loss = 3.156, Fit loss U = 15.963, Fit loss F = 3.298, KL loss = 438.617\n",
      "Epoch: 13611/40000, alpha = 1.00589\n",
      "\n",
      "Epoch: 13621/40000, total loss = 2.818, Fit loss U = 9.157, Fit loss F = 3.298, KL loss = 439.005\n",
      "Epoch: 13621/40000, alpha = 1.00586\n",
      "\n",
      "Epoch: 13631/40000, total loss = 2.806, Fit loss U = 9.070, Fit loss F = 3.297, KL loss = 437.603\n",
      "Epoch: 13631/40000, alpha = 1.00583\n",
      "\n",
      "Epoch: 13641/40000, total loss = 2.772, Fit loss U = 8.458, Fit loss F = 3.297, KL loss = 436.822\n",
      "Epoch: 13641/40000, alpha = 1.00581\n",
      "\n",
      "Epoch: 13651/40000, total loss = 2.941, Fit loss U = 11.806, Fit loss F = 3.297, KL loss = 437.097\n",
      "Epoch: 13651/40000, alpha = 1.00578\n",
      "\n",
      "Epoch: 13661/40000, total loss = 2.818, Fit loss U = 9.311, Fit loss F = 3.296, KL loss = 437.539\n",
      "Epoch: 13661/40000, alpha = 1.00575\n",
      "\n",
      "Epoch: 13671/40000, total loss = 2.981, Fit loss U = 12.474, Fit loss F = 3.296, KL loss = 438.406\n",
      "Epoch: 13671/40000, alpha = 1.00573\n",
      "\n",
      "Epoch: 13681/40000, total loss = 2.694, Fit loss U = 6.680, Fit loss F = 3.296, KL loss = 439.146\n",
      "Epoch: 13681/40000, alpha = 1.00570\n",
      "\n",
      "Epoch: 13691/40000, total loss = 2.801, Fit loss U = 8.801, Fit loss F = 3.296, KL loss = 439.308\n",
      "Epoch: 13691/40000, alpha = 1.00567\n",
      "\n",
      "Epoch: 13701/40000, total loss = 2.801, Fit loss U = 8.850, Fit loss F = 3.295, KL loss = 438.718\n",
      "Epoch: 13701/40000, error_test = 1.01253, error_train = 1.02656\n",
      "Epoch: 13701/40000, error_f = 0.99999\n",
      "Epoch: 13701/40000, alpha = 1.00565\n",
      "\n",
      "Epoch: 13711/40000, total loss = 2.941, Fit loss U = 11.660, Fit loss F = 3.295, KL loss = 438.735\n",
      "Epoch: 13711/40000, alpha = 1.00562\n",
      "\n",
      "Epoch: 13721/40000, total loss = 2.812, Fit loss U = 9.055, Fit loss F = 3.294, KL loss = 438.822\n",
      "Epoch: 13721/40000, alpha = 1.00560\n",
      "\n",
      "Epoch: 13731/40000, total loss = 2.736, Fit loss U = 7.654, Fit loss F = 3.294, KL loss = 437.777\n",
      "Epoch: 13731/40000, alpha = 1.00557\n",
      "\n",
      "Epoch: 13741/40000, total loss = 2.830, Fit loss U = 9.480, Fit loss F = 3.294, KL loss = 438.348\n",
      "Epoch: 13741/40000, alpha = 1.00555\n",
      "\n",
      "Epoch: 13751/40000, total loss = 2.803, Fit loss U = 8.873, Fit loss F = 3.293, KL loss = 438.923\n",
      "Epoch: 13751/40000, alpha = 1.00552\n",
      "\n",
      "Epoch: 13761/40000, total loss = 2.704, Fit loss U = 6.829, Fit loss F = 3.293, KL loss = 439.555\n",
      "Epoch: 13761/40000, alpha = 1.00550\n",
      "\n",
      "Epoch: 13771/40000, total loss = 2.786, Fit loss U = 8.485, Fit loss F = 3.292, KL loss = 439.444\n",
      "Epoch: 13771/40000, alpha = 1.00547\n",
      "\n",
      "Epoch: 13781/40000, total loss = 2.784, Fit loss U = 8.527, Fit loss F = 3.292, KL loss = 438.565\n",
      "Epoch: 13781/40000, alpha = 1.00545\n",
      "\n",
      "Epoch: 13791/40000, total loss = 2.765, Fit loss U = 8.181, Fit loss F = 3.292, KL loss = 438.216\n",
      "Epoch: 13791/40000, alpha = 1.00542\n",
      "\n",
      "Epoch: 13801/40000, total loss = 2.822, Fit loss U = 9.377, Fit loss F = 3.292, KL loss = 437.774\n",
      "Epoch: 13801/40000, error_test = 0.99599, error_train = 1.01044\n",
      "Epoch: 13801/40000, error_f = 0.99999\n",
      "Epoch: 13801/40000, alpha = 1.00540\n",
      "\n",
      "Epoch: 13811/40000, total loss = 2.902, Fit loss U = 10.961, Fit loss F = 3.291, KL loss = 437.927\n",
      "Epoch: 13811/40000, alpha = 1.00537\n",
      "\n",
      "Epoch: 13821/40000, total loss = 2.860, Fit loss U = 9.994, Fit loss F = 3.291, KL loss = 439.084\n",
      "Epoch: 13821/40000, alpha = 1.00535\n",
      "\n",
      "Epoch: 13831/40000, total loss = 3.072, Fit loss U = 14.308, Fit loss F = 3.291, KL loss = 438.450\n",
      "Epoch: 13831/40000, alpha = 1.00532\n",
      "\n",
      "Epoch: 13841/40000, total loss = 2.795, Fit loss U = 8.701, Fit loss F = 3.290, KL loss = 439.076\n",
      "Epoch: 13841/40000, alpha = 1.00530\n",
      "\n",
      "Epoch: 13851/40000, total loss = 2.772, Fit loss U = 8.203, Fit loss F = 3.290, KL loss = 439.459\n",
      "Epoch: 13851/40000, alpha = 1.00527\n",
      "\n",
      "Epoch: 13861/40000, total loss = 2.876, Fit loss U = 10.213, Fit loss F = 3.290, KL loss = 440.102\n",
      "Epoch: 13861/40000, alpha = 1.00525\n",
      "\n",
      "Epoch: 13871/40000, total loss = 2.806, Fit loss U = 8.862, Fit loss F = 3.289, KL loss = 439.737\n",
      "Epoch: 13871/40000, alpha = 1.00523\n",
      "\n",
      "Epoch: 13881/40000, total loss = 2.848, Fit loss U = 9.657, Fit loss F = 3.289, KL loss = 440.099\n",
      "Epoch: 13881/40000, alpha = 1.00520\n",
      "\n",
      "Epoch: 13891/40000, total loss = 2.818, Fit loss U = 9.109, Fit loss F = 3.288, KL loss = 439.533\n",
      "Epoch: 13891/40000, alpha = 1.00518\n",
      "\n",
      "Epoch: 13901/40000, total loss = 2.827, Fit loss U = 9.187, Fit loss F = 3.288, KL loss = 440.651\n",
      "Epoch: 13901/40000, error_test = 0.97303, error_train = 0.98531\n",
      "Epoch: 13901/40000, error_f = 1.00000\n",
      "Epoch: 13901/40000, alpha = 1.00516\n",
      "\n",
      "Epoch: 13911/40000, total loss = 2.764, Fit loss U = 7.783, Fit loss F = 3.288, KL loss = 442.003\n",
      "Epoch: 13911/40000, alpha = 1.00513\n",
      "\n",
      "Epoch: 13921/40000, total loss = 2.838, Fit loss U = 9.346, Fit loss F = 3.288, KL loss = 441.202\n",
      "Epoch: 13921/40000, alpha = 1.00511\n",
      "\n",
      "Epoch: 13931/40000, total loss = 2.747, Fit loss U = 7.500, Fit loss F = 3.288, KL loss = 441.487\n",
      "Epoch: 13931/40000, alpha = 1.00509\n",
      "\n",
      "Epoch: 13941/40000, total loss = 3.024, Fit loss U = 13.060, Fit loss F = 3.287, KL loss = 441.404\n",
      "Epoch: 13941/40000, alpha = 1.00506\n",
      "\n",
      "Epoch: 13951/40000, total loss = 2.816, Fit loss U = 8.937, Fit loss F = 3.287, KL loss = 440.982\n",
      "Epoch: 13951/40000, alpha = 1.00504\n",
      "\n",
      "Epoch: 13961/40000, total loss = 2.638, Fit loss U = 5.429, Fit loss F = 3.286, KL loss = 440.392\n",
      "Epoch: 13961/40000, alpha = 1.00502\n",
      "\n",
      "Epoch: 13971/40000, total loss = 2.843, Fit loss U = 9.682, Fit loss F = 3.286, KL loss = 439.021\n",
      "Epoch: 13971/40000, alpha = 1.00499\n",
      "\n",
      "Epoch: 13981/40000, total loss = 2.761, Fit loss U = 8.075, Fit loss F = 3.286, KL loss = 438.678\n",
      "Epoch: 13981/40000, alpha = 1.00497\n",
      "\n",
      "Epoch: 13991/40000, total loss = 2.901, Fit loss U = 10.783, Fit loss F = 3.285, KL loss = 439.501\n",
      "Epoch: 13991/40000, alpha = 1.00495\n",
      "\n",
      "Epoch: 14001/40000, total loss = 2.794, Fit loss U = 8.663, Fit loss F = 3.285, KL loss = 439.307\n",
      "Epoch: 14001/40000, error_test = 1.03812, error_train = 1.01189\n",
      "Epoch: 14001/40000, error_f = 1.00000\n",
      "Epoch: 14001/40000, alpha = 1.00493\n",
      "\n",
      "Epoch: 14011/40000, total loss = 2.957, Fit loss U = 11.983, Fit loss F = 3.285, KL loss = 438.690\n",
      "Epoch: 14011/40000, alpha = 1.00491\n",
      "\n",
      "Epoch: 14021/40000, total loss = 2.832, Fit loss U = 9.388, Fit loss F = 3.285, KL loss = 439.683\n",
      "Epoch: 14021/40000, alpha = 1.00488\n",
      "\n",
      "Epoch: 14031/40000, total loss = 2.851, Fit loss U = 9.794, Fit loss F = 3.284, KL loss = 439.434\n",
      "Epoch: 14031/40000, alpha = 1.00486\n",
      "\n",
      "Epoch: 14041/40000, total loss = 2.733, Fit loss U = 7.350, Fit loss F = 3.284, KL loss = 440.241\n",
      "Epoch: 14041/40000, alpha = 1.00484\n",
      "\n",
      "Epoch: 14051/40000, total loss = 2.804, Fit loss U = 8.748, Fit loss F = 3.284, KL loss = 440.413\n",
      "Epoch: 14051/40000, alpha = 1.00482\n",
      "\n",
      "Epoch: 14061/40000, total loss = 2.927, Fit loss U = 11.294, Fit loss F = 3.283, KL loss = 439.687\n",
      "Epoch: 14061/40000, alpha = 1.00480\n",
      "\n",
      "Epoch: 14071/40000, total loss = 2.904, Fit loss U = 10.696, Fit loss F = 3.283, KL loss = 440.922\n",
      "Epoch: 14071/40000, alpha = 1.00477\n",
      "\n",
      "Epoch: 14081/40000, total loss = 3.029, Fit loss U = 13.130, Fit loss F = 3.283, KL loss = 441.726\n",
      "Epoch: 14081/40000, alpha = 1.00475\n",
      "\n",
      "Epoch: 14091/40000, total loss = 2.777, Fit loss U = 8.083, Fit loss F = 3.283, KL loss = 441.676\n",
      "Epoch: 14091/40000, alpha = 1.00473\n",
      "\n",
      "Epoch: 14101/40000, total loss = 2.960, Fit loss U = 11.963, Fit loss F = 3.282, KL loss = 439.459\n",
      "Epoch: 14101/40000, error_test = 0.97913, error_train = 0.95690\n",
      "Epoch: 14101/40000, error_f = 1.00000\n",
      "Epoch: 14101/40000, alpha = 1.00471\n",
      "\n",
      "Epoch: 14111/40000, total loss = 2.854, Fit loss U = 9.975, Fit loss F = 3.282, KL loss = 438.198\n",
      "Epoch: 14111/40000, alpha = 1.00469\n",
      "\n",
      "Epoch: 14121/40000, total loss = 2.820, Fit loss U = 9.325, Fit loss F = 3.282, KL loss = 437.934\n",
      "Epoch: 14121/40000, alpha = 1.00467\n",
      "\n",
      "Epoch: 14131/40000, total loss = 2.705, Fit loss U = 6.963, Fit loss F = 3.281, KL loss = 438.516\n",
      "Epoch: 14131/40000, alpha = 1.00465\n",
      "\n",
      "Epoch: 14141/40000, total loss = 2.781, Fit loss U = 8.504, Fit loss F = 3.281, KL loss = 438.404\n",
      "Epoch: 14141/40000, alpha = 1.00462\n",
      "\n",
      "Epoch: 14151/40000, total loss = 2.837, Fit loss U = 9.662, Fit loss F = 3.281, KL loss = 437.892\n",
      "Epoch: 14151/40000, alpha = 1.00460\n",
      "\n",
      "Epoch: 14161/40000, total loss = 2.870, Fit loss U = 10.309, Fit loss F = 3.281, KL loss = 438.138\n",
      "Epoch: 14161/40000, alpha = 1.00458\n",
      "\n",
      "Epoch: 14171/40000, total loss = 2.888, Fit loss U = 10.626, Fit loss F = 3.280, KL loss = 438.617\n",
      "Epoch: 14171/40000, alpha = 1.00456\n",
      "\n",
      "Epoch: 14181/40000, total loss = 2.788, Fit loss U = 8.617, Fit loss F = 3.280, KL loss = 438.547\n",
      "Epoch: 14181/40000, alpha = 1.00454\n",
      "\n",
      "Epoch: 14191/40000, total loss = 2.820, Fit loss U = 9.320, Fit loss F = 3.279, KL loss = 438.013\n",
      "Epoch: 14191/40000, alpha = 1.00452\n",
      "\n",
      "Epoch: 14201/40000, total loss = 2.734, Fit loss U = 7.547, Fit loss F = 3.280, KL loss = 438.560\n",
      "Epoch: 14201/40000, error_test = 1.01712, error_train = 1.01529\n",
      "Epoch: 14201/40000, error_f = 1.00000\n",
      "Epoch: 14201/40000, alpha = 1.00450\n",
      "\n",
      "Epoch: 14211/40000, total loss = 2.710, Fit loss U = 7.133, Fit loss F = 3.279, KL loss = 437.875\n",
      "Epoch: 14211/40000, alpha = 1.00448\n",
      "\n",
      "Epoch: 14221/40000, total loss = 2.752, Fit loss U = 8.026, Fit loss F = 3.279, KL loss = 437.328\n",
      "Epoch: 14221/40000, alpha = 1.00446\n",
      "\n",
      "Epoch: 14231/40000, total loss = 2.807, Fit loss U = 9.011, Fit loss F = 3.279, KL loss = 438.408\n",
      "Epoch: 14231/40000, alpha = 1.00444\n",
      "\n",
      "Epoch: 14241/40000, total loss = 2.694, Fit loss U = 6.681, Fit loss F = 3.278, KL loss = 439.206\n",
      "Epoch: 14241/40000, alpha = 1.00442\n",
      "\n",
      "Epoch: 14251/40000, total loss = 2.724, Fit loss U = 7.234, Fit loss F = 3.278, KL loss = 439.579\n",
      "Epoch: 14251/40000, alpha = 1.00440\n",
      "\n",
      "Epoch: 14261/40000, total loss = 2.922, Fit loss U = 11.230, Fit loss F = 3.278, KL loss = 439.369\n",
      "Epoch: 14261/40000, alpha = 1.00438\n",
      "\n",
      "Epoch: 14271/40000, total loss = 2.722, Fit loss U = 7.181, Fit loss F = 3.277, KL loss = 439.744\n",
      "Epoch: 14271/40000, alpha = 1.00436\n",
      "\n",
      "Epoch: 14281/40000, total loss = 2.694, Fit loss U = 6.664, Fit loss F = 3.277, KL loss = 439.298\n",
      "Epoch: 14281/40000, alpha = 1.00434\n",
      "\n",
      "Epoch: 14291/40000, total loss = 2.837, Fit loss U = 9.620, Fit loss F = 3.277, KL loss = 438.399\n",
      "Epoch: 14291/40000, alpha = 1.00432\n",
      "\n",
      "Epoch: 14301/40000, total loss = 2.832, Fit loss U = 9.480, Fit loss F = 3.277, KL loss = 438.760\n",
      "Epoch: 14301/40000, error_test = 0.98363, error_train = 1.01660\n",
      "Epoch: 14301/40000, error_f = 1.00000\n",
      "Epoch: 14301/40000, alpha = 1.00430\n",
      "\n",
      "Epoch: 14311/40000, total loss = 2.781, Fit loss U = 8.544, Fit loss F = 3.276, KL loss = 438.033\n",
      "Epoch: 14311/40000, alpha = 1.00428\n",
      "\n",
      "Epoch: 14321/40000, total loss = 2.952, Fit loss U = 11.954, Fit loss F = 3.276, KL loss = 438.137\n",
      "Epoch: 14321/40000, alpha = 1.00426\n",
      "\n",
      "Epoch: 14331/40000, total loss = 2.774, Fit loss U = 8.230, Fit loss F = 3.276, KL loss = 439.697\n",
      "Epoch: 14331/40000, alpha = 1.00425\n",
      "\n",
      "Epoch: 14341/40000, total loss = 2.777, Fit loss U = 8.308, Fit loss F = 3.276, KL loss = 439.530\n",
      "Epoch: 14341/40000, alpha = 1.00423\n",
      "\n",
      "Epoch: 14351/40000, total loss = 2.719, Fit loss U = 7.308, Fit loss F = 3.275, KL loss = 437.978\n",
      "Epoch: 14351/40000, alpha = 1.00421\n",
      "\n",
      "Epoch: 14361/40000, total loss = 2.772, Fit loss U = 8.394, Fit loss F = 3.275, KL loss = 437.774\n",
      "Epoch: 14361/40000, alpha = 1.00419\n",
      "\n",
      "Epoch: 14371/40000, total loss = 2.778, Fit loss U = 8.482, Fit loss F = 3.275, KL loss = 438.099\n",
      "Epoch: 14371/40000, alpha = 1.00417\n",
      "\n",
      "Epoch: 14381/40000, total loss = 2.778, Fit loss U = 8.478, Fit loss F = 3.275, KL loss = 438.029\n",
      "Epoch: 14381/40000, alpha = 1.00415\n",
      "\n",
      "Epoch: 14391/40000, total loss = 2.851, Fit loss U = 9.994, Fit loss F = 3.274, KL loss = 437.575\n",
      "Epoch: 14391/40000, alpha = 1.00413\n",
      "\n",
      "Epoch: 14401/40000, total loss = 2.763, Fit loss U = 8.216, Fit loss F = 3.274, KL loss = 437.649\n",
      "Epoch: 14401/40000, error_test = 1.03281, error_train = 1.01199\n",
      "Epoch: 14401/40000, error_f = 1.00000\n",
      "Epoch: 14401/40000, alpha = 1.00411\n",
      "\n",
      "Epoch: 14411/40000, total loss = 2.749, Fit loss U = 7.887, Fit loss F = 3.274, KL loss = 438.201\n",
      "Epoch: 14411/40000, alpha = 1.00410\n",
      "\n",
      "Epoch: 14421/40000, total loss = 2.898, Fit loss U = 10.853, Fit loss F = 3.274, KL loss = 438.344\n",
      "Epoch: 14421/40000, alpha = 1.00408\n",
      "\n",
      "Epoch: 14431/40000, total loss = 2.897, Fit loss U = 10.721, Fit loss F = 3.273, KL loss = 439.369\n",
      "Epoch: 14431/40000, alpha = 1.00406\n",
      "\n",
      "Epoch: 14441/40000, total loss = 2.777, Fit loss U = 8.315, Fit loss F = 3.273, KL loss = 439.563\n",
      "Epoch: 14441/40000, alpha = 1.00404\n",
      "\n",
      "Epoch: 14451/40000, total loss = 2.857, Fit loss U = 9.938, Fit loss F = 3.273, KL loss = 439.284\n",
      "Epoch: 14451/40000, alpha = 1.00402\n",
      "\n",
      "Epoch: 14461/40000, total loss = 2.772, Fit loss U = 8.290, Fit loss F = 3.273, KL loss = 438.784\n",
      "Epoch: 14461/40000, alpha = 1.00400\n",
      "\n",
      "Epoch: 14471/40000, total loss = 2.792, Fit loss U = 8.789, Fit loss F = 3.272, KL loss = 437.869\n",
      "Epoch: 14471/40000, alpha = 1.00399\n",
      "\n",
      "Epoch: 14481/40000, total loss = 2.895, Fit loss U = 10.779, Fit loss F = 3.272, KL loss = 438.455\n",
      "Epoch: 14481/40000, alpha = 1.00397\n",
      "\n",
      "Epoch: 14491/40000, total loss = 2.805, Fit loss U = 8.868, Fit loss F = 3.272, KL loss = 439.628\n",
      "Epoch: 14491/40000, alpha = 1.00395\n",
      "\n",
      "Epoch: 14501/40000, total loss = 2.847, Fit loss U = 9.772, Fit loss F = 3.272, KL loss = 438.867\n",
      "Epoch: 14501/40000, error_test = 1.03169, error_train = 1.00251\n",
      "Epoch: 14501/40000, error_f = 0.99999\n",
      "Epoch: 14501/40000, alpha = 1.00393\n",
      "\n",
      "Epoch: 14511/40000, total loss = 2.810, Fit loss U = 9.024, Fit loss F = 3.271, KL loss = 438.962\n",
      "Epoch: 14511/40000, alpha = 1.00392\n",
      "\n",
      "Epoch: 14521/40000, total loss = 2.845, Fit loss U = 9.707, Fit loss F = 3.271, KL loss = 439.255\n",
      "Epoch: 14521/40000, alpha = 1.00390\n",
      "\n",
      "Epoch: 14531/40000, total loss = 2.776, Fit loss U = 8.382, Fit loss F = 3.271, KL loss = 438.572\n",
      "Epoch: 14531/40000, alpha = 1.00388\n",
      "\n",
      "Epoch: 14541/40000, total loss = 2.673, Fit loss U = 6.346, Fit loss F = 3.271, KL loss = 438.367\n",
      "Epoch: 14541/40000, alpha = 1.00386\n",
      "\n",
      "Epoch: 14551/40000, total loss = 2.901, Fit loss U = 10.982, Fit loss F = 3.270, KL loss = 437.634\n",
      "Epoch: 14551/40000, alpha = 1.00385\n",
      "\n",
      "Epoch: 14561/40000, total loss = 2.877, Fit loss U = 10.514, Fit loss F = 3.270, KL loss = 437.649\n",
      "Epoch: 14561/40000, alpha = 1.00383\n",
      "\n",
      "Epoch: 14571/40000, total loss = 2.844, Fit loss U = 9.826, Fit loss F = 3.270, KL loss = 437.895\n",
      "Epoch: 14571/40000, alpha = 1.00381\n",
      "\n",
      "Epoch: 14581/40000, total loss = 2.853, Fit loss U = 9.819, Fit loss F = 3.270, KL loss = 439.726\n",
      "Epoch: 14581/40000, alpha = 1.00379\n",
      "\n",
      "Epoch: 14591/40000, total loss = 2.766, Fit loss U = 7.980, Fit loss F = 3.269, KL loss = 440.637\n",
      "Epoch: 14591/40000, alpha = 1.00378\n",
      "\n",
      "Epoch: 14601/40000, total loss = 2.899, Fit loss U = 10.690, Fit loss F = 3.269, KL loss = 440.280\n",
      "Epoch: 14601/40000, error_test = 1.01939, error_train = 1.01761\n",
      "Epoch: 14601/40000, error_f = 1.00000\n",
      "Epoch: 14601/40000, alpha = 1.00376\n",
      "\n",
      "Epoch: 14611/40000, total loss = 2.877, Fit loss U = 10.232, Fit loss F = 3.269, KL loss = 440.301\n",
      "Epoch: 14611/40000, alpha = 1.00374\n",
      "\n",
      "Epoch: 14621/40000, total loss = 2.781, Fit loss U = 8.339, Fit loss F = 3.269, KL loss = 440.056\n",
      "Epoch: 14621/40000, alpha = 1.00373\n",
      "\n",
      "Epoch: 14631/40000, total loss = 2.890, Fit loss U = 10.558, Fit loss F = 3.269, KL loss = 439.685\n",
      "Epoch: 14631/40000, alpha = 1.00371\n",
      "\n",
      "Epoch: 14641/40000, total loss = 2.772, Fit loss U = 8.292, Fit loss F = 3.269, KL loss = 438.723\n",
      "Epoch: 14641/40000, alpha = 1.00369\n",
      "\n",
      "Epoch: 14651/40000, total loss = 2.813, Fit loss U = 9.193, Fit loss F = 3.268, KL loss = 438.015\n",
      "Epoch: 14651/40000, alpha = 1.00368\n",
      "\n",
      "Epoch: 14661/40000, total loss = 2.782, Fit loss U = 8.603, Fit loss F = 3.268, KL loss = 437.601\n",
      "Epoch: 14661/40000, alpha = 1.00366\n",
      "\n",
      "Epoch: 14671/40000, total loss = 2.744, Fit loss U = 7.833, Fit loss F = 3.268, KL loss = 437.788\n",
      "Epoch: 14671/40000, alpha = 1.00364\n",
      "\n",
      "Epoch: 14681/40000, total loss = 2.970, Fit loss U = 12.338, Fit loss F = 3.268, KL loss = 437.884\n",
      "Epoch: 14681/40000, alpha = 1.00363\n",
      "\n",
      "Epoch: 14691/40000, total loss = 2.905, Fit loss U = 10.727, Fit loss F = 3.267, KL loss = 441.010\n",
      "Epoch: 14691/40000, alpha = 1.00361\n",
      "\n",
      "Epoch: 14701/40000, total loss = 2.780, Fit loss U = 8.179, Fit loss F = 3.267, KL loss = 441.482\n",
      "Epoch: 14701/40000, error_test = 0.98476, error_train = 1.02212\n",
      "Epoch: 14701/40000, error_f = 1.00000\n",
      "Epoch: 14701/40000, alpha = 1.00360\n",
      "\n",
      "Epoch: 14711/40000, total loss = 2.795, Fit loss U = 8.532, Fit loss F = 3.267, KL loss = 441.002\n",
      "Epoch: 14711/40000, alpha = 1.00358\n",
      "\n",
      "Epoch: 14721/40000, total loss = 2.787, Fit loss U = 8.476, Fit loss F = 3.267, KL loss = 439.888\n",
      "Epoch: 14721/40000, alpha = 1.00356\n",
      "\n",
      "Epoch: 14731/40000, total loss = 2.748, Fit loss U = 7.756, Fit loss F = 3.266, KL loss = 439.430\n",
      "Epoch: 14731/40000, alpha = 1.00355\n",
      "\n",
      "Epoch: 14741/40000, total loss = 2.813, Fit loss U = 9.102, Fit loss F = 3.266, KL loss = 438.949\n",
      "Epoch: 14741/40000, alpha = 1.00353\n",
      "\n",
      "Epoch: 14751/40000, total loss = 2.939, Fit loss U = 11.744, Fit loss F = 3.266, KL loss = 437.775\n",
      "Epoch: 14751/40000, alpha = 1.00352\n",
      "\n",
      "Epoch: 14761/40000, total loss = 2.639, Fit loss U = 5.781, Fit loss F = 3.266, KL loss = 437.321\n",
      "Epoch: 14761/40000, alpha = 1.00350\n",
      "\n",
      "Epoch: 14771/40000, total loss = 2.851, Fit loss U = 10.132, Fit loss F = 3.266, KL loss = 436.314\n",
      "Epoch: 14771/40000, alpha = 1.00349\n",
      "\n",
      "Epoch: 14781/40000, total loss = 2.918, Fit loss U = 11.443, Fit loss F = 3.266, KL loss = 436.505\n",
      "Epoch: 14781/40000, alpha = 1.00347\n",
      "\n",
      "Epoch: 14791/40000, total loss = 2.682, Fit loss U = 6.623, Fit loss F = 3.265, KL loss = 437.491\n",
      "Epoch: 14791/40000, alpha = 1.00345\n",
      "\n",
      "Epoch: 14801/40000, total loss = 2.756, Fit loss U = 8.154, Fit loss F = 3.265, KL loss = 437.106\n",
      "Epoch: 14801/40000, error_test = 1.01182, error_train = 1.04568\n",
      "Epoch: 14801/40000, error_f = 1.00001\n",
      "Epoch: 14801/40000, alpha = 1.00344\n",
      "\n",
      "Epoch: 14811/40000, total loss = 2.824, Fit loss U = 9.433, Fit loss F = 3.265, KL loss = 437.744\n",
      "Epoch: 14811/40000, alpha = 1.00342\n",
      "\n",
      "Epoch: 14821/40000, total loss = 2.853, Fit loss U = 10.019, Fit loss F = 3.265, KL loss = 437.835\n",
      "Epoch: 14821/40000, alpha = 1.00341\n",
      "\n",
      "Epoch: 14831/40000, total loss = 2.801, Fit loss U = 8.993, Fit loss F = 3.264, KL loss = 437.543\n",
      "Epoch: 14831/40000, alpha = 1.00339\n",
      "\n",
      "Epoch: 14841/40000, total loss = 2.874, Fit loss U = 10.479, Fit loss F = 3.264, KL loss = 437.464\n",
      "Epoch: 14841/40000, alpha = 1.00338\n",
      "\n",
      "Epoch: 14851/40000, total loss = 2.749, Fit loss U = 8.078, Fit loss F = 3.264, KL loss = 436.309\n",
      "Epoch: 14851/40000, alpha = 1.00336\n",
      "\n",
      "Epoch: 14861/40000, total loss = 2.689, Fit loss U = 6.982, Fit loss F = 3.264, KL loss = 435.283\n",
      "Epoch: 14861/40000, alpha = 1.00335\n",
      "\n",
      "Epoch: 14871/40000, total loss = 2.858, Fit loss U = 10.414, Fit loss F = 3.264, KL loss = 434.909\n",
      "Epoch: 14871/40000, alpha = 1.00333\n",
      "\n",
      "Epoch: 14881/40000, total loss = 2.730, Fit loss U = 7.740, Fit loss F = 3.263, KL loss = 435.934\n",
      "Epoch: 14881/40000, alpha = 1.00332\n",
      "\n",
      "Epoch: 14891/40000, total loss = 2.728, Fit loss U = 7.648, Fit loss F = 3.263, KL loss = 436.439\n",
      "Epoch: 14891/40000, alpha = 1.00330\n",
      "\n",
      "Epoch: 14901/40000, total loss = 2.834, Fit loss U = 9.719, Fit loss F = 3.263, KL loss = 437.000\n",
      "Epoch: 14901/40000, error_test = 0.98352, error_train = 1.00820\n",
      "Epoch: 14901/40000, error_f = 1.00001\n",
      "Epoch: 14901/40000, alpha = 1.00329\n",
      "\n",
      "Epoch: 14911/40000, total loss = 2.842, Fit loss U = 9.888, Fit loss F = 3.263, KL loss = 436.911\n",
      "Epoch: 14911/40000, alpha = 1.00327\n",
      "\n",
      "Epoch: 14921/40000, total loss = 2.770, Fit loss U = 8.506, Fit loss F = 3.263, KL loss = 436.330\n",
      "Epoch: 14921/40000, alpha = 1.00326\n",
      "\n",
      "Epoch: 14931/40000, total loss = 2.824, Fit loss U = 9.578, Fit loss F = 3.262, KL loss = 436.483\n",
      "Epoch: 14931/40000, alpha = 1.00325\n",
      "\n",
      "Epoch: 14941/40000, total loss = 2.743, Fit loss U = 8.015, Fit loss F = 3.262, KL loss = 435.823\n",
      "Epoch: 14941/40000, alpha = 1.00323\n",
      "\n",
      "Epoch: 14951/40000, total loss = 2.789, Fit loss U = 8.903, Fit loss F = 3.262, KL loss = 436.214\n",
      "Epoch: 14951/40000, alpha = 1.00322\n",
      "\n",
      "Epoch: 14961/40000, total loss = 2.830, Fit loss U = 9.605, Fit loss F = 3.262, KL loss = 437.318\n",
      "Epoch: 14961/40000, alpha = 1.00320\n",
      "\n",
      "Epoch: 14971/40000, total loss = 2.729, Fit loss U = 7.505, Fit loss F = 3.261, KL loss = 438.158\n",
      "Epoch: 14971/40000, alpha = 1.00319\n",
      "\n",
      "Epoch: 14981/40000, total loss = 2.672, Fit loss U = 6.393, Fit loss F = 3.261, KL loss = 437.777\n",
      "Epoch: 14981/40000, alpha = 1.00317\n",
      "\n",
      "Epoch: 14991/40000, total loss = 2.773, Fit loss U = 8.369, Fit loss F = 3.261, KL loss = 438.329\n",
      "Epoch: 14991/40000, alpha = 1.00316\n",
      "\n",
      "Epoch: 15001/40000, total loss = 2.888, Fit loss U = 10.750, Fit loss F = 3.261, KL loss = 437.508\n",
      "Epoch: 15001/40000, error_test = 0.98341, error_train = 1.01187\n",
      "Epoch: 15001/40000, error_f = 1.00000\n",
      "Epoch: 15001/40000, alpha = 1.00315\n",
      "\n",
      "Epoch: 15011/40000, total loss = 2.746, Fit loss U = 7.840, Fit loss F = 3.261, KL loss = 438.236\n",
      "Epoch: 15011/40000, alpha = 1.00313\n",
      "\n",
      "Epoch: 15021/40000, total loss = 2.957, Fit loss U = 12.104, Fit loss F = 3.261, KL loss = 437.724\n",
      "Epoch: 15021/40000, alpha = 1.00312\n",
      "\n",
      "Epoch: 15031/40000, total loss = 2.982, Fit loss U = 12.600, Fit loss F = 3.261, KL loss = 437.863\n",
      "Epoch: 15031/40000, alpha = 1.00310\n",
      "\n",
      "Epoch: 15041/40000, total loss = 2.682, Fit loss U = 6.462, Fit loss F = 3.260, KL loss = 439.252\n",
      "Epoch: 15041/40000, alpha = 1.00309\n",
      "\n",
      "Epoch: 15051/40000, total loss = 2.750, Fit loss U = 7.805, Fit loss F = 3.260, KL loss = 439.292\n",
      "Epoch: 15051/40000, alpha = 1.00308\n",
      "\n",
      "Epoch: 15061/40000, total loss = 2.842, Fit loss U = 9.770, Fit loss F = 3.260, KL loss = 438.024\n",
      "Epoch: 15061/40000, alpha = 1.00306\n",
      "\n",
      "Epoch: 15071/40000, total loss = 2.818, Fit loss U = 9.339, Fit loss F = 3.260, KL loss = 437.537\n",
      "Epoch: 15071/40000, alpha = 1.00305\n",
      "\n",
      "Epoch: 15081/40000, total loss = 2.693, Fit loss U = 6.736, Fit loss F = 3.260, KL loss = 438.597\n",
      "Epoch: 15081/40000, alpha = 1.00304\n",
      "\n",
      "Epoch: 15091/40000, total loss = 2.795, Fit loss U = 8.728, Fit loss F = 3.259, KL loss = 439.156\n",
      "Epoch: 15091/40000, alpha = 1.00302\n",
      "\n",
      "Epoch: 15101/40000, total loss = 2.882, Fit loss U = 10.490, Fit loss F = 3.259, KL loss = 438.949\n",
      "Epoch: 15101/40000, error_test = 1.00313, error_train = 1.01049\n",
      "Epoch: 15101/40000, error_f = 1.00000\n",
      "Epoch: 15101/40000, alpha = 1.00301\n",
      "\n",
      "Epoch: 15111/40000, total loss = 2.825, Fit loss U = 9.316, Fit loss F = 3.259, KL loss = 439.350\n",
      "Epoch: 15111/40000, alpha = 1.00300\n",
      "\n",
      "Epoch: 15121/40000, total loss = 2.906, Fit loss U = 10.967, Fit loss F = 3.259, KL loss = 438.985\n",
      "Epoch: 15121/40000, alpha = 1.00298\n",
      "\n",
      "Epoch: 15131/40000, total loss = 2.729, Fit loss U = 7.450, Fit loss F = 3.259, KL loss = 438.742\n",
      "Epoch: 15131/40000, alpha = 1.00297\n",
      "\n",
      "Epoch: 15141/40000, total loss = 2.782, Fit loss U = 8.675, Fit loss F = 3.259, KL loss = 437.093\n",
      "Epoch: 15141/40000, alpha = 1.00296\n",
      "\n",
      "Epoch: 15151/40000, total loss = 2.679, Fit loss U = 6.714, Fit loss F = 3.258, KL loss = 436.159\n",
      "Epoch: 15151/40000, alpha = 1.00294\n",
      "\n",
      "Epoch: 15161/40000, total loss = 2.801, Fit loss U = 9.087, Fit loss F = 3.258, KL loss = 436.734\n",
      "Epoch: 15161/40000, alpha = 1.00293\n",
      "\n",
      "Epoch: 15171/40000, total loss = 2.737, Fit loss U = 7.787, Fit loss F = 3.258, KL loss = 436.950\n",
      "Epoch: 15171/40000, alpha = 1.00292\n",
      "\n",
      "Epoch: 15181/40000, total loss = 2.723, Fit loss U = 7.511, Fit loss F = 3.258, KL loss = 436.824\n",
      "Epoch: 15181/40000, alpha = 1.00291\n",
      "\n",
      "Epoch: 15191/40000, total loss = 2.841, Fit loss U = 9.899, Fit loss F = 3.258, KL loss = 436.713\n",
      "Epoch: 15191/40000, alpha = 1.00289\n",
      "\n",
      "Epoch: 15201/40000, total loss = 2.914, Fit loss U = 11.335, Fit loss F = 3.257, KL loss = 436.962\n",
      "Epoch: 15201/40000, error_test = 0.99547, error_train = 1.02083\n",
      "Epoch: 15201/40000, error_f = 1.00000\n",
      "Epoch: 15201/40000, alpha = 1.00288\n",
      "\n",
      "Epoch: 15211/40000, total loss = 2.782, Fit loss U = 8.584, Fit loss F = 3.257, KL loss = 438.042\n",
      "Epoch: 15211/40000, alpha = 1.00287\n",
      "\n",
      "Epoch: 15221/40000, total loss = 2.927, Fit loss U = 11.455, Fit loss F = 3.257, KL loss = 438.224\n",
      "Epoch: 15221/40000, alpha = 1.00285\n",
      "\n",
      "Epoch: 15231/40000, total loss = 2.872, Fit loss U = 10.303, Fit loss F = 3.257, KL loss = 438.730\n",
      "Epoch: 15231/40000, alpha = 1.00284\n",
      "\n",
      "Epoch: 15241/40000, total loss = 2.845, Fit loss U = 9.748, Fit loss F = 3.257, KL loss = 438.936\n",
      "Epoch: 15241/40000, alpha = 1.00283\n",
      "\n",
      "Epoch: 15251/40000, total loss = 2.712, Fit loss U = 7.101, Fit loss F = 3.257, KL loss = 438.731\n",
      "Epoch: 15251/40000, alpha = 1.00282\n",
      "\n",
      "Epoch: 15261/40000, total loss = 2.879, Fit loss U = 10.576, Fit loss F = 3.256, KL loss = 437.508\n",
      "Epoch: 15261/40000, alpha = 1.00280\n",
      "\n",
      "Epoch: 15271/40000, total loss = 2.852, Fit loss U = 10.135, Fit loss F = 3.256, KL loss = 436.449\n",
      "Epoch: 15271/40000, alpha = 1.00279\n",
      "\n",
      "Epoch: 15281/40000, total loss = 2.787, Fit loss U = 8.845, Fit loss F = 3.256, KL loss = 436.290\n",
      "Epoch: 15281/40000, alpha = 1.00278\n",
      "\n",
      "Epoch: 15291/40000, total loss = 2.653, Fit loss U = 6.247, Fit loss F = 3.256, KL loss = 435.607\n",
      "Epoch: 15291/40000, alpha = 1.00277\n",
      "\n",
      "Epoch: 15301/40000, total loss = 2.861, Fit loss U = 10.464, Fit loss F = 3.256, KL loss = 435.015\n",
      "Epoch: 15301/40000, error_test = 1.04078, error_train = 0.99394\n",
      "Epoch: 15301/40000, error_f = 1.00000\n",
      "Epoch: 15301/40000, alpha = 1.00276\n",
      "\n",
      "Epoch: 15311/40000, total loss = 2.864, Fit loss U = 10.366, Fit loss F = 3.256, KL loss = 436.539\n",
      "Epoch: 15311/40000, alpha = 1.00274\n",
      "\n",
      "Epoch: 15321/40000, total loss = 2.946, Fit loss U = 11.963, Fit loss F = 3.255, KL loss = 437.024\n",
      "Epoch: 15321/40000, alpha = 1.00273\n",
      "\n",
      "Epoch: 15331/40000, total loss = 2.765, Fit loss U = 8.188, Fit loss F = 3.255, KL loss = 438.540\n",
      "Epoch: 15331/40000, alpha = 1.00272\n",
      "\n",
      "Epoch: 15341/40000, total loss = 2.862, Fit loss U = 10.026, Fit loss F = 3.255, KL loss = 439.579\n",
      "Epoch: 15341/40000, alpha = 1.00271\n",
      "\n",
      "Epoch: 15351/40000, total loss = 2.855, Fit loss U = 10.003, Fit loss F = 3.255, KL loss = 438.511\n",
      "Epoch: 15351/40000, alpha = 1.00269\n",
      "\n",
      "Epoch: 15361/40000, total loss = 2.986, Fit loss U = 12.717, Fit loss F = 3.255, KL loss = 437.475\n",
      "Epoch: 15361/40000, alpha = 1.00268\n",
      "\n",
      "Epoch: 15371/40000, total loss = 2.905, Fit loss U = 11.138, Fit loss F = 3.254, KL loss = 437.029\n",
      "Epoch: 15371/40000, alpha = 1.00267\n",
      "\n",
      "Epoch: 15381/40000, total loss = 2.878, Fit loss U = 10.673, Fit loss F = 3.255, KL loss = 436.405\n",
      "Epoch: 15381/40000, alpha = 1.00266\n",
      "\n",
      "Epoch: 15391/40000, total loss = 2.924, Fit loss U = 11.572, Fit loss F = 3.254, KL loss = 436.548\n",
      "Epoch: 15391/40000, alpha = 1.00265\n",
      "\n",
      "Epoch: 15401/40000, total loss = 2.881, Fit loss U = 10.651, Fit loss F = 3.254, KL loss = 437.221\n",
      "Epoch: 15401/40000, error_test = 0.99794, error_train = 0.98152\n",
      "Epoch: 15401/40000, error_f = 1.00001\n",
      "Epoch: 15401/40000, alpha = 1.00264\n",
      "\n",
      "Epoch: 15411/40000, total loss = 2.762, Fit loss U = 8.329, Fit loss F = 3.254, KL loss = 436.604\n",
      "Epoch: 15411/40000, alpha = 1.00262\n",
      "\n",
      "Epoch: 15421/40000, total loss = 2.846, Fit loss U = 10.093, Fit loss F = 3.253, KL loss = 435.834\n",
      "Epoch: 15421/40000, alpha = 1.00261\n",
      "\n",
      "Epoch: 15431/40000, total loss = 2.812, Fit loss U = 9.384, Fit loss F = 3.254, KL loss = 435.935\n",
      "Epoch: 15431/40000, alpha = 1.00260\n",
      "\n",
      "Epoch: 15441/40000, total loss = 2.741, Fit loss U = 7.899, Fit loss F = 3.253, KL loss = 436.717\n",
      "Epoch: 15441/40000, alpha = 1.00259\n",
      "\n",
      "Epoch: 15451/40000, total loss = 2.767, Fit loss U = 8.472, Fit loss F = 3.253, KL loss = 436.052\n",
      "Epoch: 15451/40000, alpha = 1.00258\n",
      "\n",
      "Epoch: 15461/40000, total loss = 2.893, Fit loss U = 11.033, Fit loss F = 3.253, KL loss = 435.771\n",
      "Epoch: 15461/40000, alpha = 1.00257\n",
      "\n",
      "Epoch: 15471/40000, total loss = 2.802, Fit loss U = 9.174, Fit loss F = 3.253, KL loss = 436.193\n",
      "Epoch: 15471/40000, alpha = 1.00256\n",
      "\n",
      "Epoch: 15481/40000, total loss = 2.744, Fit loss U = 8.027, Fit loss F = 3.253, KL loss = 435.967\n",
      "Epoch: 15481/40000, alpha = 1.00254\n",
      "\n",
      "Epoch: 15491/40000, total loss = 2.918, Fit loss U = 11.442, Fit loss F = 3.253, KL loss = 436.692\n",
      "Epoch: 15491/40000, alpha = 1.00253\n",
      "\n",
      "Epoch: 15501/40000, total loss = 2.869, Fit loss U = 10.355, Fit loss F = 3.253, KL loss = 437.662\n",
      "Epoch: 15501/40000, error_test = 1.00330, error_train = 1.01469\n",
      "Epoch: 15501/40000, error_f = 1.00000\n",
      "Epoch: 15501/40000, alpha = 1.00252\n",
      "\n",
      "Epoch: 15511/40000, total loss = 2.860, Fit loss U = 10.187, Fit loss F = 3.252, KL loss = 437.615\n",
      "Epoch: 15511/40000, alpha = 1.00251\n",
      "\n",
      "Epoch: 15521/40000, total loss = 2.829, Fit loss U = 9.570, Fit loss F = 3.252, KL loss = 437.513\n",
      "Epoch: 15521/40000, alpha = 1.00250\n",
      "\n",
      "Epoch: 15531/40000, total loss = 2.591, Fit loss U = 4.853, Fit loss F = 3.252, KL loss = 437.165\n",
      "Epoch: 15531/40000, alpha = 1.00249\n",
      "\n",
      "Epoch: 15541/40000, total loss = 2.852, Fit loss U = 9.927, Fit loss F = 3.252, KL loss = 438.583\n",
      "Epoch: 15541/40000, alpha = 1.00248\n",
      "\n",
      "Epoch: 15551/40000, total loss = 2.845, Fit loss U = 9.679, Fit loss F = 3.252, KL loss = 439.755\n",
      "Epoch: 15551/40000, alpha = 1.00247\n",
      "\n",
      "Epoch: 15561/40000, total loss = 2.711, Fit loss U = 6.901, Fit loss F = 3.252, KL loss = 440.758\n",
      "Epoch: 15561/40000, alpha = 1.00246\n",
      "\n",
      "Epoch: 15571/40000, total loss = 2.959, Fit loss U = 11.891, Fit loss F = 3.251, KL loss = 440.466\n",
      "Epoch: 15571/40000, alpha = 1.00245\n",
      "\n",
      "Epoch: 15581/40000, total loss = 2.896, Fit loss U = 10.564, Fit loss F = 3.251, KL loss = 441.115\n",
      "Epoch: 15581/40000, alpha = 1.00244\n",
      "\n",
      "Epoch: 15591/40000, total loss = 2.752, Fit loss U = 7.822, Fit loss F = 3.251, KL loss = 439.715\n",
      "Epoch: 15591/40000, alpha = 1.00242\n",
      "\n",
      "Epoch: 15601/40000, total loss = 2.838, Fit loss U = 9.683, Fit loss F = 3.251, KL loss = 438.181\n",
      "Epoch: 15601/40000, error_test = 1.02944, error_train = 1.03378\n",
      "Epoch: 15601/40000, error_f = 1.00000\n",
      "Epoch: 15601/40000, alpha = 1.00241\n",
      "\n",
      "Epoch: 15611/40000, total loss = 2.880, Fit loss U = 10.626, Fit loss F = 3.251, KL loss = 437.218\n",
      "Epoch: 15611/40000, alpha = 1.00240\n",
      "\n",
      "Epoch: 15621/40000, total loss = 2.787, Fit loss U = 8.736, Fit loss F = 3.251, KL loss = 437.617\n",
      "Epoch: 15621/40000, alpha = 1.00239\n",
      "\n",
      "Epoch: 15631/40000, total loss = 2.704, Fit loss U = 7.078, Fit loss F = 3.251, KL loss = 437.494\n",
      "Epoch: 15631/40000, alpha = 1.00238\n",
      "\n",
      "Epoch: 15641/40000, total loss = 2.744, Fit loss U = 7.851, Fit loss F = 3.251, KL loss = 437.729\n",
      "Epoch: 15641/40000, alpha = 1.00237\n",
      "\n",
      "Epoch: 15651/40000, total loss = 2.819, Fit loss U = 9.380, Fit loss F = 3.251, KL loss = 437.539\n",
      "Epoch: 15651/40000, alpha = 1.00236\n",
      "\n",
      "Epoch: 15661/40000, total loss = 2.885, Fit loss U = 10.685, Fit loss F = 3.250, KL loss = 437.719\n",
      "Epoch: 15661/40000, alpha = 1.00235\n",
      "\n",
      "Epoch: 15671/40000, total loss = 2.836, Fit loss U = 9.654, Fit loss F = 3.250, KL loss = 438.083\n",
      "Epoch: 15671/40000, alpha = 1.00234\n",
      "\n",
      "Epoch: 15681/40000, total loss = 2.771, Fit loss U = 8.363, Fit loss F = 3.250, KL loss = 437.985\n",
      "Epoch: 15681/40000, alpha = 1.00233\n",
      "\n",
      "Epoch: 15691/40000, total loss = 2.791, Fit loss U = 8.790, Fit loss F = 3.250, KL loss = 437.786\n",
      "Epoch: 15691/40000, alpha = 1.00232\n",
      "\n",
      "Epoch: 15701/40000, total loss = 2.826, Fit loss U = 9.509, Fit loss F = 3.250, KL loss = 437.528\n",
      "Epoch: 15701/40000, error_test = 0.97944, error_train = 0.97489\n",
      "Epoch: 15701/40000, error_f = 1.00000\n",
      "Epoch: 15701/40000, alpha = 1.00231\n",
      "\n",
      "Epoch: 15711/40000, total loss = 2.895, Fit loss U = 10.965, Fit loss F = 3.250, KL loss = 436.839\n",
      "Epoch: 15711/40000, alpha = 1.00230\n",
      "\n",
      "Epoch: 15721/40000, total loss = 2.708, Fit loss U = 7.225, Fit loss F = 3.250, KL loss = 436.857\n",
      "Epoch: 15721/40000, alpha = 1.00229\n",
      "\n",
      "Epoch: 15731/40000, total loss = 2.757, Fit loss U = 8.143, Fit loss F = 3.250, KL loss = 437.450\n",
      "Epoch: 15731/40000, alpha = 1.00228\n",
      "\n",
      "Epoch: 15741/40000, total loss = 2.843, Fit loss U = 9.749, Fit loss F = 3.249, KL loss = 438.602\n",
      "Epoch: 15741/40000, alpha = 1.00227\n",
      "\n",
      "Epoch: 15751/40000, total loss = 2.923, Fit loss U = 11.326, Fit loss F = 3.249, KL loss = 438.775\n",
      "Epoch: 15751/40000, alpha = 1.00226\n",
      "\n",
      "Epoch: 15761/40000, total loss = 2.734, Fit loss U = 7.554, Fit loss F = 3.249, KL loss = 438.826\n",
      "Epoch: 15761/40000, alpha = 1.00225\n",
      "\n",
      "Epoch: 15771/40000, total loss = 2.907, Fit loss U = 10.918, Fit loss F = 3.249, KL loss = 439.683\n",
      "Epoch: 15771/40000, alpha = 1.00224\n",
      "\n",
      "Epoch: 15781/40000, total loss = 2.799, Fit loss U = 8.667, Fit loss F = 3.249, KL loss = 440.652\n",
      "Epoch: 15781/40000, alpha = 1.00223\n",
      "\n",
      "Epoch: 15791/40000, total loss = 2.741, Fit loss U = 7.539, Fit loss F = 3.248, KL loss = 440.236\n",
      "Epoch: 15791/40000, alpha = 1.00222\n",
      "\n",
      "Epoch: 15801/40000, total loss = 2.946, Fit loss U = 11.722, Fit loss F = 3.248, KL loss = 439.472\n",
      "Epoch: 15801/40000, error_test = 0.99880, error_train = 1.03725\n",
      "Epoch: 15801/40000, error_f = 0.99999\n",
      "Epoch: 15801/40000, alpha = 1.00221\n",
      "\n",
      "Epoch: 15811/40000, total loss = 2.722, Fit loss U = 7.311, Fit loss F = 3.248, KL loss = 438.784\n",
      "Epoch: 15811/40000, alpha = 1.00220\n",
      "\n",
      "Epoch: 15821/40000, total loss = 2.788, Fit loss U = 8.622, Fit loss F = 3.248, KL loss = 438.889\n",
      "Epoch: 15821/40000, alpha = 1.00219\n",
      "\n",
      "Epoch: 15831/40000, total loss = 2.999, Fit loss U = 12.803, Fit loss F = 3.248, KL loss = 439.346\n",
      "Epoch: 15831/40000, alpha = 1.00218\n",
      "\n",
      "Epoch: 15841/40000, total loss = 2.798, Fit loss U = 8.736, Fit loss F = 3.248, KL loss = 439.731\n",
      "Epoch: 15841/40000, alpha = 1.00217\n",
      "\n",
      "Epoch: 15851/40000, total loss = 2.780, Fit loss U = 8.453, Fit loss F = 3.247, KL loss = 438.955\n",
      "Epoch: 15851/40000, alpha = 1.00216\n",
      "\n",
      "Epoch: 15861/40000, total loss = 2.802, Fit loss U = 8.927, Fit loss F = 3.247, KL loss = 438.725\n",
      "Epoch: 15861/40000, alpha = 1.00215\n",
      "\n",
      "Epoch: 15871/40000, total loss = 2.748, Fit loss U = 7.820, Fit loss F = 3.247, KL loss = 438.990\n",
      "Epoch: 15871/40000, alpha = 1.00214\n",
      "\n",
      "Epoch: 15881/40000, total loss = 2.716, Fit loss U = 7.137, Fit loss F = 3.247, KL loss = 439.412\n",
      "Epoch: 15881/40000, alpha = 1.00214\n",
      "\n",
      "Epoch: 15891/40000, total loss = 2.838, Fit loss U = 9.579, Fit loss F = 3.247, KL loss = 439.287\n",
      "Epoch: 15891/40000, alpha = 1.00213\n",
      "\n",
      "Epoch: 15901/40000, total loss = 2.847, Fit loss U = 9.807, Fit loss F = 3.247, KL loss = 438.832\n",
      "Epoch: 15901/40000, error_test = 1.04471, error_train = 1.04001\n",
      "Epoch: 15901/40000, error_f = 1.00000\n",
      "Epoch: 15901/40000, alpha = 1.00212\n",
      "\n",
      "Epoch: 15911/40000, total loss = 2.795, Fit loss U = 8.836, Fit loss F = 3.247, KL loss = 438.188\n",
      "Epoch: 15911/40000, alpha = 1.00211\n",
      "\n",
      "Epoch: 15921/40000, total loss = 2.845, Fit loss U = 9.937, Fit loss F = 3.247, KL loss = 437.063\n",
      "Epoch: 15921/40000, alpha = 1.00210\n",
      "\n",
      "Epoch: 15931/40000, total loss = 2.760, Fit loss U = 8.323, Fit loss F = 3.247, KL loss = 436.286\n",
      "Epoch: 15931/40000, alpha = 1.00209\n",
      "\n",
      "Epoch: 15941/40000, total loss = 2.863, Fit loss U = 10.414, Fit loss F = 3.247, KL loss = 435.962\n",
      "Epoch: 15941/40000, alpha = 1.00208\n",
      "\n",
      "Epoch: 15951/40000, total loss = 2.814, Fit loss U = 9.297, Fit loss F = 3.246, KL loss = 437.278\n",
      "Epoch: 15951/40000, alpha = 1.00207\n",
      "\n",
      "Epoch: 15961/40000, total loss = 2.769, Fit loss U = 8.382, Fit loss F = 3.246, KL loss = 437.547\n",
      "Epoch: 15961/40000, alpha = 1.00206\n",
      "\n",
      "Epoch: 15971/40000, total loss = 2.771, Fit loss U = 8.481, Fit loss F = 3.246, KL loss = 436.949\n",
      "Epoch: 15971/40000, alpha = 1.00205\n",
      "\n",
      "Epoch: 15981/40000, total loss = 2.814, Fit loss U = 9.357, Fit loss F = 3.246, KL loss = 436.757\n",
      "Epoch: 15981/40000, alpha = 1.00204\n",
      "\n",
      "Epoch: 15991/40000, total loss = 2.845, Fit loss U = 9.936, Fit loss F = 3.246, KL loss = 437.271\n",
      "Epoch: 15991/40000, alpha = 1.00204\n",
      "\n",
      "Epoch: 16001/40000, total loss = 2.740, Fit loss U = 7.755, Fit loss F = 3.246, KL loss = 438.055\n",
      "Epoch: 16001/40000, error_test = 1.03645, error_train = 1.01622\n",
      "Epoch: 16001/40000, error_f = 1.00001\n",
      "Epoch: 16001/40000, alpha = 1.00203\n",
      "\n",
      "Epoch: 16011/40000, total loss = 2.713, Fit loss U = 7.201, Fit loss F = 3.246, KL loss = 438.080\n",
      "Epoch: 16011/40000, alpha = 1.00202\n",
      "\n",
      "Epoch: 16021/40000, total loss = 2.807, Fit loss U = 9.066, Fit loss F = 3.246, KL loss = 438.288\n",
      "Epoch: 16021/40000, alpha = 1.00201\n",
      "\n",
      "Epoch: 16031/40000, total loss = 2.970, Fit loss U = 12.285, Fit loss F = 3.245, KL loss = 438.647\n",
      "Epoch: 16031/40000, alpha = 1.00200\n",
      "\n",
      "Epoch: 16041/40000, total loss = 2.847, Fit loss U = 9.827, Fit loss F = 3.245, KL loss = 438.663\n",
      "Epoch: 16041/40000, alpha = 1.00199\n",
      "\n",
      "Epoch: 16051/40000, total loss = 2.761, Fit loss U = 8.030, Fit loss F = 3.245, KL loss = 439.434\n",
      "Epoch: 16051/40000, alpha = 1.00198\n",
      "\n",
      "Epoch: 16061/40000, total loss = 2.824, Fit loss U = 9.294, Fit loss F = 3.245, KL loss = 439.319\n",
      "Epoch: 16061/40000, alpha = 1.00197\n",
      "\n",
      "Epoch: 16071/40000, total loss = 2.716, Fit loss U = 7.216, Fit loss F = 3.245, KL loss = 438.682\n",
      "Epoch: 16071/40000, alpha = 1.00197\n",
      "\n",
      "Epoch: 16081/40000, total loss = 2.774, Fit loss U = 8.365, Fit loss F = 3.245, KL loss = 438.715\n",
      "Epoch: 16081/40000, alpha = 1.00196\n",
      "\n",
      "Epoch: 16091/40000, total loss = 2.792, Fit loss U = 8.803, Fit loss F = 3.245, KL loss = 437.987\n",
      "Epoch: 16091/40000, alpha = 1.00195\n",
      "\n",
      "Epoch: 16101/40000, total loss = 2.831, Fit loss U = 9.656, Fit loss F = 3.245, KL loss = 437.218\n",
      "Epoch: 16101/40000, error_test = 0.99923, error_train = 1.06732\n",
      "Epoch: 16101/40000, error_f = 1.00000\n",
      "Epoch: 16101/40000, alpha = 1.00194\n",
      "\n",
      "Epoch: 16111/40000, total loss = 2.769, Fit loss U = 8.331, Fit loss F = 3.245, KL loss = 438.111\n",
      "Epoch: 16111/40000, alpha = 1.00193\n",
      "\n",
      "Epoch: 16121/40000, total loss = 2.771, Fit loss U = 8.318, Fit loss F = 3.244, KL loss = 438.483\n",
      "Epoch: 16121/40000, alpha = 1.00192\n",
      "\n",
      "Epoch: 16131/40000, total loss = 2.820, Fit loss U = 9.337, Fit loss F = 3.244, KL loss = 438.126\n",
      "Epoch: 16131/40000, alpha = 1.00191\n",
      "\n",
      "Epoch: 16141/40000, total loss = 2.787, Fit loss U = 8.617, Fit loss F = 3.244, KL loss = 438.759\n",
      "Epoch: 16141/40000, alpha = 1.00191\n",
      "\n",
      "Epoch: 16151/40000, total loss = 2.904, Fit loss U = 10.950, Fit loss F = 3.244, KL loss = 438.855\n",
      "Epoch: 16151/40000, alpha = 1.00190\n",
      "\n",
      "Epoch: 16161/40000, total loss = 2.854, Fit loss U = 10.059, Fit loss F = 3.244, KL loss = 437.798\n",
      "Epoch: 16161/40000, alpha = 1.00189\n",
      "\n",
      "Epoch: 16171/40000, total loss = 2.892, Fit loss U = 10.884, Fit loss F = 3.244, KL loss = 437.150\n",
      "Epoch: 16171/40000, alpha = 1.00188\n",
      "\n",
      "Epoch: 16181/40000, total loss = 2.768, Fit loss U = 8.340, Fit loss F = 3.244, KL loss = 437.667\n",
      "Epoch: 16181/40000, alpha = 1.00187\n",
      "\n",
      "Epoch: 16191/40000, total loss = 2.784, Fit loss U = 8.717, Fit loss F = 3.244, KL loss = 437.178\n",
      "Epoch: 16191/40000, alpha = 1.00187\n",
      "\n",
      "Epoch: 16201/40000, total loss = 2.811, Fit loss U = 9.321, Fit loss F = 3.244, KL loss = 436.585\n",
      "Epoch: 16201/40000, error_test = 0.99414, error_train = 1.05300\n",
      "Epoch: 16201/40000, error_f = 1.00001\n",
      "Epoch: 16201/40000, alpha = 1.00186\n",
      "\n",
      "Epoch: 16211/40000, total loss = 2.625, Fit loss U = 5.608, Fit loss F = 3.243, KL loss = 436.396\n",
      "Epoch: 16211/40000, alpha = 1.00185\n",
      "\n",
      "Epoch: 16221/40000, total loss = 2.936, Fit loss U = 11.852, Fit loss F = 3.243, KL loss = 436.215\n",
      "Epoch: 16221/40000, alpha = 1.00184\n",
      "\n",
      "Epoch: 16231/40000, total loss = 2.886, Fit loss U = 10.760, Fit loss F = 3.243, KL loss = 437.251\n",
      "Epoch: 16231/40000, alpha = 1.00183\n",
      "\n",
      "Epoch: 16241/40000, total loss = 2.833, Fit loss U = 9.671, Fit loss F = 3.243, KL loss = 437.393\n",
      "Epoch: 16241/40000, alpha = 1.00183\n",
      "\n",
      "Epoch: 16251/40000, total loss = 2.677, Fit loss U = 6.486, Fit loss F = 3.243, KL loss = 438.038\n",
      "Epoch: 16251/40000, alpha = 1.00182\n",
      "\n",
      "Epoch: 16261/40000, total loss = 2.770, Fit loss U = 8.332, Fit loss F = 3.243, KL loss = 438.278\n",
      "Epoch: 16261/40000, alpha = 1.00181\n",
      "\n",
      "Epoch: 16271/40000, total loss = 2.708, Fit loss U = 7.170, Fit loss F = 3.243, KL loss = 437.473\n",
      "Epoch: 16271/40000, alpha = 1.00180\n",
      "\n",
      "Epoch: 16281/40000, total loss = 2.793, Fit loss U = 8.960, Fit loss F = 3.243, KL loss = 436.641\n",
      "Epoch: 16281/40000, alpha = 1.00179\n",
      "\n",
      "Epoch: 16291/40000, total loss = 2.710, Fit loss U = 7.286, Fit loss F = 3.243, KL loss = 436.780\n",
      "Epoch: 16291/40000, alpha = 1.00179\n",
      "\n",
      "Epoch: 16301/40000, total loss = 2.845, Fit loss U = 10.010, Fit loss F = 3.242, KL loss = 436.440\n",
      "Epoch: 16301/40000, error_test = 1.00418, error_train = 1.09711\n",
      "Epoch: 16301/40000, error_f = 1.00000\n",
      "Epoch: 16301/40000, alpha = 1.00178\n",
      "\n",
      "Epoch: 16311/40000, total loss = 2.896, Fit loss U = 10.752, Fit loss F = 3.242, KL loss = 439.185\n",
      "Epoch: 16311/40000, alpha = 1.00177\n",
      "\n",
      "Epoch: 16321/40000, total loss = 2.953, Fit loss U = 11.749, Fit loss F = 3.242, KL loss = 440.636\n",
      "Epoch: 16321/40000, alpha = 1.00176\n",
      "\n",
      "Epoch: 16331/40000, total loss = 2.806, Fit loss U = 8.808, Fit loss F = 3.242, KL loss = 440.706\n",
      "Epoch: 16331/40000, alpha = 1.00176\n",
      "\n",
      "Epoch: 16341/40000, total loss = 2.783, Fit loss U = 8.267, Fit loss F = 3.242, KL loss = 441.501\n",
      "Epoch: 16341/40000, alpha = 1.00175\n",
      "\n",
      "Epoch: 16351/40000, total loss = 2.851, Fit loss U = 9.618, Fit loss F = 3.242, KL loss = 441.583\n",
      "Epoch: 16351/40000, alpha = 1.00174\n",
      "\n",
      "Epoch: 16361/40000, total loss = 2.702, Fit loss U = 6.602, Fit loss F = 3.242, KL loss = 442.023\n",
      "Epoch: 16361/40000, alpha = 1.00173\n",
      "\n",
      "Epoch: 16371/40000, total loss = 2.950, Fit loss U = 11.676, Fit loss F = 3.242, KL loss = 440.811\n",
      "Epoch: 16371/40000, alpha = 1.00173\n",
      "\n",
      "Epoch: 16381/40000, total loss = 2.755, Fit loss U = 7.823, Fit loss F = 3.241, KL loss = 440.441\n",
      "Epoch: 16381/40000, alpha = 1.00172\n",
      "\n",
      "Epoch: 16391/40000, total loss = 2.784, Fit loss U = 8.531, Fit loss F = 3.242, KL loss = 439.143\n",
      "Epoch: 16391/40000, alpha = 1.00171\n",
      "\n",
      "Epoch: 16401/40000, total loss = 2.865, Fit loss U = 10.214, Fit loss F = 3.241, KL loss = 438.447\n",
      "Epoch: 16401/40000, error_test = 1.01983, error_train = 1.03464\n",
      "Epoch: 16401/40000, error_f = 1.00000\n",
      "Epoch: 16401/40000, alpha = 1.00170\n",
      "\n",
      "Epoch: 16411/40000, total loss = 2.839, Fit loss U = 9.718, Fit loss F = 3.241, KL loss = 438.116\n",
      "Epoch: 16411/40000, alpha = 1.00170\n",
      "\n",
      "Epoch: 16421/40000, total loss = 2.703, Fit loss U = 7.074, Fit loss F = 3.241, KL loss = 437.496\n",
      "Epoch: 16421/40000, alpha = 1.00169\n",
      "\n",
      "Epoch: 16431/40000, total loss = 2.794, Fit loss U = 8.909, Fit loss F = 3.241, KL loss = 437.355\n",
      "Epoch: 16431/40000, alpha = 1.00168\n",
      "\n",
      "Epoch: 16441/40000, total loss = 2.868, Fit loss U = 10.246, Fit loss F = 3.241, KL loss = 438.801\n",
      "Epoch: 16441/40000, alpha = 1.00167\n",
      "\n",
      "Epoch: 16451/40000, total loss = 2.871, Fit loss U = 10.182, Fit loss F = 3.241, KL loss = 439.884\n",
      "Epoch: 16451/40000, alpha = 1.00167\n",
      "\n",
      "Epoch: 16461/40000, total loss = 2.739, Fit loss U = 7.578, Fit loss F = 3.241, KL loss = 439.547\n",
      "Epoch: 16461/40000, alpha = 1.00166\n",
      "\n",
      "Epoch: 16471/40000, total loss = 2.835, Fit loss U = 9.546, Fit loss F = 3.241, KL loss = 439.083\n",
      "Epoch: 16471/40000, alpha = 1.00165\n",
      "\n",
      "Epoch: 16481/40000, total loss = 2.892, Fit loss U = 10.694, Fit loss F = 3.241, KL loss = 439.001\n",
      "Epoch: 16481/40000, alpha = 1.00164\n",
      "\n",
      "Epoch: 16491/40000, total loss = 2.837, Fit loss U = 9.620, Fit loss F = 3.241, KL loss = 438.896\n",
      "Epoch: 16491/40000, alpha = 1.00164\n",
      "\n",
      "Epoch: 16501/40000, total loss = 2.905, Fit loss U = 10.940, Fit loss F = 3.241, KL loss = 439.208\n",
      "Epoch: 16501/40000, error_test = 1.03085, error_train = 1.05491\n",
      "Epoch: 16501/40000, error_f = 1.00000\n",
      "Epoch: 16501/40000, alpha = 1.00163\n",
      "\n",
      "Epoch: 16511/40000, total loss = 2.976, Fit loss U = 12.258, Fit loss F = 3.241, KL loss = 440.214\n",
      "Epoch: 16511/40000, alpha = 1.00162\n",
      "\n",
      "Epoch: 16521/40000, total loss = 2.811, Fit loss U = 8.961, Fit loss F = 3.240, KL loss = 440.117\n",
      "Epoch: 16521/40000, alpha = 1.00162\n",
      "\n",
      "Epoch: 16531/40000, total loss = 2.849, Fit loss U = 9.894, Fit loss F = 3.240, KL loss = 438.501\n",
      "Epoch: 16531/40000, alpha = 1.00161\n",
      "\n",
      "Epoch: 16541/40000, total loss = 2.844, Fit loss U = 9.826, Fit loss F = 3.240, KL loss = 438.064\n",
      "Epoch: 16541/40000, alpha = 1.00160\n",
      "\n",
      "Epoch: 16551/40000, total loss = 2.845, Fit loss U = 9.881, Fit loss F = 3.240, KL loss = 437.868\n",
      "Epoch: 16551/40000, alpha = 1.00160\n",
      "\n",
      "Epoch: 16561/40000, total loss = 2.769, Fit loss U = 8.394, Fit loss F = 3.240, KL loss = 437.439\n",
      "Epoch: 16561/40000, alpha = 1.00159\n",
      "\n",
      "Epoch: 16571/40000, total loss = 2.744, Fit loss U = 7.949, Fit loss F = 3.240, KL loss = 436.865\n",
      "Epoch: 16571/40000, alpha = 1.00158\n",
      "\n",
      "Epoch: 16581/40000, total loss = 2.651, Fit loss U = 5.975, Fit loss F = 3.240, KL loss = 438.033\n",
      "Epoch: 16581/40000, alpha = 1.00158\n",
      "\n",
      "Epoch: 16591/40000, total loss = 3.042, Fit loss U = 13.675, Fit loss F = 3.240, KL loss = 439.236\n",
      "Epoch: 16591/40000, alpha = 1.00157\n",
      "\n",
      "Epoch: 16601/40000, total loss = 2.798, Fit loss U = 8.713, Fit loss F = 3.239, KL loss = 440.092\n",
      "Epoch: 16601/40000, error_test = 1.01686, error_train = 1.03968\n",
      "Epoch: 16601/40000, error_f = 1.00000\n",
      "Epoch: 16601/40000, alpha = 1.00156\n",
      "\n",
      "Epoch: 16611/40000, total loss = 2.846, Fit loss U = 9.649, Fit loss F = 3.240, KL loss = 440.388\n",
      "Epoch: 16611/40000, alpha = 1.00155\n",
      "\n",
      "Epoch: 16621/40000, total loss = 2.715, Fit loss U = 7.003, Fit loss F = 3.239, KL loss = 440.606\n",
      "Epoch: 16621/40000, alpha = 1.00155\n",
      "\n",
      "Epoch: 16631/40000, total loss = 2.803, Fit loss U = 8.825, Fit loss F = 3.239, KL loss = 439.952\n",
      "Epoch: 16631/40000, alpha = 1.00154\n",
      "\n",
      "Epoch: 16641/40000, total loss = 2.743, Fit loss U = 7.704, Fit loss F = 3.239, KL loss = 439.082\n",
      "Epoch: 16641/40000, alpha = 1.00153\n",
      "\n",
      "Epoch: 16651/40000, total loss = 2.732, Fit loss U = 7.588, Fit loss F = 3.239, KL loss = 438.232\n",
      "Epoch: 16651/40000, alpha = 1.00153\n",
      "\n",
      "Epoch: 16661/40000, total loss = 2.768, Fit loss U = 8.366, Fit loss F = 3.239, KL loss = 437.576\n",
      "Epoch: 16661/40000, alpha = 1.00152\n",
      "\n",
      "Epoch: 16671/40000, total loss = 2.946, Fit loss U = 11.809, Fit loss F = 3.239, KL loss = 438.626\n",
      "Epoch: 16671/40000, alpha = 1.00152\n",
      "\n",
      "Epoch: 16681/40000, total loss = 2.747, Fit loss U = 7.822, Fit loss F = 3.239, KL loss = 438.821\n",
      "Epoch: 16681/40000, alpha = 1.00151\n",
      "\n",
      "Epoch: 16691/40000, total loss = 2.844, Fit loss U = 9.835, Fit loss F = 3.239, KL loss = 438.042\n",
      "Epoch: 16691/40000, alpha = 1.00150\n",
      "\n",
      "Epoch: 16701/40000, total loss = 2.798, Fit loss U = 8.957, Fit loss F = 3.239, KL loss = 437.576\n",
      "Epoch: 16701/40000, error_test = 1.02483, error_train = 1.00918\n",
      "Epoch: 16701/40000, error_f = 1.00000\n",
      "Epoch: 16701/40000, alpha = 1.00150\n",
      "\n",
      "Epoch: 16711/40000, total loss = 2.842, Fit loss U = 9.918, Fit loss F = 3.239, KL loss = 436.906\n",
      "Epoch: 16711/40000, alpha = 1.00149\n",
      "\n",
      "Epoch: 16721/40000, total loss = 2.719, Fit loss U = 7.451, Fit loss F = 3.239, KL loss = 437.002\n",
      "Epoch: 16721/40000, alpha = 1.00148\n",
      "\n",
      "Epoch: 16731/40000, total loss = 2.970, Fit loss U = 12.396, Fit loss F = 3.238, KL loss = 437.600\n",
      "Epoch: 16731/40000, alpha = 1.00148\n",
      "\n",
      "Epoch: 16741/40000, total loss = 2.784, Fit loss U = 8.649, Fit loss F = 3.238, KL loss = 437.830\n",
      "Epoch: 16741/40000, alpha = 1.00147\n",
      "\n",
      "Epoch: 16751/40000, total loss = 2.959, Fit loss U = 12.192, Fit loss F = 3.238, KL loss = 437.456\n",
      "Epoch: 16751/40000, alpha = 1.00146\n",
      "\n",
      "Epoch: 16761/40000, total loss = 2.731, Fit loss U = 7.533, Fit loss F = 3.238, KL loss = 438.561\n",
      "Epoch: 16761/40000, alpha = 1.00146\n",
      "\n",
      "Epoch: 16771/40000, total loss = 2.994, Fit loss U = 12.742, Fit loss F = 3.238, KL loss = 439.090\n",
      "Epoch: 16771/40000, alpha = 1.00145\n",
      "\n",
      "Epoch: 16781/40000, total loss = 2.770, Fit loss U = 8.255, Fit loss F = 3.238, KL loss = 438.973\n",
      "Epoch: 16781/40000, alpha = 1.00144\n",
      "\n",
      "Epoch: 16791/40000, total loss = 2.887, Fit loss U = 10.689, Fit loss F = 3.238, KL loss = 438.125\n",
      "Epoch: 16791/40000, alpha = 1.00144\n",
      "\n",
      "Epoch: 16801/40000, total loss = 2.827, Fit loss U = 9.569, Fit loss F = 3.238, KL loss = 437.419\n",
      "Epoch: 16801/40000, error_test = 1.00655, error_train = 1.03578\n",
      "Epoch: 16801/40000, error_f = 1.00001\n",
      "Epoch: 16801/40000, alpha = 1.00143\n",
      "\n",
      "Epoch: 16811/40000, total loss = 2.857, Fit loss U = 10.137, Fit loss F = 3.238, KL loss = 437.678\n",
      "Epoch: 16811/40000, alpha = 1.00143\n",
      "\n",
      "Epoch: 16821/40000, total loss = 2.869, Fit loss U = 10.350, Fit loss F = 3.238, KL loss = 437.842\n",
      "Epoch: 16821/40000, alpha = 1.00142\n",
      "\n",
      "Epoch: 16831/40000, total loss = 2.764, Fit loss U = 8.296, Fit loss F = 3.238, KL loss = 437.478\n",
      "Epoch: 16831/40000, alpha = 1.00141\n",
      "\n",
      "Epoch: 16841/40000, total loss = 2.936, Fit loss U = 11.797, Fit loss F = 3.237, KL loss = 436.918\n",
      "Epoch: 16841/40000, alpha = 1.00141\n",
      "\n",
      "Epoch: 16851/40000, total loss = 2.829, Fit loss U = 9.529, Fit loss F = 3.237, KL loss = 438.121\n",
      "Epoch: 16851/40000, alpha = 1.00140\n",
      "\n",
      "Epoch: 16861/40000, total loss = 2.781, Fit loss U = 8.572, Fit loss F = 3.237, KL loss = 438.116\n",
      "Epoch: 16861/40000, alpha = 1.00140\n",
      "\n",
      "Epoch: 16871/40000, total loss = 2.812, Fit loss U = 9.227, Fit loss F = 3.237, KL loss = 437.836\n",
      "Epoch: 16871/40000, alpha = 1.00139\n",
      "\n",
      "Epoch: 16881/40000, total loss = 2.857, Fit loss U = 10.228, Fit loss F = 3.237, KL loss = 436.845\n",
      "Epoch: 16881/40000, alpha = 1.00138\n",
      "\n",
      "Epoch: 16891/40000, total loss = 2.837, Fit loss U = 9.907, Fit loss F = 3.237, KL loss = 436.008\n",
      "Epoch: 16891/40000, alpha = 1.00138\n",
      "\n",
      "Epoch: 16901/40000, total loss = 2.738, Fit loss U = 7.903, Fit loss F = 3.237, KL loss = 436.293\n",
      "Epoch: 16901/40000, error_test = 1.01356, error_train = 0.99772\n",
      "Epoch: 16901/40000, error_f = 1.00000\n",
      "Epoch: 16901/40000, alpha = 1.00137\n",
      "\n",
      "Epoch: 16911/40000, total loss = 2.831, Fit loss U = 9.721, Fit loss F = 3.237, KL loss = 436.585\n",
      "Epoch: 16911/40000, alpha = 1.00137\n",
      "\n",
      "Epoch: 16921/40000, total loss = 2.754, Fit loss U = 8.187, Fit loss F = 3.237, KL loss = 436.524\n",
      "Epoch: 16921/40000, alpha = 1.00136\n",
      "\n",
      "Epoch: 16931/40000, total loss = 2.802, Fit loss U = 9.253, Fit loss F = 3.237, KL loss = 435.463\n",
      "Epoch: 16931/40000, alpha = 1.00135\n",
      "\n",
      "Epoch: 16941/40000, total loss = 2.857, Fit loss U = 10.394, Fit loss F = 3.237, KL loss = 435.179\n",
      "Epoch: 16941/40000, alpha = 1.00135\n",
      "\n",
      "Epoch: 16951/40000, total loss = 2.795, Fit loss U = 9.064, Fit loss F = 3.237, KL loss = 435.939\n",
      "Epoch: 16951/40000, alpha = 1.00134\n",
      "\n",
      "Epoch: 16961/40000, total loss = 2.799, Fit loss U = 9.129, Fit loss F = 3.236, KL loss = 436.121\n",
      "Epoch: 16961/40000, alpha = 1.00134\n",
      "\n",
      "Epoch: 16971/40000, total loss = 2.927, Fit loss U = 11.613, Fit loss F = 3.237, KL loss = 436.810\n",
      "Epoch: 16971/40000, alpha = 1.00133\n",
      "\n",
      "Epoch: 16981/40000, total loss = 2.758, Fit loss U = 8.041, Fit loss F = 3.236, KL loss = 438.879\n",
      "Epoch: 16981/40000, alpha = 1.00133\n",
      "\n",
      "Epoch: 16991/40000, total loss = 2.732, Fit loss U = 7.488, Fit loss F = 3.236, KL loss = 439.084\n",
      "Epoch: 16991/40000, alpha = 1.00132\n",
      "\n",
      "Epoch: 17001/40000, total loss = 2.838, Fit loss U = 9.651, Fit loss F = 3.236, KL loss = 438.677\n",
      "Epoch: 17001/40000, error_test = 1.00403, error_train = 1.00733\n",
      "Epoch: 17001/40000, error_f = 1.00000\n",
      "Epoch: 17001/40000, alpha = 1.00131\n",
      "\n",
      "Epoch: 17011/40000, total loss = 2.901, Fit loss U = 11.011, Fit loss F = 3.236, KL loss = 437.744\n",
      "Epoch: 17011/40000, alpha = 1.00131\n",
      "\n",
      "Epoch: 17021/40000, total loss = 2.896, Fit loss U = 10.942, Fit loss F = 3.236, KL loss = 437.436\n",
      "Epoch: 17021/40000, alpha = 1.00130\n",
      "\n",
      "Epoch: 17031/40000, total loss = 2.671, Fit loss U = 6.433, Fit loss F = 3.236, KL loss = 437.541\n",
      "Epoch: 17031/40000, alpha = 1.00130\n",
      "\n",
      "Epoch: 17041/40000, total loss = 2.792, Fit loss U = 8.905, Fit loss F = 3.236, KL loss = 436.949\n",
      "Epoch: 17041/40000, alpha = 1.00129\n",
      "\n",
      "Epoch: 17051/40000, total loss = 2.767, Fit loss U = 8.410, Fit loss F = 3.236, KL loss = 436.846\n",
      "Epoch: 17051/40000, alpha = 1.00129\n",
      "\n",
      "Epoch: 17061/40000, total loss = 2.871, Fit loss U = 10.558, Fit loss F = 3.236, KL loss = 436.328\n",
      "Epoch: 17061/40000, alpha = 1.00128\n",
      "\n",
      "Epoch: 17071/40000, total loss = 2.983, Fit loss U = 12.782, Fit loss F = 3.236, KL loss = 436.510\n",
      "Epoch: 17071/40000, alpha = 1.00128\n",
      "\n",
      "Epoch: 17081/40000, total loss = 3.134, Fit loss U = 15.720, Fit loss F = 3.236, KL loss = 437.175\n",
      "Epoch: 17081/40000, alpha = 1.00127\n",
      "\n",
      "Epoch: 17091/40000, total loss = 2.735, Fit loss U = 7.529, Fit loss F = 3.236, KL loss = 439.364\n",
      "Epoch: 17091/40000, alpha = 1.00126\n",
      "\n",
      "Epoch: 17101/40000, total loss = 2.902, Fit loss U = 10.893, Fit loss F = 3.235, KL loss = 439.116\n",
      "Epoch: 17101/40000, error_test = 1.02524, error_train = 1.03484\n",
      "Epoch: 17101/40000, error_f = 1.00000\n",
      "Epoch: 17101/40000, alpha = 1.00126\n",
      "\n",
      "Epoch: 17111/40000, total loss = 2.767, Fit loss U = 8.172, Fit loss F = 3.235, KL loss = 439.247\n",
      "Epoch: 17111/40000, alpha = 1.00125\n",
      "\n",
      "Epoch: 17121/40000, total loss = 2.901, Fit loss U = 10.938, Fit loss F = 3.235, KL loss = 438.502\n",
      "Epoch: 17121/40000, alpha = 1.00125\n",
      "\n",
      "Epoch: 17131/40000, total loss = 2.886, Fit loss U = 10.632, Fit loss F = 3.235, KL loss = 438.453\n",
      "Epoch: 17131/40000, alpha = 1.00124\n",
      "\n",
      "Epoch: 17141/40000, total loss = 2.816, Fit loss U = 9.181, Fit loss F = 3.235, KL loss = 438.996\n",
      "Epoch: 17141/40000, alpha = 1.00124\n",
      "\n",
      "Epoch: 17151/40000, total loss = 2.709, Fit loss U = 7.005, Fit loss F = 3.236, KL loss = 439.460\n",
      "Epoch: 17151/40000, alpha = 1.00123\n",
      "\n",
      "Epoch: 17161/40000, total loss = 2.917, Fit loss U = 11.248, Fit loss F = 3.235, KL loss = 438.586\n",
      "Epoch: 17161/40000, alpha = 1.00123\n",
      "\n",
      "Epoch: 17171/40000, total loss = 2.720, Fit loss U = 7.332, Fit loss F = 3.235, KL loss = 438.395\n",
      "Epoch: 17171/40000, alpha = 1.00122\n",
      "\n",
      "Epoch: 17181/40000, total loss = 2.876, Fit loss U = 10.530, Fit loss F = 3.235, KL loss = 437.614\n",
      "Epoch: 17181/40000, alpha = 1.00122\n",
      "\n",
      "Epoch: 17191/40000, total loss = 2.690, Fit loss U = 6.932, Fit loss F = 3.235, KL loss = 436.430\n",
      "Epoch: 17191/40000, alpha = 1.00121\n",
      "\n",
      "Epoch: 17201/40000, total loss = 2.703, Fit loss U = 7.269, Fit loss F = 3.235, KL loss = 435.612\n",
      "Epoch: 17201/40000, error_test = 1.00554, error_train = 1.04787\n",
      "Epoch: 17201/40000, error_f = 1.00001\n",
      "Epoch: 17201/40000, alpha = 1.00121\n",
      "\n",
      "Epoch: 17211/40000, total loss = 2.829, Fit loss U = 9.833, Fit loss F = 3.234, KL loss = 435.161\n",
      "Epoch: 17211/40000, alpha = 1.00120\n",
      "\n",
      "Epoch: 17221/40000, total loss = 2.768, Fit loss U = 8.566, Fit loss F = 3.235, KL loss = 435.640\n",
      "Epoch: 17221/40000, alpha = 1.00120\n",
      "\n",
      "Epoch: 17231/40000, total loss = 2.801, Fit loss U = 9.130, Fit loss F = 3.235, KL loss = 436.634\n",
      "Epoch: 17231/40000, alpha = 1.00119\n",
      "\n",
      "Epoch: 17241/40000, total loss = 2.780, Fit loss U = 8.588, Fit loss F = 3.234, KL loss = 437.786\n",
      "Epoch: 17241/40000, alpha = 1.00119\n",
      "\n",
      "Epoch: 17251/40000, total loss = 2.651, Fit loss U = 5.955, Fit loss F = 3.234, KL loss = 438.254\n",
      "Epoch: 17251/40000, alpha = 1.00118\n",
      "\n",
      "Epoch: 17261/40000, total loss = 2.645, Fit loss U = 5.806, Fit loss F = 3.234, KL loss = 438.529\n",
      "Epoch: 17261/40000, alpha = 1.00118\n",
      "\n",
      "Epoch: 17271/40000, total loss = 2.906, Fit loss U = 11.072, Fit loss F = 3.234, KL loss = 438.168\n",
      "Epoch: 17271/40000, alpha = 1.00117\n",
      "\n",
      "Epoch: 17281/40000, total loss = 2.896, Fit loss U = 10.969, Fit loss F = 3.234, KL loss = 437.096\n",
      "Epoch: 17281/40000, alpha = 1.00117\n",
      "\n",
      "Epoch: 17291/40000, total loss = 2.779, Fit loss U = 8.728, Fit loss F = 3.234, KL loss = 436.249\n",
      "Epoch: 17291/40000, alpha = 1.00116\n",
      "\n",
      "Epoch: 17301/40000, total loss = 2.801, Fit loss U = 9.196, Fit loss F = 3.234, KL loss = 435.929\n",
      "Epoch: 17301/40000, error_test = 0.98262, error_train = 1.05990\n",
      "Epoch: 17301/40000, error_f = 1.00000\n",
      "Epoch: 17301/40000, alpha = 1.00116\n",
      "\n",
      "Epoch: 17311/40000, total loss = 2.770, Fit loss U = 8.576, Fit loss F = 3.234, KL loss = 435.842\n",
      "Epoch: 17311/40000, alpha = 1.00115\n",
      "\n",
      "Epoch: 17321/40000, total loss = 2.815, Fit loss U = 9.504, Fit loss F = 3.234, KL loss = 435.525\n",
      "Epoch: 17321/40000, alpha = 1.00115\n",
      "\n",
      "Epoch: 17331/40000, total loss = 2.882, Fit loss U = 10.868, Fit loss F = 3.234, KL loss = 435.408\n",
      "Epoch: 17331/40000, alpha = 1.00114\n",
      "\n",
      "Epoch: 17341/40000, total loss = 2.938, Fit loss U = 11.947, Fit loss F = 3.234, KL loss = 435.863\n",
      "Epoch: 17341/40000, alpha = 1.00114\n",
      "\n",
      "Epoch: 17351/40000, total loss = 2.901, Fit loss U = 11.052, Fit loss F = 3.234, KL loss = 437.241\n",
      "Epoch: 17351/40000, alpha = 1.00113\n",
      "\n",
      "Epoch: 17361/40000, total loss = 2.789, Fit loss U = 8.858, Fit loss F = 3.234, KL loss = 436.900\n",
      "Epoch: 17361/40000, alpha = 1.00113\n",
      "\n",
      "Epoch: 17371/40000, total loss = 2.846, Fit loss U = 10.100, Fit loss F = 3.234, KL loss = 435.776\n",
      "Epoch: 17371/40000, alpha = 1.00112\n",
      "\n",
      "Epoch: 17381/40000, total loss = 2.854, Fit loss U = 10.265, Fit loss F = 3.234, KL loss = 435.803\n",
      "Epoch: 17381/40000, alpha = 1.00112\n",
      "\n",
      "Epoch: 17391/40000, total loss = 2.857, Fit loss U = 10.232, Fit loss F = 3.233, KL loss = 436.721\n",
      "Epoch: 17391/40000, alpha = 1.00111\n",
      "\n",
      "Epoch: 17401/40000, total loss = 2.777, Fit loss U = 8.598, Fit loss F = 3.233, KL loss = 437.139\n",
      "Epoch: 17401/40000, error_test = 1.03100, error_train = 1.03396\n",
      "Epoch: 17401/40000, error_f = 1.00000\n",
      "Epoch: 17401/40000, alpha = 1.00111\n",
      "\n",
      "Epoch: 17411/40000, total loss = 2.751, Fit loss U = 7.992, Fit loss F = 3.233, KL loss = 438.012\n",
      "Epoch: 17411/40000, alpha = 1.00110\n",
      "\n",
      "Epoch: 17421/40000, total loss = 2.847, Fit loss U = 9.994, Fit loss F = 3.233, KL loss = 437.047\n",
      "Epoch: 17421/40000, alpha = 1.00110\n",
      "\n",
      "Epoch: 17431/40000, total loss = 2.882, Fit loss U = 10.726, Fit loss F = 3.233, KL loss = 436.853\n",
      "Epoch: 17431/40000, alpha = 1.00109\n",
      "\n",
      "Epoch: 17441/40000, total loss = 2.888, Fit loss U = 10.887, Fit loss F = 3.233, KL loss = 436.496\n",
      "Epoch: 17441/40000, alpha = 1.00109\n",
      "\n",
      "Epoch: 17451/40000, total loss = 2.775, Fit loss U = 8.611, Fit loss F = 3.233, KL loss = 436.628\n",
      "Epoch: 17451/40000, alpha = 1.00108\n",
      "\n",
      "Epoch: 17461/40000, total loss = 2.802, Fit loss U = 9.152, Fit loss F = 3.233, KL loss = 436.539\n",
      "Epoch: 17461/40000, alpha = 1.00108\n",
      "\n",
      "Epoch: 17471/40000, total loss = 2.794, Fit loss U = 9.038, Fit loss F = 3.233, KL loss = 436.028\n",
      "Epoch: 17471/40000, alpha = 1.00108\n",
      "\n",
      "Epoch: 17481/40000, total loss = 2.926, Fit loss U = 11.811, Fit loss F = 3.233, KL loss = 434.847\n",
      "Epoch: 17481/40000, alpha = 1.00107\n",
      "\n",
      "Epoch: 17491/40000, total loss = 2.746, Fit loss U = 8.299, Fit loss F = 3.233, KL loss = 433.814\n",
      "Epoch: 17491/40000, alpha = 1.00107\n",
      "\n",
      "Epoch: 17501/40000, total loss = 2.886, Fit loss U = 11.049, Fit loss F = 3.233, KL loss = 434.410\n",
      "Epoch: 17501/40000, error_test = 0.99317, error_train = 0.98740\n",
      "Epoch: 17501/40000, error_f = 1.00000\n",
      "Epoch: 17501/40000, alpha = 1.00106\n",
      "\n",
      "Epoch: 17511/40000, total loss = 2.762, Fit loss U = 8.380, Fit loss F = 3.233, KL loss = 436.242\n",
      "Epoch: 17511/40000, alpha = 1.00106\n",
      "\n",
      "Epoch: 17521/40000, total loss = 2.878, Fit loss U = 10.692, Fit loss F = 3.233, KL loss = 436.443\n",
      "Epoch: 17521/40000, alpha = 1.00105\n",
      "\n",
      "Epoch: 17531/40000, total loss = 2.698, Fit loss U = 6.990, Fit loss F = 3.232, KL loss = 437.326\n",
      "Epoch: 17531/40000, alpha = 1.00105\n",
      "\n",
      "Epoch: 17541/40000, total loss = 2.743, Fit loss U = 7.902, Fit loss F = 3.232, KL loss = 437.166\n",
      "Epoch: 17541/40000, alpha = 1.00104\n",
      "\n",
      "Epoch: 17551/40000, total loss = 2.719, Fit loss U = 7.520, Fit loss F = 3.233, KL loss = 436.373\n",
      "Epoch: 17551/40000, alpha = 1.00104\n",
      "\n",
      "Epoch: 17561/40000, total loss = 2.837, Fit loss U = 9.891, Fit loss F = 3.233, KL loss = 436.135\n",
      "Epoch: 17561/40000, alpha = 1.00103\n",
      "\n",
      "Epoch: 17571/40000, total loss = 2.731, Fit loss U = 7.852, Fit loss F = 3.232, KL loss = 435.398\n",
      "Epoch: 17571/40000, alpha = 1.00103\n",
      "\n",
      "Epoch: 17581/40000, total loss = 2.872, Fit loss U = 10.640, Fit loss F = 3.232, KL loss = 435.602\n",
      "Epoch: 17581/40000, alpha = 1.00103\n",
      "\n",
      "Epoch: 17591/40000, total loss = 2.844, Fit loss U = 9.945, Fit loss F = 3.232, KL loss = 437.100\n",
      "Epoch: 17591/40000, alpha = 1.00102\n",
      "\n",
      "Epoch: 17601/40000, total loss = 2.804, Fit loss U = 9.097, Fit loss F = 3.232, KL loss = 437.586\n",
      "Epoch: 17601/40000, error_test = 1.01468, error_train = 1.01307\n",
      "Epoch: 17601/40000, error_f = 1.00000\n",
      "Epoch: 17601/40000, alpha = 1.00102\n",
      "\n",
      "Epoch: 17611/40000, total loss = 2.810, Fit loss U = 9.175, Fit loss F = 3.232, KL loss = 437.975\n",
      "Epoch: 17611/40000, alpha = 1.00101\n",
      "\n",
      "Epoch: 17621/40000, total loss = 2.741, Fit loss U = 7.822, Fit loss F = 3.232, KL loss = 437.593\n",
      "Epoch: 17621/40000, alpha = 1.00101\n",
      "\n",
      "Epoch: 17631/40000, total loss = 2.738, Fit loss U = 7.897, Fit loss F = 3.232, KL loss = 436.334\n",
      "Epoch: 17631/40000, alpha = 1.00100\n",
      "\n",
      "Epoch: 17641/40000, total loss = 2.963, Fit loss U = 12.457, Fit loss F = 3.232, KL loss = 435.616\n",
      "Epoch: 17641/40000, alpha = 1.00100\n",
      "\n",
      "Epoch: 17651/40000, total loss = 2.882, Fit loss U = 10.763, Fit loss F = 3.232, KL loss = 436.385\n",
      "Epoch: 17651/40000, alpha = 1.00100\n",
      "\n",
      "Epoch: 17661/40000, total loss = 2.756, Fit loss U = 8.227, Fit loss F = 3.232, KL loss = 436.666\n",
      "Epoch: 17661/40000, alpha = 1.00099\n",
      "\n",
      "Epoch: 17671/40000, total loss = 2.793, Fit loss U = 9.015, Fit loss F = 3.232, KL loss = 436.100\n",
      "Epoch: 17671/40000, alpha = 1.00099\n",
      "\n",
      "Epoch: 17681/40000, total loss = 2.679, Fit loss U = 6.767, Fit loss F = 3.232, KL loss = 435.755\n",
      "Epoch: 17681/40000, alpha = 1.00098\n",
      "\n",
      "Epoch: 17691/40000, total loss = 2.883, Fit loss U = 10.902, Fit loss F = 3.232, KL loss = 435.188\n",
      "Epoch: 17691/40000, alpha = 1.00098\n",
      "\n",
      "Epoch: 17701/40000, total loss = 2.764, Fit loss U = 8.451, Fit loss F = 3.232, KL loss = 435.990\n",
      "Epoch: 17701/40000, error_test = 0.99076, error_train = 1.02561\n",
      "Epoch: 17701/40000, error_f = 1.00000\n",
      "Epoch: 17701/40000, alpha = 1.00098\n",
      "\n",
      "Epoch: 17711/40000, total loss = 2.856, Fit loss U = 10.168, Fit loss F = 3.232, KL loss = 437.282\n",
      "Epoch: 17711/40000, alpha = 1.00097\n",
      "\n",
      "Epoch: 17721/40000, total loss = 2.868, Fit loss U = 10.301, Fit loss F = 3.231, KL loss = 438.332\n",
      "Epoch: 17721/40000, alpha = 1.00097\n",
      "\n",
      "Epoch: 17731/40000, total loss = 2.793, Fit loss U = 8.732, Fit loss F = 3.232, KL loss = 439.000\n",
      "Epoch: 17731/40000, alpha = 1.00096\n",
      "\n",
      "Epoch: 17741/40000, total loss = 2.898, Fit loss U = 10.849, Fit loss F = 3.231, KL loss = 438.814\n",
      "Epoch: 17741/40000, alpha = 1.00096\n",
      "\n",
      "Epoch: 17751/40000, total loss = 2.996, Fit loss U = 12.836, Fit loss F = 3.231, KL loss = 438.528\n",
      "Epoch: 17751/40000, alpha = 1.00095\n",
      "\n",
      "Epoch: 17761/40000, total loss = 2.745, Fit loss U = 7.792, Fit loss F = 3.231, KL loss = 438.771\n",
      "Epoch: 17761/40000, alpha = 1.00095\n",
      "\n",
      "Epoch: 17771/40000, total loss = 2.805, Fit loss U = 8.957, Fit loss F = 3.231, KL loss = 439.117\n",
      "Epoch: 17771/40000, alpha = 1.00095\n",
      "\n",
      "Epoch: 17781/40000, total loss = 2.721, Fit loss U = 7.277, Fit loss F = 3.231, KL loss = 439.199\n",
      "Epoch: 17781/40000, alpha = 1.00094\n",
      "\n",
      "Epoch: 17791/40000, total loss = 2.797, Fit loss U = 8.824, Fit loss F = 3.231, KL loss = 438.761\n",
      "Epoch: 17791/40000, alpha = 1.00094\n",
      "\n",
      "Epoch: 17801/40000, total loss = 2.693, Fit loss U = 6.757, Fit loss F = 3.231, KL loss = 438.768\n",
      "Epoch: 17801/40000, error_test = 1.01156, error_train = 1.05754\n",
      "Epoch: 17801/40000, error_f = 1.00000\n",
      "Epoch: 17801/40000, alpha = 1.00093\n",
      "\n",
      "Epoch: 17811/40000, total loss = 2.782, Fit loss U = 8.557, Fit loss F = 3.231, KL loss = 438.529\n",
      "Epoch: 17811/40000, alpha = 1.00093\n",
      "\n",
      "Epoch: 17821/40000, total loss = 2.798, Fit loss U = 8.793, Fit loss F = 3.231, KL loss = 439.341\n",
      "Epoch: 17821/40000, alpha = 1.00093\n",
      "\n",
      "Epoch: 17831/40000, total loss = 2.922, Fit loss U = 11.255, Fit loss F = 3.231, KL loss = 439.595\n",
      "Epoch: 17831/40000, alpha = 1.00092\n",
      "\n",
      "Epoch: 17841/40000, total loss = 2.936, Fit loss U = 11.532, Fit loss F = 3.231, KL loss = 439.549\n",
      "Epoch: 17841/40000, alpha = 1.00092\n",
      "\n",
      "Epoch: 17851/40000, total loss = 2.705, Fit loss U = 6.853, Fit loss F = 3.231, KL loss = 440.107\n",
      "Epoch: 17851/40000, alpha = 1.00091\n",
      "\n",
      "Epoch: 17861/40000, total loss = 2.984, Fit loss U = 12.557, Fit loss F = 3.231, KL loss = 438.957\n",
      "Epoch: 17861/40000, alpha = 1.00091\n",
      "\n",
      "Epoch: 17871/40000, total loss = 2.760, Fit loss U = 8.124, Fit loss F = 3.231, KL loss = 438.503\n",
      "Epoch: 17871/40000, alpha = 1.00091\n",
      "\n",
      "Epoch: 17881/40000, total loss = 2.897, Fit loss U = 10.913, Fit loss F = 3.230, KL loss = 438.017\n",
      "Epoch: 17881/40000, alpha = 1.00090\n",
      "\n",
      "Epoch: 17891/40000, total loss = 2.908, Fit loss U = 11.213, Fit loss F = 3.231, KL loss = 437.203\n",
      "Epoch: 17891/40000, alpha = 1.00090\n",
      "\n",
      "Epoch: 17901/40000, total loss = 2.730, Fit loss U = 7.597, Fit loss F = 3.230, KL loss = 437.762\n",
      "Epoch: 17901/40000, error_test = 1.00960, error_train = 0.97805\n",
      "Epoch: 17901/40000, error_f = 1.00000\n",
      "Epoch: 17901/40000, alpha = 1.00090\n",
      "\n",
      "Epoch: 17911/40000, total loss = 3.010, Fit loss U = 13.242, Fit loss F = 3.231, KL loss = 437.281\n",
      "Epoch: 17911/40000, alpha = 1.00089\n",
      "\n",
      "Epoch: 17921/40000, total loss = 2.846, Fit loss U = 9.834, Fit loss F = 3.231, KL loss = 438.485\n",
      "Epoch: 17921/40000, alpha = 1.00089\n",
      "\n",
      "Epoch: 17931/40000, total loss = 2.737, Fit loss U = 7.665, Fit loss F = 3.230, KL loss = 438.392\n",
      "Epoch: 17931/40000, alpha = 1.00088\n",
      "\n",
      "Epoch: 17941/40000, total loss = 2.822, Fit loss U = 9.463, Fit loss F = 3.230, KL loss = 437.536\n",
      "Epoch: 17941/40000, alpha = 1.00088\n",
      "\n",
      "Epoch: 17951/40000, total loss = 2.861, Fit loss U = 10.187, Fit loss F = 3.230, KL loss = 438.071\n",
      "Epoch: 17951/40000, alpha = 1.00088\n",
      "\n",
      "Epoch: 17961/40000, total loss = 2.885, Fit loss U = 10.640, Fit loss F = 3.230, KL loss = 438.219\n",
      "Epoch: 17961/40000, alpha = 1.00087\n",
      "\n",
      "Epoch: 17971/40000, total loss = 2.886, Fit loss U = 10.649, Fit loss F = 3.230, KL loss = 438.484\n",
      "Epoch: 17971/40000, alpha = 1.00087\n",
      "\n",
      "Epoch: 17981/40000, total loss = 2.760, Fit loss U = 8.185, Fit loss F = 3.230, KL loss = 437.874\n",
      "Epoch: 17981/40000, alpha = 1.00087\n",
      "\n",
      "Epoch: 17991/40000, total loss = 2.774, Fit loss U = 8.467, Fit loss F = 3.230, KL loss = 437.758\n",
      "Epoch: 17991/40000, alpha = 1.00086\n",
      "\n",
      "Epoch: 18001/40000, total loss = 2.754, Fit loss U = 8.035, Fit loss F = 3.230, KL loss = 438.065\n",
      "Epoch: 18001/40000, error_test = 0.96746, error_train = 0.94322\n",
      "Epoch: 18001/40000, error_f = 1.00000\n",
      "Epoch: 18001/40000, alpha = 1.00086\n",
      "\n",
      "Epoch: 18011/40000, total loss = 2.667, Fit loss U = 6.332, Fit loss F = 3.230, KL loss = 437.694\n",
      "Epoch: 18011/40000, alpha = 1.00086\n",
      "\n",
      "Epoch: 18021/40000, total loss = 2.941, Fit loss U = 11.572, Fit loss F = 3.230, KL loss = 440.231\n",
      "Epoch: 18021/40000, alpha = 1.00085\n",
      "\n",
      "Epoch: 18031/40000, total loss = 2.822, Fit loss U = 9.082, Fit loss F = 3.230, KL loss = 441.239\n",
      "Epoch: 18031/40000, alpha = 1.00085\n",
      "\n",
      "Epoch: 18041/40000, total loss = 2.764, Fit loss U = 7.966, Fit loss F = 3.230, KL loss = 440.907\n",
      "Epoch: 18041/40000, alpha = 1.00084\n",
      "\n",
      "Epoch: 18051/40000, total loss = 2.711, Fit loss U = 6.957, Fit loss F = 3.230, KL loss = 440.344\n",
      "Epoch: 18051/40000, alpha = 1.00084\n",
      "\n",
      "Epoch: 18061/40000, total loss = 2.795, Fit loss U = 8.655, Fit loss F = 3.230, KL loss = 440.069\n",
      "Epoch: 18061/40000, alpha = 1.00084\n",
      "\n",
      "Epoch: 18071/40000, total loss = 2.756, Fit loss U = 7.979, Fit loss F = 3.230, KL loss = 439.148\n",
      "Epoch: 18071/40000, alpha = 1.00083\n",
      "\n",
      "Epoch: 18081/40000, total loss = 2.763, Fit loss U = 8.245, Fit loss F = 3.230, KL loss = 437.761\n",
      "Epoch: 18081/40000, alpha = 1.00083\n",
      "\n",
      "Epoch: 18091/40000, total loss = 2.789, Fit loss U = 8.858, Fit loss F = 3.230, KL loss = 436.840\n",
      "Epoch: 18091/40000, alpha = 1.00083\n",
      "\n",
      "Epoch: 18101/40000, total loss = 3.043, Fit loss U = 13.997, Fit loss F = 3.230, KL loss = 436.321\n",
      "Epoch: 18101/40000, error_test = 1.00931, error_train = 1.03719\n",
      "Epoch: 18101/40000, error_f = 1.00000\n",
      "Epoch: 18101/40000, alpha = 1.00082\n",
      "\n",
      "Epoch: 18111/40000, total loss = 2.912, Fit loss U = 11.198, Fit loss F = 3.230, KL loss = 438.035\n",
      "Epoch: 18111/40000, alpha = 1.00082\n",
      "\n",
      "Epoch: 18121/40000, total loss = 2.766, Fit loss U = 8.187, Fit loss F = 3.229, KL loss = 439.131\n",
      "Epoch: 18121/40000, alpha = 1.00082\n",
      "\n",
      "Epoch: 18131/40000, total loss = 2.844, Fit loss U = 9.754, Fit loss F = 3.229, KL loss = 438.957\n",
      "Epoch: 18131/40000, alpha = 1.00081\n",
      "\n",
      "Epoch: 18141/40000, total loss = 2.696, Fit loss U = 6.733, Fit loss F = 3.229, KL loss = 439.535\n",
      "Epoch: 18141/40000, alpha = 1.00081\n",
      "\n",
      "Epoch: 18151/40000, total loss = 2.759, Fit loss U = 8.043, Fit loss F = 3.229, KL loss = 438.993\n",
      "Epoch: 18151/40000, alpha = 1.00081\n",
      "\n",
      "Epoch: 18161/40000, total loss = 2.743, Fit loss U = 7.872, Fit loss F = 3.229, KL loss = 437.653\n",
      "Epoch: 18161/40000, alpha = 1.00080\n",
      "\n",
      "Epoch: 18171/40000, total loss = 2.799, Fit loss U = 9.049, Fit loss F = 3.229, KL loss = 437.074\n",
      "Epoch: 18171/40000, alpha = 1.00080\n",
      "\n",
      "Epoch: 18181/40000, total loss = 2.876, Fit loss U = 10.589, Fit loss F = 3.229, KL loss = 437.104\n",
      "Epoch: 18181/40000, alpha = 1.00080\n",
      "\n",
      "Epoch: 18191/40000, total loss = 2.973, Fit loss U = 12.512, Fit loss F = 3.229, KL loss = 437.216\n",
      "Epoch: 18191/40000, alpha = 1.00079\n",
      "\n",
      "Epoch: 18201/40000, total loss = 2.782, Fit loss U = 8.547, Fit loss F = 3.229, KL loss = 438.603\n",
      "Epoch: 18201/40000, error_test = 1.01693, error_train = 1.04184\n",
      "Epoch: 18201/40000, error_f = 0.99999\n",
      "Epoch: 18201/40000, alpha = 1.00079\n",
      "\n",
      "Epoch: 18211/40000, total loss = 2.898, Fit loss U = 10.796, Fit loss F = 3.229, KL loss = 439.376\n",
      "Epoch: 18211/40000, alpha = 1.00079\n",
      "\n",
      "Epoch: 18221/40000, total loss = 2.756, Fit loss U = 7.945, Fit loss F = 3.229, KL loss = 439.536\n",
      "Epoch: 18221/40000, alpha = 1.00078\n",
      "\n",
      "Epoch: 18231/40000, total loss = 2.817, Fit loss U = 9.245, Fit loss F = 3.229, KL loss = 438.629\n",
      "Epoch: 18231/40000, alpha = 1.00078\n",
      "\n",
      "Epoch: 18241/40000, total loss = 2.821, Fit loss U = 9.398, Fit loss F = 3.229, KL loss = 437.957\n",
      "Epoch: 18241/40000, alpha = 1.00078\n",
      "\n",
      "Epoch: 18251/40000, total loss = 2.879, Fit loss U = 10.573, Fit loss F = 3.229, KL loss = 437.722\n",
      "Epoch: 18251/40000, alpha = 1.00077\n",
      "\n",
      "Epoch: 18261/40000, total loss = 2.798, Fit loss U = 8.929, Fit loss F = 3.229, KL loss = 437.931\n",
      "Epoch: 18261/40000, alpha = 1.00077\n",
      "\n",
      "Epoch: 18271/40000, total loss = 2.870, Fit loss U = 10.396, Fit loss F = 3.229, KL loss = 437.803\n",
      "Epoch: 18271/40000, alpha = 1.00077\n",
      "\n",
      "Epoch: 18281/40000, total loss = 2.712, Fit loss U = 7.217, Fit loss F = 3.229, KL loss = 437.860\n",
      "Epoch: 18281/40000, alpha = 1.00076\n",
      "\n",
      "Epoch: 18291/40000, total loss = 2.807, Fit loss U = 9.135, Fit loss F = 3.229, KL loss = 437.703\n",
      "Epoch: 18291/40000, alpha = 1.00076\n",
      "\n",
      "Epoch: 18301/40000, total loss = 3.008, Fit loss U = 13.184, Fit loss F = 3.229, KL loss = 437.469\n",
      "Epoch: 18301/40000, error_test = 1.01663, error_train = 0.94548\n",
      "Epoch: 18301/40000, error_f = 1.00000\n",
      "Epoch: 18301/40000, alpha = 1.00076\n",
      "\n",
      "Epoch: 18311/40000, total loss = 2.865, Fit loss U = 10.237, Fit loss F = 3.229, KL loss = 438.405\n",
      "Epoch: 18311/40000, alpha = 1.00075\n",
      "\n",
      "Epoch: 18321/40000, total loss = 2.781, Fit loss U = 8.498, Fit loss F = 3.229, KL loss = 438.945\n",
      "Epoch: 18321/40000, alpha = 1.00075\n",
      "\n",
      "Epoch: 18331/40000, total loss = 2.771, Fit loss U = 8.273, Fit loss F = 3.229, KL loss = 439.233\n",
      "Epoch: 18331/40000, alpha = 1.00075\n",
      "\n",
      "Epoch: 18341/40000, total loss = 2.909, Fit loss U = 11.116, Fit loss F = 3.228, KL loss = 438.361\n",
      "Epoch: 18341/40000, alpha = 1.00074\n",
      "\n",
      "Epoch: 18351/40000, total loss = 2.961, Fit loss U = 12.105, Fit loss F = 3.229, KL loss = 438.922\n",
      "Epoch: 18351/40000, alpha = 1.00074\n",
      "\n",
      "Epoch: 18361/40000, total loss = 2.788, Fit loss U = 8.629, Fit loss F = 3.228, KL loss = 439.061\n",
      "Epoch: 18361/40000, alpha = 1.00074\n",
      "\n",
      "Epoch: 18371/40000, total loss = 2.819, Fit loss U = 9.252, Fit loss F = 3.228, KL loss = 439.085\n",
      "Epoch: 18371/40000, alpha = 1.00073\n",
      "\n",
      "Epoch: 18381/40000, total loss = 2.942, Fit loss U = 11.686, Fit loss F = 3.228, KL loss = 439.304\n",
      "Epoch: 18381/40000, alpha = 1.00073\n",
      "\n",
      "Epoch: 18391/40000, total loss = 2.798, Fit loss U = 8.750, Fit loss F = 3.228, KL loss = 439.883\n",
      "Epoch: 18391/40000, alpha = 1.00073\n",
      "\n",
      "Epoch: 18401/40000, total loss = 2.772, Fit loss U = 8.314, Fit loss F = 3.228, KL loss = 439.005\n",
      "Epoch: 18401/40000, error_test = 0.96957, error_train = 1.00867\n",
      "Epoch: 18401/40000, error_f = 1.00000\n",
      "Epoch: 18401/40000, alpha = 1.00073\n",
      "\n",
      "Epoch: 18411/40000, total loss = 2.765, Fit loss U = 8.298, Fit loss F = 3.228, KL loss = 437.801\n",
      "Epoch: 18411/40000, alpha = 1.00072\n",
      "\n",
      "Epoch: 18421/40000, total loss = 2.763, Fit loss U = 8.220, Fit loss F = 3.228, KL loss = 438.131\n",
      "Epoch: 18421/40000, alpha = 1.00072\n",
      "\n",
      "Epoch: 18431/40000, total loss = 2.819, Fit loss U = 9.285, Fit loss F = 3.228, KL loss = 438.741\n",
      "Epoch: 18431/40000, alpha = 1.00072\n",
      "\n",
      "Epoch: 18441/40000, total loss = 2.797, Fit loss U = 8.748, Fit loss F = 3.228, KL loss = 439.543\n",
      "Epoch: 18441/40000, alpha = 1.00071\n",
      "\n",
      "Epoch: 18451/40000, total loss = 2.942, Fit loss U = 11.590, Fit loss F = 3.228, KL loss = 440.123\n",
      "Epoch: 18451/40000, alpha = 1.00071\n",
      "\n",
      "Epoch: 18461/40000, total loss = 2.793, Fit loss U = 8.568, Fit loss F = 3.228, KL loss = 440.602\n",
      "Epoch: 18461/40000, alpha = 1.00071\n",
      "\n",
      "Epoch: 18471/40000, total loss = 2.881, Fit loss U = 10.427, Fit loss F = 3.228, KL loss = 439.563\n",
      "Epoch: 18471/40000, alpha = 1.00070\n",
      "\n",
      "Epoch: 18481/40000, total loss = 2.969, Fit loss U = 12.233, Fit loss F = 3.228, KL loss = 439.211\n",
      "Epoch: 18481/40000, alpha = 1.00070\n",
      "\n",
      "Epoch: 18491/40000, total loss = 2.781, Fit loss U = 8.439, Fit loss F = 3.228, KL loss = 439.593\n",
      "Epoch: 18491/40000, alpha = 1.00070\n",
      "\n",
      "Epoch: 18501/40000, total loss = 2.979, Fit loss U = 12.472, Fit loss F = 3.228, KL loss = 438.818\n",
      "Epoch: 18501/40000, error_test = 1.00462, error_train = 0.98700\n",
      "Epoch: 18501/40000, error_f = 1.00000\n",
      "Epoch: 18501/40000, alpha = 1.00070\n",
      "\n",
      "Epoch: 18511/40000, total loss = 2.870, Fit loss U = 10.312, Fit loss F = 3.228, KL loss = 438.601\n",
      "Epoch: 18511/40000, alpha = 1.00069\n",
      "\n",
      "Epoch: 18521/40000, total loss = 2.762, Fit loss U = 8.255, Fit loss F = 3.227, KL loss = 437.537\n",
      "Epoch: 18521/40000, alpha = 1.00069\n",
      "\n",
      "Epoch: 18531/40000, total loss = 2.837, Fit loss U = 9.780, Fit loss F = 3.228, KL loss = 437.246\n",
      "Epoch: 18531/40000, alpha = 1.00069\n",
      "\n",
      "Epoch: 18541/40000, total loss = 2.785, Fit loss U = 8.618, Fit loss F = 3.228, KL loss = 438.513\n",
      "Epoch: 18541/40000, alpha = 1.00068\n",
      "\n",
      "Epoch: 18551/40000, total loss = 2.704, Fit loss U = 6.969, Fit loss F = 3.228, KL loss = 438.920\n",
      "Epoch: 18551/40000, alpha = 1.00068\n",
      "\n",
      "Epoch: 18561/40000, total loss = 2.833, Fit loss U = 9.630, Fit loss F = 3.228, KL loss = 437.985\n",
      "Epoch: 18561/40000, alpha = 1.00068\n",
      "\n",
      "Epoch: 18571/40000, total loss = 2.786, Fit loss U = 8.694, Fit loss F = 3.227, KL loss = 437.980\n",
      "Epoch: 18571/40000, alpha = 1.00068\n",
      "\n",
      "Epoch: 18581/40000, total loss = 2.778, Fit loss U = 8.540, Fit loss F = 3.227, KL loss = 437.967\n",
      "Epoch: 18581/40000, alpha = 1.00067\n",
      "\n",
      "Epoch: 18591/40000, total loss = 2.840, Fit loss U = 9.744, Fit loss F = 3.227, KL loss = 438.317\n",
      "Epoch: 18591/40000, alpha = 1.00067\n",
      "\n",
      "Epoch: 18601/40000, total loss = 2.810, Fit loss U = 9.107, Fit loss F = 3.227, KL loss = 438.586\n",
      "Epoch: 18601/40000, error_test = 1.00547, error_train = 1.02109\n",
      "Epoch: 18601/40000, error_f = 0.99999\n",
      "Epoch: 18601/40000, alpha = 1.00067\n",
      "\n",
      "Epoch: 18611/40000, total loss = 2.819, Fit loss U = 9.300, Fit loss F = 3.227, KL loss = 438.431\n",
      "Epoch: 18611/40000, alpha = 1.00066\n",
      "\n",
      "Epoch: 18621/40000, total loss = 2.781, Fit loss U = 8.584, Fit loss F = 3.227, KL loss = 438.123\n",
      "Epoch: 18621/40000, alpha = 1.00066\n",
      "\n",
      "Epoch: 18631/40000, total loss = 2.905, Fit loss U = 11.135, Fit loss F = 3.227, KL loss = 437.450\n",
      "Epoch: 18631/40000, alpha = 1.00066\n",
      "\n",
      "Epoch: 18641/40000, total loss = 2.940, Fit loss U = 11.855, Fit loss F = 3.227, KL loss = 437.144\n",
      "Epoch: 18641/40000, alpha = 1.00066\n",
      "\n",
      "Epoch: 18651/40000, total loss = 2.836, Fit loss U = 9.713, Fit loss F = 3.228, KL loss = 437.808\n",
      "Epoch: 18651/40000, alpha = 1.00065\n",
      "\n",
      "Epoch: 18661/40000, total loss = 2.813, Fit loss U = 9.169, Fit loss F = 3.227, KL loss = 438.730\n",
      "Epoch: 18661/40000, alpha = 1.00065\n",
      "\n",
      "Epoch: 18671/40000, total loss = 2.728, Fit loss U = 7.399, Fit loss F = 3.227, KL loss = 439.260\n",
      "Epoch: 18671/40000, alpha = 1.00065\n",
      "\n",
      "Epoch: 18681/40000, total loss = 2.707, Fit loss U = 6.982, Fit loss F = 3.227, KL loss = 439.265\n",
      "Epoch: 18681/40000, alpha = 1.00065\n",
      "\n",
      "Epoch: 18691/40000, total loss = 2.740, Fit loss U = 7.791, Fit loss F = 3.227, KL loss = 437.842\n",
      "Epoch: 18691/40000, alpha = 1.00064\n",
      "\n",
      "Epoch: 18701/40000, total loss = 2.832, Fit loss U = 9.635, Fit loss F = 3.227, KL loss = 437.857\n",
      "Epoch: 18701/40000, error_test = 1.04558, error_train = 1.01153\n",
      "Epoch: 18701/40000, error_f = 1.00000\n",
      "Epoch: 18701/40000, alpha = 1.00064\n",
      "\n",
      "Epoch: 18711/40000, total loss = 2.826, Fit loss U = 9.415, Fit loss F = 3.227, KL loss = 438.873\n",
      "Epoch: 18711/40000, alpha = 1.00064\n",
      "\n",
      "Epoch: 18721/40000, total loss = 2.772, Fit loss U = 8.228, Fit loss F = 3.227, KL loss = 439.866\n",
      "Epoch: 18721/40000, alpha = 1.00063\n",
      "\n",
      "Epoch: 18731/40000, total loss = 2.769, Fit loss U = 8.176, Fit loss F = 3.227, KL loss = 439.697\n",
      "Epoch: 18731/40000, alpha = 1.00063\n",
      "\n",
      "Epoch: 18741/40000, total loss = 2.707, Fit loss U = 7.090, Fit loss F = 3.227, KL loss = 438.325\n",
      "Epoch: 18741/40000, alpha = 1.00063\n",
      "\n",
      "Epoch: 18751/40000, total loss = 2.695, Fit loss U = 7.010, Fit loss F = 3.227, KL loss = 436.663\n",
      "Epoch: 18751/40000, alpha = 1.00063\n",
      "\n",
      "Epoch: 18761/40000, total loss = 2.856, Fit loss U = 10.332, Fit loss F = 3.227, KL loss = 435.569\n",
      "Epoch: 18761/40000, alpha = 1.00062\n",
      "\n",
      "Epoch: 18771/40000, total loss = 2.775, Fit loss U = 8.730, Fit loss F = 3.227, KL loss = 435.521\n",
      "Epoch: 18771/40000, alpha = 1.00062\n",
      "\n",
      "Epoch: 18781/40000, total loss = 2.780, Fit loss U = 8.705, Fit loss F = 3.227, KL loss = 436.669\n",
      "Epoch: 18781/40000, alpha = 1.00062\n",
      "\n",
      "Epoch: 18791/40000, total loss = 2.733, Fit loss U = 7.719, Fit loss F = 3.227, KL loss = 437.152\n",
      "Epoch: 18791/40000, alpha = 1.00062\n",
      "\n",
      "Epoch: 18801/40000, total loss = 2.907, Fit loss U = 11.145, Fit loss F = 3.227, KL loss = 437.630\n",
      "Epoch: 18801/40000, error_test = 1.01873, error_train = 1.04567\n",
      "Epoch: 18801/40000, error_f = 1.00000\n",
      "Epoch: 18801/40000, alpha = 1.00061\n",
      "\n",
      "Epoch: 18811/40000, total loss = 2.721, Fit loss U = 7.419, Fit loss F = 3.227, KL loss = 437.803\n",
      "Epoch: 18811/40000, alpha = 1.00061\n",
      "\n",
      "Epoch: 18821/40000, total loss = 2.916, Fit loss U = 11.274, Fit loss F = 3.226, KL loss = 438.207\n",
      "Epoch: 18821/40000, alpha = 1.00061\n",
      "\n",
      "Epoch: 18831/40000, total loss = 2.773, Fit loss U = 8.327, Fit loss F = 3.227, KL loss = 439.112\n",
      "Epoch: 18831/40000, alpha = 1.00061\n",
      "\n",
      "Epoch: 18841/40000, total loss = 2.683, Fit loss U = 6.531, Fit loss F = 3.227, KL loss = 439.032\n",
      "Epoch: 18841/40000, alpha = 1.00060\n",
      "\n",
      "Epoch: 18851/40000, total loss = 2.816, Fit loss U = 9.241, Fit loss F = 3.227, KL loss = 438.590\n",
      "Epoch: 18851/40000, alpha = 1.00060\n",
      "\n",
      "Epoch: 18861/40000, total loss = 2.837, Fit loss U = 9.650, Fit loss F = 3.226, KL loss = 438.565\n",
      "Epoch: 18861/40000, alpha = 1.00060\n",
      "\n",
      "Epoch: 18871/40000, total loss = 2.734, Fit loss U = 7.566, Fit loss F = 3.226, KL loss = 438.901\n",
      "Epoch: 18871/40000, alpha = 1.00060\n",
      "\n",
      "Epoch: 18881/40000, total loss = 2.830, Fit loss U = 9.442, Fit loss F = 3.226, KL loss = 439.361\n",
      "Epoch: 18881/40000, alpha = 1.00059\n",
      "\n",
      "Epoch: 18891/40000, total loss = 2.725, Fit loss U = 7.361, Fit loss F = 3.226, KL loss = 439.195\n",
      "Epoch: 18891/40000, alpha = 1.00059\n",
      "\n",
      "Epoch: 18901/40000, total loss = 2.813, Fit loss U = 9.061, Fit loss F = 3.226, KL loss = 439.816\n",
      "Epoch: 18901/40000, error_test = 1.03251, error_train = 0.99737\n",
      "Epoch: 18901/40000, error_f = 1.00000\n",
      "Epoch: 18901/40000, alpha = 1.00059\n",
      "\n",
      "Epoch: 18911/40000, total loss = 2.733, Fit loss U = 7.501, Fit loss F = 3.226, KL loss = 439.410\n",
      "Epoch: 18911/40000, alpha = 1.00059\n",
      "\n",
      "Epoch: 18921/40000, total loss = 2.780, Fit loss U = 8.527, Fit loss F = 3.226, KL loss = 438.517\n",
      "Epoch: 18921/40000, alpha = 1.00058\n",
      "\n",
      "Epoch: 18931/40000, total loss = 2.857, Fit loss U = 10.021, Fit loss F = 3.226, KL loss = 438.938\n",
      "Epoch: 18931/40000, alpha = 1.00058\n",
      "\n",
      "Epoch: 18941/40000, total loss = 2.880, Fit loss U = 10.571, Fit loss F = 3.226, KL loss = 438.099\n",
      "Epoch: 18941/40000, alpha = 1.00058\n",
      "\n",
      "Epoch: 18951/40000, total loss = 2.774, Fit loss U = 8.481, Fit loss F = 3.226, KL loss = 437.695\n",
      "Epoch: 18951/40000, alpha = 1.00058\n",
      "\n",
      "Epoch: 18961/40000, total loss = 2.866, Fit loss U = 10.375, Fit loss F = 3.226, KL loss = 437.164\n",
      "Epoch: 18961/40000, alpha = 1.00057\n",
      "\n",
      "Epoch: 18971/40000, total loss = 2.788, Fit loss U = 8.821, Fit loss F = 3.226, KL loss = 437.215\n",
      "Epoch: 18971/40000, alpha = 1.00057\n",
      "\n",
      "Epoch: 18981/40000, total loss = 2.876, Fit loss U = 10.552, Fit loss F = 3.226, KL loss = 437.384\n",
      "Epoch: 18981/40000, alpha = 1.00057\n",
      "\n",
      "Epoch: 18991/40000, total loss = 2.829, Fit loss U = 9.603, Fit loss F = 3.226, KL loss = 437.457\n",
      "Epoch: 18991/40000, alpha = 1.00057\n",
      "\n",
      "Epoch: 19001/40000, total loss = 2.682, Fit loss U = 6.534, Fit loss F = 3.226, KL loss = 438.871\n",
      "Epoch: 19001/40000, error_test = 1.03516, error_train = 0.96657\n",
      "Epoch: 19001/40000, error_f = 1.00000\n",
      "Epoch: 19001/40000, alpha = 1.00056\n",
      "\n",
      "Epoch: 19011/40000, total loss = 2.762, Fit loss U = 8.106, Fit loss F = 3.226, KL loss = 439.064\n",
      "Epoch: 19011/40000, alpha = 1.00056\n",
      "\n",
      "Epoch: 19021/40000, total loss = 2.772, Fit loss U = 8.389, Fit loss F = 3.226, KL loss = 438.212\n",
      "Epoch: 19021/40000, alpha = 1.00056\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(num_epochs)\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 13\u001b[0m     EU, EF, KL_loss, total_loss \u001b[39m=\u001b[39m pinn_model\u001b[39m.\u001b[39;49mfit(X_u, X_f, U, F, n_samples \u001b[39m=\u001b[39;49m n_fit)\n\u001b[1;32m     15\u001b[0m     fit_loss_U_train[i] \u001b[39m=\u001b[39m EU\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m     fit_loss_F_train[i] \u001b[39m=\u001b[39m EF\u001b[39m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[10], line 119\u001b[0m, in \u001b[0;36mBBP_Model_PINN_Poisson.fit\u001b[0;34m(self, X_u, X_f, U, F, n_samples)\u001b[0m\n\u001b[1;32m    116\u001b[0m     f_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet_F(X_f, lambda1_sample)\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     f_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet_F_forward(X_f)\n\u001b[1;32m    120\u001b[0m     KL_loss_lambda1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[39m# calculate fit loss based on mean and standard deviation of output\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 76\u001b[0m, in \u001b[0;36mBBP_Model_PINN_Poisson.net_F_forward\u001b[0;34m(self, X_f)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnet_F_forward\u001b[39m(\u001b[39mself\u001b[39m, X_f):\n\u001b[0;32m---> 76\u001b[0m     u, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet_U(X_f)\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormal:\n\u001b[1;32m     78\u001b[0m         u \u001b[39m=\u001b[39m u\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_ub\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_lb) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_lb \u001b[39m# reverse scaling\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 49\u001b[0m, in \u001b[0;36mBBP_Model_PINN_Poisson.net_U\u001b[0;34m(self, xt)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnet_U\u001b[39m(\u001b[39mself\u001b[39m, xt):\n\u001b[1;32m     48\u001b[0m     xt \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m(xt\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxt_lb)\u001b[39m/\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxt_ub\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxt_lb) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 49\u001b[0m     out, KL_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(xt)\n\u001b[1;32m     51\u001b[0m     u \u001b[39m=\u001b[39m out[:, \u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]\n\u001b[1;32m     52\u001b[0m     log_noise_u \u001b[39m=\u001b[39m out[:, \u001b[39m1\u001b[39m:\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/torch/Bayesian_DL/BPINN/model.py:193\u001b[0m, in \u001b[0;36mBBP_Model_res.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m KL_loss_total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_list_torch:\n\u001b[0;32m--> 193\u001b[0m     x, KL_loss \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    194\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n\u001b[1;32m    195\u001b[0m     KL_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m KL_loss\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/torch/Bayesian_DL/BPINN/model.py:158\u001b[0m, in \u001b[0;36mRes_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(out)\n\u001b[1;32m    156\u001b[0m KL_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m KL_loss\n\u001b[0;32m--> 158\u001b[0m out, KL_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb_layer2(out)\n\u001b[1;32m    159\u001b[0m KL_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m KL_loss\n\u001b[1;32m    161\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(out \u001b[39m+\u001b[39m res)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/torch/Bayesian_DL/BPINN/model.py:94\u001b[0m, in \u001b[0;36mBayesLinear_Normalq_local.forward\u001b[0;34m(self, x, sample)\u001b[0m\n\u001b[1;32m     90\u001b[0m output \u001b[39m=\u001b[39m act_W_out \u001b[39m+\u001b[39m act_b_out\n\u001b[1;32m     93\u001b[0m KL_loss_weight \u001b[39m=\u001b[39m get_kl_Gaussian_divergence(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior\u001b[39m.\u001b[39mmu, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior\u001b[39m.\u001b[39msigma\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_mu, std_w\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m KL_loss_bias \u001b[39m=\u001b[39m get_kl_Gaussian_divergence(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprior\u001b[39m.\u001b[39;49mmu, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprior\u001b[39m.\u001b[39;49msigma\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb_mu, std_b\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     95\u001b[0m KL_loss \u001b[39m=\u001b[39m KL_loss_weight \u001b[39m+\u001b[39m KL_loss_bias\n\u001b[1;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m output, KL_loss\n",
      "File \u001b[0;32m~/torch/Bayesian_DL/BPINN/utils.py:35\u001b[0m, in \u001b[0;36mget_kl_Gaussian_divergence\u001b[0;34m(prior_mus, prior_cov, varpost_mus, varpost_cov)\u001b[0m\n\u001b[1;32m     33\u001b[0m KL_loss \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (torch\u001b[39m.\u001b[39mlog(prior_cov \u001b[39m/\u001b[39m varpost_cov))\u001b[39m.\u001b[39msum() \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m varpost_cov\u001b[39m.\u001b[39mnumel()\n\u001b[1;32m     34\u001b[0m KL_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (varpost_cov \u001b[39m/\u001b[39m prior_cov)\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> 35\u001b[0m KL_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m  \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m ((varpost_mus \u001b[39m-\u001b[39;49m prior_mus) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m/\u001b[39m prior_cov)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m KL_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_fit = 10\n",
    "# comment = f'KdV n_sample = {N_u} n_fit = {n_fit} res = {res}'\n",
    "# writer = SummaryWriter(comment = comment)\n",
    "\n",
    "fit_loss_U_train = np.zeros(num_epochs)\n",
    "fit_loss_F_train = np.zeros(num_epochs)\n",
    "KL_loss_train = np.zeros(num_epochs)\n",
    "loss = np.zeros(num_epochs)\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    EU, EF, KL_loss, total_loss = pinn_model.fit(X_u, X_f, U, F, n_samples = n_fit)\n",
    "    \n",
    "    fit_loss_U_train[i] = EU.item()\n",
    "    fit_loss_F_train[i] = EF.item()\n",
    "    KL_loss_train[i] = KL_loss.item()\n",
    "    loss[i] = total_loss.item()\n",
    "    \n",
    "\n",
    "    # writer.add_scalar(\"loss/total_loss\", loss[i], i)\n",
    "    # writer.add_scalar(\"loss/U_loss\", fit_loss_U_train[i], i)\n",
    "    # writer.add_scalar(\"loss/F_loss\", fit_loss_F_train[i], i)\n",
    "    # writer.add_scalar(\"loss/KL_loss\", KL_loss_train[i], i)\n",
    "    \n",
    "\n",
    "    # if i % 1000 == 0:\n",
    "    #     F_test = net.sample_F(X_u_test_25)\n",
    "    #     fig, axs = plt.subplots(2, 2, figsize=(20, 8))\n",
    "    #     axs[0,0].hist(F_test[:,0])\n",
    "    #     axs[0,1].hist(F_test[:,100])\n",
    "    #     axs[1,0].hist(F_test[:,150])\n",
    "    #     axs[1,1].hist(F_test[:,255])\n",
    "    #     plt.savefig('./plots/kdv_epoch{}_F.tiff'.format(i))\n",
    "\n",
    "\n",
    "    if i % 10 == 0 or i == num_epochs - 1:\n",
    "\n",
    "        print(\"Epoch: {:5d}/{:5d}, total loss = {:.3f}, Fit loss U = {:.3f}, Fit loss F = {:.3f}, KL loss = {:.3f}\".format(i + 1, num_epochs, \n",
    "            loss[i], fit_loss_U_train[i], fit_loss_F_train[i], KL_loss_train[i]))\n",
    "\n",
    "        if identification:\n",
    "            lambda1_mus = pinn_model.lambda1_mus.item()\n",
    "            lambda1_stds = torch.log(1 + torch.exp(pinn_model.lambda1_rhos)).item()\n",
    "            print(\"Epoch: {:5d}/{:5d}, lambda1_mu = {:.5f}, lambda1_std = {:.3f}\".format(i + 1, num_epochs,lambda1_mus, lambda1_stds))\n",
    "        \n",
    "    \n",
    "        \n",
    "        if i % 100 == 0 or i == num_epochs - 1:\n",
    "            samples_star, _, f_samples = pinn_model.predict(x, 50)\n",
    "            u_pred_star = samples_star.mean(axis = 0)\n",
    "            f_pred_star = f_samples.mean(axis = 0)\n",
    "\n",
    "            error_star = np.linalg.norm(u-u_pred_star, 2)/np.linalg.norm(u, 2)\n",
    "            error_f = np.linalg.norm(f-f_pred_star, 2)/np.linalg.norm(f, 2)\n",
    "            \n",
    "\n",
    "\n",
    "            samples_train, _, _ = pinn_model.predict(X_u_train, 50)\n",
    "            u_pred_train = samples_train.mean(axis=0)\n",
    "            error_train = np.linalg.norm(u_train-u_pred_train, 2)/np.linalg.norm(u_train, 2)\n",
    "\n",
    "            print(\"Epoch: {:5d}/{:5d}, error_test = {:.5f}, error_train = {:.5f}\".format(i+1, num_epochs, error_star, error_train))\n",
    "            print(\"Epoch: {:5d}/{:5d}, error_f = {:.5f}\".format(i+1, num_epochs, error_f))\n",
    "            # writer.add_scalars(\"loss/train_test\", {'train':error_train, 'test':error_star}, i)\n",
    "    \n",
    "        \n",
    "        \n",
    "        # print(\"Epoch: {:5d}/{:5d}, alpha = {:.5f}, beta = {:.5f}\".format(i+1, num_epochs, pinn_model.coef[0].item(), pinn_model.coef[1].item()))\n",
    "        print(\"Epoch: {:5d}/{:5d}, alpha = {:.5f}\".format(i+1, num_epochs, pinn_model.coef.item()))\n",
    "\n",
    "        print()\n",
    "\n",
    "# writer.close()\n",
    "#%%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f39eb2efd90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_res(X):\n",
    "    samples, noises, f_samples = pinn_model.predict(X, 100)\n",
    "    u_pred = samples.mean(axis = 0)\n",
    "    f_pred = f_samples.mean(axis = 0)\n",
    "    aleatoric = (noises**2).mean(axis = 0)**0.5\n",
    "    epistemic = samples.var(axis = 0)**0.5\n",
    "    total_unc = (aleatoric**2 + epistemic**2)**0.5\n",
    "\n",
    "    return u_pred.ravel(), f_pred.ravel(), aleatoric.ravel(), epistemic.ravel(), total_unc.ravel()\n",
    "\n",
    "u_pred, f_pred, aleatoric, epistemic, total_unc = get_res(x)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (15,4))\n",
    "axs[0].plot(x, f)\n",
    "axs[0].plot(x, f_pred)\n",
    "axs[0].plot(X_f_train, f_train, 'o')\n",
    "\n",
    "axs[1].plot(x, u)\n",
    "axs[1].plot(x, u_pred)\n",
    "axs[1].plot(X_u_train, u_train, 'o')\n",
    "axs[1].fill_between(x.ravel(), u_pred-2*total_unc, u_pred+2*total_unc, color = 'g', alpha = 0.5, label = 'Epistemic + Aleatoric')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda1_mu Parameter containing:\n",
      "tensor([0.0302], requires_grad=True)\n",
      "lambda1_rho Parameter containing:\n",
      "tensor([1.3662], requires_grad=True)\n",
      "alpha Parameter containing:\n",
      "tensor([-13.4181], requires_grad=True)\n",
      "last_layer.W_mu Parameter containing:\n",
      "tensor([[ 1.6277e-03, -1.7501e-03],\n",
      "        [-7.9999e-04, -3.4783e-03],\n",
      "        [-6.0921e-04, -2.1888e-03],\n",
      "        [ 4.4109e-04,  1.3757e-03],\n",
      "        [-1.5744e-03, -1.8203e-03],\n",
      "        [ 8.6123e-06,  1.4729e-03],\n",
      "        [ 8.6955e-04,  3.6897e-03],\n",
      "        [ 1.5298e-03,  9.3304e-04],\n",
      "        [-6.6330e-04,  7.7340e-06],\n",
      "        [ 4.1315e-04,  8.4451e-04],\n",
      "        [ 4.5148e-03, -1.5925e-03],\n",
      "        [-3.5029e-03, -2.7679e-04],\n",
      "        [ 5.1169e-04, -1.8087e-03],\n",
      "        [-2.1285e-03, -5.8471e-04],\n",
      "        [ 1.6366e-04,  1.7354e-03],\n",
      "        [-2.7697e-03,  2.7012e-03],\n",
      "        [ 1.0186e-03, -1.3753e-03],\n",
      "        [-1.1058e-03, -5.0656e-04],\n",
      "        [ 5.5778e-04,  2.8129e-03],\n",
      "        [-3.3109e-04,  1.7627e-03],\n",
      "        [-2.0930e-04, -2.9715e-04],\n",
      "        [-2.1061e-03, -4.0396e-03],\n",
      "        [-1.6173e-03,  1.3909e-03],\n",
      "        [-2.2663e-03, -3.2677e-06],\n",
      "        [-4.9341e-04, -1.4389e-03],\n",
      "        [ 6.8970e-04,  2.8339e-03],\n",
      "        [ 1.4333e-03, -8.0163e-04],\n",
      "        [-9.6214e-04, -4.1322e-06],\n",
      "        [ 7.8772e-05, -8.7939e-05],\n",
      "        [-1.0088e-04,  1.7792e-03],\n",
      "        [ 1.0534e-03,  3.3160e-05],\n",
      "        [-3.3505e-04,  3.7235e-03],\n",
      "        [-1.7016e-03,  2.0862e-04],\n",
      "        [-2.4304e-03,  2.8327e-04],\n",
      "        [ 2.6356e-03, -2.2243e-05],\n",
      "        [-1.2301e-04,  7.7736e-04],\n",
      "        [-1.9078e-04, -7.2387e-04],\n",
      "        [-1.6000e-03, -8.7549e-04],\n",
      "        [ 4.6117e-03, -6.7103e-04],\n",
      "        [ 1.8830e-03,  1.1466e-03],\n",
      "        [ 6.1971e-04,  1.4072e-03],\n",
      "        [ 1.7414e-04,  8.8734e-05],\n",
      "        [ 1.2308e-03,  5.9072e-04],\n",
      "        [ 1.0380e-03,  1.0177e-04],\n",
      "        [-1.4758e-03, -1.2011e-03],\n",
      "        [-1.0091e-03, -6.6320e-05],\n",
      "        [ 7.0482e-04,  1.0870e-03],\n",
      "        [ 7.2809e-04, -1.7296e-03],\n",
      "        [ 1.8837e-03, -2.5823e-03],\n",
      "        [-2.7010e-03, -1.2959e-04],\n",
      "        [-2.5167e-03,  1.9998e-03],\n",
      "        [-8.3244e-04,  1.6444e-03],\n",
      "        [ 2.9399e-03, -1.1373e-03],\n",
      "        [ 1.0889e-03,  1.2909e-03],\n",
      "        [ 4.3973e-05, -1.8753e-03],\n",
      "        [ 2.9831e-04,  1.0071e-03],\n",
      "        [-2.3902e-04,  1.8841e-03],\n",
      "        [ 8.0962e-04, -1.6750e-04],\n",
      "        [-9.4495e-04,  1.5608e-04],\n",
      "        [-9.9560e-04, -1.9562e-03],\n",
      "        [-4.2021e-04, -2.4517e-03],\n",
      "        [-8.8301e-04, -1.6496e-03],\n",
      "        [ 2.5647e-04, -9.9607e-04],\n",
      "        [-6.7696e-04,  8.1323e-04],\n",
      "        [-6.1041e-04, -2.0240e-03],\n",
      "        [-3.4965e-05,  1.3963e-03],\n",
      "        [-8.8446e-05, -1.3815e-03],\n",
      "        [ 6.4815e-04, -2.3084e-04],\n",
      "        [ 2.7774e-04,  1.0918e-03],\n",
      "        [-1.8218e-04, -6.3635e-04],\n",
      "        [ 4.3556e-03, -2.3654e-04],\n",
      "        [-1.9081e-03,  7.3239e-05],\n",
      "        [-2.4596e-05, -3.8283e-04],\n",
      "        [-3.0985e-03,  1.7313e-03],\n",
      "        [ 7.3304e-04,  1.7096e-03],\n",
      "        [ 6.5423e-06,  2.8071e-04],\n",
      "        [ 3.2047e-04, -5.7289e-04],\n",
      "        [-5.5987e-05, -9.3229e-04],\n",
      "        [-4.8434e-05, -6.2620e-04],\n",
      "        [ 1.5022e-04, -2.5653e-03],\n",
      "        [ 5.6940e-04, -1.3929e-05],\n",
      "        [-3.1447e-04,  1.0921e-03],\n",
      "        [ 6.4272e-04, -9.9443e-04],\n",
      "        [ 3.5368e-03, -1.9578e-03],\n",
      "        [-1.1812e-03, -9.1464e-05],\n",
      "        [-4.4999e-04,  2.9970e-03],\n",
      "        [-2.3570e-04, -9.7655e-04],\n",
      "        [-2.4358e-03, -1.0980e-03],\n",
      "        [ 6.6346e-05, -3.9374e-04],\n",
      "        [ 3.3756e-04,  6.0266e-04],\n",
      "        [-3.6008e-03, -1.6821e-04],\n",
      "        [-2.7805e-03, -6.2530e-04],\n",
      "        [ 5.8722e-04, -1.2018e-03],\n",
      "        [ 2.9944e-03,  5.3333e-04],\n",
      "        [-1.8228e-03,  1.4599e-03],\n",
      "        [-2.7296e-03, -3.8180e-04],\n",
      "        [ 1.7376e-03, -2.9461e-03],\n",
      "        [ 3.0591e-04, -1.2574e-03],\n",
      "        [ 1.7899e-03, -1.8686e-03],\n",
      "        [ 2.6757e-03, -1.5908e-03]], requires_grad=True)\n",
      "last_layer.W_p Parameter containing:\n",
      "tensor([[-2.6067, -2.6504],\n",
      "        [-2.6064, -2.6495],\n",
      "        [-2.6068, -2.6496],\n",
      "        [-2.6070, -2.6501],\n",
      "        [-2.6064, -2.6500],\n",
      "        [-2.6069, -2.6499],\n",
      "        [-2.6058, -2.6492],\n",
      "        [-2.6066, -2.6492],\n",
      "        [-2.6058, -2.6488],\n",
      "        [-2.6066, -2.6500],\n",
      "        [-2.6066, -2.6503],\n",
      "        [-2.6067, -2.6491],\n",
      "        [-2.6064, -2.6499],\n",
      "        [-2.6068, -2.6501],\n",
      "        [-2.6071, -2.6509],\n",
      "        [-2.6068, -2.6501],\n",
      "        [-2.6060, -2.6494],\n",
      "        [-2.6062, -2.6491],\n",
      "        [-2.6066, -2.6494],\n",
      "        [-2.6069, -2.6498],\n",
      "        [-2.6062, -2.6490],\n",
      "        [-2.6070, -2.6499],\n",
      "        [-2.6067, -2.6501],\n",
      "        [-2.6068, -2.6501],\n",
      "        [-2.6067, -2.6492],\n",
      "        [-2.6066, -2.6495],\n",
      "        [-2.6064, -2.6491],\n",
      "        [-2.6065, -2.6495],\n",
      "        [-2.6066, -2.6492],\n",
      "        [-2.6064, -2.6498],\n",
      "        [-2.6059, -2.6484],\n",
      "        [-2.6065, -2.6504],\n",
      "        [-2.6069, -2.6505],\n",
      "        [-2.6066, -2.6493],\n",
      "        [-2.6066, -2.6501],\n",
      "        [-2.6073, -2.6516],\n",
      "        [-2.6062, -2.6494],\n",
      "        [-2.6065, -2.6498],\n",
      "        [-2.6071, -2.6506],\n",
      "        [-2.6070, -2.6503],\n",
      "        [-2.6065, -2.6503],\n",
      "        [-2.6064, -2.6504],\n",
      "        [-2.6064, -2.6497],\n",
      "        [-2.6065, -2.6498],\n",
      "        [-2.6062, -2.6494],\n",
      "        [-2.6059, -2.6490],\n",
      "        [-2.6068, -2.6498],\n",
      "        [-2.6064, -2.6490],\n",
      "        [-2.6063, -2.6499],\n",
      "        [-2.6067, -2.6498],\n",
      "        [-2.6061, -2.6484],\n",
      "        [-2.6062, -2.6492],\n",
      "        [-2.6066, -2.6491],\n",
      "        [-2.6061, -2.6498],\n",
      "        [-2.6069, -2.6496],\n",
      "        [-2.6060, -2.6487],\n",
      "        [-2.6066, -2.6491],\n",
      "        [-2.6063, -2.6493],\n",
      "        [-2.6065, -2.6493],\n",
      "        [-2.6073, -2.6503],\n",
      "        [-2.6067, -2.6496],\n",
      "        [-2.6065, -2.6500],\n",
      "        [-2.6067, -2.6498],\n",
      "        [-2.6062, -2.6488],\n",
      "        [-2.6071, -2.6505],\n",
      "        [-2.6064, -2.6492],\n",
      "        [-2.6059, -2.6495],\n",
      "        [-2.6071, -2.6505],\n",
      "        [-2.6061, -2.6495],\n",
      "        [-2.6063, -2.6491],\n",
      "        [-2.6067, -2.6502],\n",
      "        [-2.6073, -2.6510],\n",
      "        [-2.6063, -2.6493],\n",
      "        [-2.6065, -2.6498],\n",
      "        [-2.6066, -2.6499],\n",
      "        [-2.6061, -2.6490],\n",
      "        [-2.6066, -2.6500],\n",
      "        [-2.6063, -2.6486],\n",
      "        [-2.6065, -2.6494],\n",
      "        [-2.6066, -2.6502],\n",
      "        [-2.6061, -2.6496],\n",
      "        [-2.6059, -2.6487],\n",
      "        [-2.6068, -2.6493],\n",
      "        [-2.6061, -2.6497],\n",
      "        [-2.6063, -2.6495],\n",
      "        [-2.6063, -2.6494],\n",
      "        [-2.6056, -2.6487],\n",
      "        [-2.6069, -2.6500],\n",
      "        [-2.6067, -2.6497],\n",
      "        [-2.6069, -2.6499],\n",
      "        [-2.6061, -2.6492],\n",
      "        [-2.6063, -2.6501],\n",
      "        [-2.6061, -2.6491],\n",
      "        [-2.6072, -2.6508],\n",
      "        [-2.6064, -2.6497],\n",
      "        [-2.6063, -2.6491],\n",
      "        [-2.6062, -2.6496],\n",
      "        [-2.6065, -2.6499],\n",
      "        [-2.6061, -2.6488],\n",
      "        [-2.6063, -2.6498]], requires_grad=True)\n",
      "last_layer.b_mu Parameter containing:\n",
      "tensor([ 0.0026, -0.0463], requires_grad=True)\n",
      "last_layer.b_p Parameter containing:\n",
      "tensor([-2.9088, -2.9434], requires_grad=True)\n",
      "layer_list_torch.0.W_mu Parameter containing:\n",
      "tensor([[ 1.1837e-03, -1.7306e-03, -6.7014e-05,  9.0865e-05, -8.3250e-05,\n",
      "          6.0521e-04,  1.5982e-03,  7.3812e-04, -2.6426e-04,  7.6939e-04,\n",
      "          2.9067e-03, -1.3530e-03,  9.4382e-04, -1.3516e-03, -1.0345e-03,\n",
      "         -2.1324e-03,  1.3599e-04, -3.8043e-04,  6.3673e-04,  4.5402e-04,\n",
      "          1.1538e-03, -1.6649e-03, -2.3181e-04, -2.7393e-03,  3.4133e-04,\n",
      "          1.1625e-03,  2.6442e-04, -2.1687e-03, -3.1988e-04, -2.4815e-04,\n",
      "          9.2486e-04, -3.0555e-04, -9.4722e-04, -1.9971e-03,  1.0088e-03,\n",
      "         -1.0848e-03,  3.4956e-04, -1.9180e-03,  3.0139e-03,  1.0518e-03,\n",
      "          2.7516e-04,  3.1604e-04,  9.9633e-04,  2.9014e-04, -1.3810e-03,\n",
      "          6.0211e-04,  1.4187e-03,  8.1843e-05,  7.4135e-04, -1.5221e-03,\n",
      "         -1.5370e-03, -2.5072e-04,  1.7006e-03, -2.2427e-04,  1.2426e-03,\n",
      "         -1.5522e-04, -9.4643e-04,  4.5047e-04, -4.6166e-04, -5.9074e-04,\n",
      "         -2.5170e-04, -1.7240e-03,  4.0662e-04, -8.7367e-04, -3.6997e-04,\n",
      "         -3.1226e-04,  4.1156e-04, -2.0427e-04,  4.2815e-04,  5.3643e-04,\n",
      "          2.7446e-03, -6.2568e-04,  2.0779e-04, -2.3315e-03,  1.2016e-04,\n",
      "         -1.7550e-03,  7.5059e-04, -1.2299e-04, -4.6743e-04, -2.0852e-04,\n",
      "         -1.0062e-03, -6.5852e-05, -1.0783e-03,  1.0442e-03, -3.3906e-04,\n",
      "         -6.1257e-04,  1.5433e-04, -3.1720e-03, -2.0331e-04,  1.6364e-03,\n",
      "         -2.4138e-03, -1.4169e-03, -2.3007e-04,  1.9944e-03, -1.1500e-03,\n",
      "         -1.7221e-03,  8.8995e-04, -2.7878e-04,  1.7060e-03,  7.0387e-04]],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.0.W_p Parameter containing:\n",
      "tensor([[0.5421, 0.5408, 0.5413, 0.5412, 0.5409, 0.5412, 0.5412, 0.5407, 0.5413,\n",
      "         0.5417, 0.5415, 0.5410, 0.5404, 0.5404, 0.5404, 0.5405, 0.5412, 0.5411,\n",
      "         0.5412, 0.5405, 0.5405, 0.5410, 0.5407, 0.5412, 0.5414, 0.5399, 0.5414,\n",
      "         0.5406, 0.5402, 0.5401, 0.5412, 0.5413, 0.5416, 0.5406, 0.5401, 0.5414,\n",
      "         0.5403, 0.5411, 0.5410, 0.5411, 0.5411, 0.5410, 0.5410, 0.5413, 0.5407,\n",
      "         0.5411, 0.5401, 0.5408, 0.5418, 0.5407, 0.5413, 0.5410, 0.5409, 0.5414,\n",
      "         0.5403, 0.5409, 0.5409, 0.5420, 0.5417, 0.5414, 0.5405, 0.5408, 0.5404,\n",
      "         0.5411, 0.5409, 0.5414, 0.5402, 0.5405, 0.5414, 0.5399, 0.5407, 0.5413,\n",
      "         0.5405, 0.5410, 0.5409, 0.5413, 0.5402, 0.5407, 0.5408, 0.5412, 0.5414,\n",
      "         0.5408, 0.5412, 0.5407, 0.5409, 0.5405, 0.5412, 0.5405, 0.5414, 0.5414,\n",
      "         0.5413, 0.5415, 0.5413, 0.5401, 0.5410, 0.5407, 0.5409, 0.5408, 0.5410,\n",
      "         0.5405]], requires_grad=True)\n",
      "layer_list_torch.0.b_mu Parameter containing:\n",
      "tensor([ 1.0173e-03, -1.4094e-04,  1.2174e-03,  6.7986e-05,  5.6261e-04,\n",
      "        -1.2042e-03,  1.4593e-03,  3.6388e-05, -9.8354e-04, -1.1274e-03,\n",
      "         6.8477e-04,  1.2785e-03,  1.6417e-03, -2.5170e-04, -1.0264e-03,\n",
      "        -1.0448e-03,  1.8981e-03,  6.0068e-04,  6.6426e-04,  1.8182e-04,\n",
      "        -2.1643e-04,  1.6121e-03, -4.8738e-04, -1.3112e-03, -3.5744e-05,\n",
      "        -7.7795e-04,  1.1810e-03, -9.7366e-04, -1.8259e-03,  1.1846e-03,\n",
      "         1.8066e-03, -3.4406e-04,  3.7512e-05,  1.0419e-03,  8.4103e-04,\n",
      "         2.8503e-04,  6.0433e-04, -6.1696e-05, -2.9696e-04,  2.0695e-03,\n",
      "         1.3536e-03,  4.9151e-04, -8.6686e-04,  9.7521e-04,  1.2881e-03,\n",
      "        -2.6580e-05,  8.4199e-04,  1.1062e-04,  8.9337e-05,  1.5423e-04,\n",
      "        -1.5676e-03, -6.5845e-04, -7.7145e-05, -5.0371e-04,  1.0750e-03,\n",
      "         1.0730e-03, -1.1555e-03,  1.3477e-03,  4.3482e-04,  1.8892e-04,\n",
      "         7.3686e-04, -6.1081e-04,  1.8284e-03,  1.3050e-03,  8.1295e-04,\n",
      "         3.6767e-04, -6.4037e-04,  2.7906e-05, -1.6341e-04,  8.3235e-04,\n",
      "         7.7242e-05, -2.0438e-03, -4.1630e-04, -3.6890e-04,  7.3841e-04,\n",
      "         1.5107e-03,  1.8227e-04, -1.3195e-03,  4.1179e-04,  3.0929e-04,\n",
      "        -7.6930e-04, -5.5166e-04, -5.5419e-04, -8.6125e-04,  3.7270e-06,\n",
      "         3.5214e-04, -6.9364e-04,  4.9375e-05, -1.9548e-04,  5.4495e-04,\n",
      "        -1.0461e-04,  1.6779e-03, -2.7433e-04, -1.0460e-04,  4.8040e-04,\n",
      "         2.6878e-03, -1.1063e-03, -5.0721e-04, -8.8650e-04, -5.5283e-04],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.0.b_p Parameter containing:\n",
      "tensor([0.5387, 0.5395, 0.5392, 0.5395, 0.5397, 0.5397, 0.5395, 0.5404, 0.5399,\n",
      "        0.5389, 0.5403, 0.5393, 0.5412, 0.5407, 0.5402, 0.5400, 0.5392, 0.5407,\n",
      "        0.5397, 0.5407, 0.5402, 0.5405, 0.5402, 0.5398, 0.5396, 0.5411, 0.5393,\n",
      "        0.5408, 0.5405, 0.5406, 0.5392, 0.5389, 0.5398, 0.5399, 0.5409, 0.5394,\n",
      "        0.5400, 0.5391, 0.5391, 0.5408, 0.5395, 0.5402, 0.5403, 0.5396, 0.5407,\n",
      "        0.5390, 0.5397, 0.5394, 0.5396, 0.5401, 0.5405, 0.5399, 0.5395, 0.5393,\n",
      "        0.5404, 0.5403, 0.5400, 0.5387, 0.5399, 0.5399, 0.5405, 0.5406, 0.5400,\n",
      "        0.5394, 0.5389, 0.5402, 0.5401, 0.5401, 0.5396, 0.5397, 0.5400, 0.5391,\n",
      "        0.5402, 0.5407, 0.5397, 0.5390, 0.5403, 0.5396, 0.5399, 0.5399, 0.5401,\n",
      "        0.5402, 0.5392, 0.5400, 0.5397, 0.5397, 0.5393, 0.5397, 0.5390, 0.5396,\n",
      "        0.5397, 0.5394, 0.5403, 0.5402, 0.5396, 0.5400, 0.5400, 0.5397, 0.5404,\n",
      "        0.5406], requires_grad=True)\n",
      "layer_list_torch.1.b_layer1.W_mu Parameter containing:\n",
      "tensor([[ 2.2570e-05, -2.0347e-05, -6.7249e-05,  ...,  4.7051e-05,\n",
      "          1.0962e-04, -3.0922e-05],\n",
      "        [-2.7279e-04,  1.9703e-04, -6.2093e-05,  ..., -7.8304e-05,\n",
      "         -1.4293e-04, -1.0933e-04],\n",
      "        [ 1.3609e-04,  2.1295e-04,  6.4172e-05,  ...,  1.3687e-04,\n",
      "          4.9899e-05,  3.1264e-04],\n",
      "        ...,\n",
      "        [ 1.0859e-04, -2.5779e-04,  2.2786e-04,  ..., -3.7111e-05,\n",
      "         -3.6326e-06,  4.9173e-05],\n",
      "        [-6.4965e-05, -1.6449e-04, -1.3923e-04,  ..., -1.8170e-05,\n",
      "          1.8088e-05,  1.2512e-04],\n",
      "        [-2.1604e-04,  8.2440e-05, -2.5356e-04,  ..., -5.6629e-05,\n",
      "         -5.7761e-05,  2.3132e-06]], requires_grad=True)\n",
      "layer_list_torch.1.b_layer1.W_p Parameter containing:\n",
      "tensor([[0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413],\n",
      "        [0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413],\n",
      "        [0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413],\n",
      "        ...,\n",
      "        [0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413],\n",
      "        [0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413],\n",
      "        [0.5413, 0.5413, 0.5413,  ..., 0.5413, 0.5413, 0.5413]],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.1.b_layer1.b_mu Parameter containing:\n",
      "tensor([ 2.2125e-05, -2.6524e-04, -4.6214e-05,  1.3799e-04,  4.0357e-04,\n",
      "         1.5145e-05, -4.9964e-06, -1.6638e-04,  1.2645e-04,  1.3372e-04,\n",
      "        -3.4776e-04,  6.0950e-05, -2.0009e-05,  3.0082e-04,  1.0286e-04,\n",
      "        -4.1880e-05, -1.8217e-04, -3.1632e-04,  2.4544e-04, -8.6395e-05,\n",
      "         4.9688e-04,  3.6510e-04, -1.5536e-04,  2.5607e-04,  3.3147e-04,\n",
      "         3.1489e-05,  1.7193e-04, -3.5827e-04, -2.5385e-04,  5.3392e-05,\n",
      "         2.0229e-04, -1.5653e-04,  1.2930e-04,  2.4003e-04,  1.9591e-04,\n",
      "         6.2268e-05,  8.0262e-05,  7.5796e-05,  2.7906e-04, -1.1825e-05,\n",
      "         6.7438e-05, -2.4202e-04, -5.9953e-05,  1.7768e-04,  2.2728e-05,\n",
      "         1.4707e-04, -1.9244e-04, -2.6198e-04, -3.5093e-04, -3.0190e-04,\n",
      "        -9.0559e-06,  8.4801e-05, -3.9884e-05, -1.2718e-04,  2.4306e-04,\n",
      "        -1.1044e-04, -2.0035e-04, -9.7559e-05,  1.8242e-04, -4.3669e-04,\n",
      "        -3.6497e-04, -3.3151e-04, -2.0676e-04, -2.0160e-06,  1.3345e-04,\n",
      "         4.5372e-05,  9.4436e-05,  4.0538e-04,  2.0283e-04, -3.4937e-05,\n",
      "         1.1713e-04,  2.4319e-04, -1.7959e-04, -1.8818e-04, -5.3605e-04,\n",
      "         2.8805e-04, -1.7570e-04,  1.9715e-04,  1.6567e-06,  1.3657e-04,\n",
      "        -9.9659e-05,  3.0104e-05, -8.8620e-05,  1.4710e-04, -6.1899e-06,\n",
      "         2.1712e-04, -3.8734e-04, -5.1568e-05,  2.6114e-04, -4.8532e-05,\n",
      "         1.3037e-04,  1.8589e-04,  4.6328e-04, -8.1074e-05, -2.5281e-05,\n",
      "        -2.2092e-04, -8.6312e-05, -1.6315e-04, -2.2698e-04,  2.0438e-04],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.1.b_layer1.b_p Parameter containing:\n",
      "tensor([0.5410, 0.5410, 0.5411, 0.5411, 0.5409, 0.5412, 0.5410, 0.5410, 0.5411,\n",
      "        0.5412, 0.5414, 0.5413, 0.5414, 0.5413, 0.5413, 0.5414, 0.5414, 0.5410,\n",
      "        0.5412, 0.5414, 0.5410, 0.5409, 0.5413, 0.5411, 0.5414, 0.5413, 0.5412,\n",
      "        0.5414, 0.5415, 0.5408, 0.5412, 0.5412, 0.5412, 0.5410, 0.5412, 0.5409,\n",
      "        0.5413, 0.5413, 0.5409, 0.5413, 0.5412, 0.5409, 0.5415, 0.5413, 0.5412,\n",
      "        0.5412, 0.5411, 0.5411, 0.5413, 0.5413, 0.5414, 0.5413, 0.5412, 0.5412,\n",
      "        0.5410, 0.5414, 0.5414, 0.5412, 0.5413, 0.5410, 0.5415, 0.5417, 0.5413,\n",
      "        0.5410, 0.5411, 0.5413, 0.5411, 0.5414, 0.5412, 0.5410, 0.5413, 0.5412,\n",
      "        0.5411, 0.5412, 0.5413, 0.5411, 0.5411, 0.5415, 0.5414, 0.5413, 0.5412,\n",
      "        0.5411, 0.5412, 0.5413, 0.5413, 0.5408, 0.5414, 0.5414, 0.5411, 0.5411,\n",
      "        0.5413, 0.5412, 0.5412, 0.5412, 0.5412, 0.5413, 0.5412, 0.5411, 0.5409,\n",
      "        0.5414], requires_grad=True)\n",
      "layer_list_torch.1.b_layer2.W_mu Parameter containing:\n",
      "tensor([[-0.0009, -0.0009, -0.0014,  ...,  0.0011, -0.0001,  0.0001],\n",
      "        [ 0.0002,  0.0020,  0.0002,  ...,  0.0008, -0.0005, -0.0016],\n",
      "        [ 0.0015,  0.0001, -0.0002,  ...,  0.0014,  0.0012, -0.0012],\n",
      "        ...,\n",
      "        [-0.0009, -0.0003,  0.0010,  ..., -0.0001,  0.0002, -0.0006],\n",
      "        [-0.0023, -0.0014,  0.0003,  ...,  0.0010,  0.0003,  0.0013],\n",
      "        [-0.0006,  0.0017, -0.0013,  ...,  0.0006, -0.0006, -0.0002]],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.1.b_layer2.W_p Parameter containing:\n",
      "tensor([[0.5409, 0.5408, 0.5407,  ..., 0.5406, 0.5407, 0.5408],\n",
      "        [0.5409, 0.5408, 0.5407,  ..., 0.5407, 0.5407, 0.5408],\n",
      "        [0.5409, 0.5408, 0.5407,  ..., 0.5407, 0.5407, 0.5408],\n",
      "        ...,\n",
      "        [0.5409, 0.5407, 0.5407,  ..., 0.5406, 0.5407, 0.5408],\n",
      "        [0.5408, 0.5408, 0.5407,  ..., 0.5406, 0.5407, 0.5408],\n",
      "        [0.5409, 0.5408, 0.5407,  ..., 0.5407, 0.5407, 0.5408]],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.1.b_layer2.b_mu Parameter containing:\n",
      "tensor([ 1.3598e-03,  3.5546e-04,  1.2440e-03, -8.4403e-04,  1.7411e-03,\n",
      "        -1.7973e-03,  2.6534e-03, -8.5797e-04, -1.1261e-03, -5.6156e-04,\n",
      "         1.1841e-03,  1.7652e-03,  1.7722e-03, -2.4382e-05, -1.3507e-03,\n",
      "        -1.9285e-03,  1.8823e-03,  8.3985e-04,  9.9724e-04,  2.7292e-04,\n",
      "        -8.9453e-04,  2.8257e-03,  1.8655e-04, -2.3582e-03, -3.7408e-04,\n",
      "        -1.7752e-03,  9.9728e-04, -4.0848e-04, -2.6546e-03,  1.8220e-03,\n",
      "         1.3858e-03, -1.4727e-03, -1.8515e-04,  1.5444e-03,  1.7283e-03,\n",
      "        -7.3881e-04,  2.1287e-04,  2.5511e-04, -9.3596e-04,  2.2319e-03,\n",
      "         2.3614e-03,  2.4044e-04, -1.3037e-03,  8.7785e-04,  1.0224e-03,\n",
      "         1.8742e-04,  3.7015e-04,  5.7333e-04,  6.1996e-04,  1.5091e-04,\n",
      "        -1.5655e-03, -1.5465e-03,  6.1441e-04,  1.7853e-04,  2.1663e-03,\n",
      "         1.9954e-03, -2.6200e-03,  6.8353e-04, -3.4911e-04,  2.9114e-05,\n",
      "         9.6064e-04, -2.1519e-04,  1.9946e-03,  2.1593e-03,  7.7822e-04,\n",
      "         1.3675e-04, -3.2779e-04, -1.1429e-04, -9.4951e-06,  9.4394e-04,\n",
      "         3.4741e-04, -2.4030e-03, -4.2693e-04,  3.7673e-04,  7.1573e-04,\n",
      "         1.2604e-03,  4.0888e-04, -1.1702e-03,  4.3289e-04,  7.2559e-04,\n",
      "        -1.5999e-03, -2.9863e-04, -3.2057e-04, -1.1922e-03, -1.7550e-04,\n",
      "        -5.4109e-05, -6.0814e-04,  2.6785e-04,  1.6519e-05,  9.9843e-04,\n",
      "        -8.1590e-04,  2.3373e-03, -7.2198e-04, -6.9869e-04,  5.4979e-04,\n",
      "         3.6320e-03,  3.1620e-05, -6.7129e-04, -1.3975e-03, -7.4089e-04],\n",
      "       requires_grad=True)\n",
      "layer_list_torch.1.b_layer2.b_p Parameter containing:\n",
      "tensor([0.5419, 0.5396, 0.5402, 0.5411, 0.5415, 0.5406, 0.5432, 0.5391, 0.5411,\n",
      "        0.5410, 0.5398, 0.5412, 0.5397, 0.5404, 0.5402, 0.5393, 0.5405, 0.5423,\n",
      "        0.5399, 0.5411, 0.5407, 0.5394, 0.5405, 0.5405, 0.5408, 0.5389, 0.5392,\n",
      "        0.5408, 0.5395, 0.5400, 0.5412, 0.5407, 0.5414, 0.5398, 0.5419, 0.5405,\n",
      "        0.5404, 0.5416, 0.5409, 0.5390, 0.5407, 0.5387, 0.5395, 0.5404, 0.5393,\n",
      "        0.5387, 0.5414, 0.5407, 0.5403, 0.5401, 0.5405, 0.5408, 0.5399, 0.5393,\n",
      "        0.5413, 0.5407, 0.5403, 0.5400, 0.5409, 0.5419, 0.5396, 0.5402, 0.5417,\n",
      "        0.5396, 0.5410, 0.5404, 0.5405, 0.5399, 0.5406, 0.5409, 0.5405, 0.5395,\n",
      "        0.5415, 0.5408, 0.5387, 0.5410, 0.5401, 0.5400, 0.5418, 0.5403, 0.5430,\n",
      "        0.5381, 0.5404, 0.5426, 0.5404, 0.5414, 0.5425, 0.5399, 0.5412, 0.5399,\n",
      "        0.5395, 0.5402, 0.5408, 0.5388, 0.5413, 0.5397, 0.5412, 0.5403, 0.5412,\n",
      "        0.5403], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, para in pinn_model.network.named_parameters():\n",
    "    print(name, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca69f467ffdc3dc00e55b12e085102ec88652c053799da0c2cca2d561c3b19a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
